{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = '95fdae7b-8a0a-4dd9-8de9-ade704bdc2df'\n",
    "secretKey = '7j9q5mkc0b'\n",
    "rurl = urllib.parse.quote('https://127.0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570eb76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.upstox.com/v2/login/authorization/dialog?response_type=code&client_id=95fdae7b-8a0a-4dd9-8de9-ade704bdc2df&redirect_uri=https%3A//127.0.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://api.upstox.com/v2/login/authorization/dialog?response_type=code&client_id={apiKey}&redirect_uri={rurl}'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'wsBUoJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c68ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': 'parth.khutwad@gmail.com',\n",
       " 'exchanges': ['NSE', 'BSE'],\n",
       " 'products': ['OCO', 'D', 'CO', 'I'],\n",
       " 'broker': 'UPSTOX',\n",
       " 'user_id': '4HCXML',\n",
       " 'user_name': 'Parth Appasaheb Khutwad',\n",
       " 'order_types': ['MARKET', 'LIMIT', 'SL', 'SL-M'],\n",
       " 'user_type': 'individual',\n",
       " 'poa': False,\n",
       " 'ddpi': False,\n",
       " 'is_active': True,\n",
       " 'access_token': 'eyJ0eXAiOiJKV1QiLCJrZXlfaWQiOiJza192MS4wIiwiYWxnIjoiSFMyNTYifQ.eyJzdWIiOiI0SENYTUwiLCJqdGkiOiI2OGZlZDAxMzZmYzliMzVhNWEwNTFjMWMiLCJpc011bHRpQ2xpZW50IjpmYWxzZSwiaXNQbHVzUGxhbiI6dHJ1ZSwiaWF0IjoxNzYxNTI5ODc1LCJpc3MiOiJ1ZGFwaS1nYXRld2F5LXNlcnZpY2UiLCJleHAiOjE3NjE2MDI0MDB9.6mXcge1fLy4krGG_7RVq-uSh3WzsEI4DOH_RQf68xUs',\n",
       " 'extended_token': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.upstox.com/v2/login/authorization/token'\n",
    "\n",
    "headers = {\n",
    "    'accept':'application/json',\n",
    "    'Api-version':'2.0',\n",
    "    \n",
    "    'Content-Type':'application/x-www-form-urlencoded'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'code':code,\n",
    "    'client_id':apiKey,\n",
    "    'client_secret':secretKey,\n",
    "    'redirect_uri': 'https://127.0.0.1',\n",
    "    'grant_type':'authorization_code'\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=data)\n",
    "json_response = response.json()\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3a9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJ0eXAiOiJKV1QiLCJrZXlfaWQiOiJza192MS4wIiwiYWxnIjoiSFMyNTYifQ.eyJzdWIiOiI0SENYTUwiLCJqdGkiOiI2OGZlZDAxMzZmYzliMzVhNWEwNTFjMWMiLCJpc011bHRpQ2xpZW50IjpmYWxzZSwiaXNQbHVzUGxhbiI6dHJ1ZSwiaWF0IjoxNzYxNTI5ODc1LCJpc3MiOiJ1ZGFwaS1nYXRld2F5LXNlcnZpY2UiLCJleHAiOjE3NjE2MDI0MDB9.6mXcge1fLy4krGG_7RVq-uSh3WzsEI4DOH_RQf68xUs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_token = json_response['access_token']\n",
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d22f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trading_symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>instrument_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22900</th>\n",
       "      <td>INOXWIND</td>\n",
       "      <td>INOX WIND LIMITED</td>\n",
       "      <td>NSE_EQ|INE066P01011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trading_symbol               name       instrument_key\n",
       "22900       INOXWIND  INOX WIND LIMITED  NSE_EQ|INE066P01011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the gzipped JSON file\n",
    "url = 'https://assets.upstox.com/market-quote/instruments/exchange/NSE.json.gz'\n",
    "symboldf = pd.read_json(url, compression='gzip')\n",
    "\n",
    "# Example 4: Get specific columns for better readability\n",
    "columns_of_interest = ['trading_symbol', 'name', 'instrument_key']\n",
    "filtered_info = symboldf[symboldf['trading_symbol'] == 'INOXWIND'][columns_of_interest]\n",
    "display(filtered_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_request(method, url, headers=None, params=None, data=None):\n",
    "    response = None\n",
    "\n",
    "    try:\n",
    "        if method == 'GET':\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "        elif method == 'POST':\n",
    "            response = requests.post(url, headers=headers, params=params, json=data)\n",
    "        elif method == 'PUT':\n",
    "            response = requests.put(url, headers=headers, params=params, json=data)\n",
    "        else:\n",
    "            raise ValueError('Invalid HTTP method.')\n",
    "\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "           \n",
    "            return response.json()\n",
    "        else:\n",
    "            \n",
    "            return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: upstox-python-sdk in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (2.18.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (2.5.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (1.17.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (1.9.0)\n",
      "Requirement already satisfied: uuid in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (1.30)\n",
      "Requirement already satisfied: protobuf in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from upstox-python-sdk) (6.32.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install upstox-python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdcd193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fvg(data, lookback_period=20, body_multiplier=1.0):\n",
    "    \"\"\"\n",
    "    Detects Fair Value Gaps (FVGs) in historical price data.\n",
    "\n",
    "    Returns list aligned with `data` where each element is either None or\n",
    "    ('bullish'|'bearish', low, high, index) with low < high.\n",
    "    \"\"\"\n",
    "    import pandas as _pd\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    # normalize OHLC column names (accept common variants)\n",
    "    cols = {k.lower(): k for k in df.columns}\n",
    "    mapping = {}\n",
    "    for want in ('open','high','low','close'):\n",
    "        # exact or startswith match\n",
    "        found = next((c for c in df.columns if str(c).lower() == want), None)\n",
    "        if found is None:\n",
    "            found = next((c for c in df.columns if str(c).lower().startswith(want)), None)\n",
    "        if found is None:\n",
    "            raise ValueError(f\"detect_fvg requires columns for {want}. Available: {list(df.columns)}\")\n",
    "        mapping[want] = found\n",
    "\n",
    "    o = _pd.to_numeric(df[mapping['open']], errors='coerce')\n",
    "    h = _pd.to_numeric(df[mapping['high']], errors='coerce')\n",
    "    l = _pd.to_numeric(df[mapping['low']], errors='coerce')\n",
    "    c = _pd.to_numeric(df[mapping['close']], errors='coerce')\n",
    "\n",
    "    # prefill with None for alignment (first two candles cannot form pattern)\n",
    "    fvg_list = [None, None] + [None] * max(0, len(df) - 2)\n",
    "\n",
    "    for i in range(2, len(df)):\n",
    "        first_high = h.iloc[i-2]\n",
    "        first_low  = l.iloc[i-2]\n",
    "        middle_open  = o.iloc[i-1]\n",
    "        middle_close = c.iloc[i-1]\n",
    "        third_low  = l.iloc[i]\n",
    "        third_high = h.iloc[i]\n",
    "\n",
    "        prev_start = max(0, i-1-lookback_period)\n",
    "        prev_bodies = (c.iloc[prev_start:i-1] - o.iloc[prev_start:i-1]).abs()\n",
    "        avg_body_size = prev_bodies.mean() if not prev_bodies.empty else 0.0\n",
    "        if avg_body_size <= 0:\n",
    "            avg_body_size = 0.001\n",
    "\n",
    "        middle_body = abs(middle_close - middle_open)\n",
    "\n",
    "        # Bullish: gap upwards (third_low > first_high)\n",
    "        if (third_low > first_high) and (middle_body > avg_body_size * body_multiplier):\n",
    "            lowv = float(first_high)\n",
    "            highv = float(third_low)\n",
    "            fvg_list[i] = ('bullish', lowv, highv, i)\n",
    "\n",
    "        # Bearish: gap downwards (third_high < first_low)\n",
    "        elif (third_high < first_low) and (middle_body > avg_body_size * body_multiplier):\n",
    "            # ensure low < high in the tuple\n",
    "            lowv = float(third_high)\n",
    "            highv = float(first_low)\n",
    "            fvg_list[i] = ('bearish', lowv, highv, i)\n",
    "\n",
    "        else:\n",
    "            fvg_list[i] = None\n",
    "\n",
    "    return fvg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b4afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\parth1\\appdata\\roaming\\python\\python313\\site-packages (from jinja2) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# First install jinja2 (run this cell first)\n",
    "!pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2862f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey2 =  {\n",
    "    \"EUISTASBNK\":\"NSE_EQ|INE063P01018\",\n",
    "    \"AUBANK\":\"NSE_EQ|INE949L01017\",\n",
    "    \"CUB\":\"NSE_EQ|INE491A01021\",\n",
    "    \"KTKBANK\":\"NSE_EQ|INE491A01021\",\n",
    "    \"ICICIBANK\":\"NSE_EQ|INE090A01021\",\n",
    "    \"KARURVYSYA\":\"NSE_EQ|INE036D01028\",\n",
    "    \"INDUSINDBK\":\"NSE_EQ|INE095A01012\",\n",
    "    \"KOTAKBANK\":\"NSE_EQ|INE237A01028\",\n",
    "    \"HDFCBANK\":\"NSE_EQ|INE040A01034\",\n",
    "    \"AXISBANK\":\"NSE_EQ|INE238A01034\",\n",
    "    \"IDFCFIRSTB\":\"NSE_EQ|INE092T01019\",\n",
    "    \"FEDERALBNK\":\"NSE_EQ|INE171A01029\",\n",
    "    \"BANDHANBNK\":\"NSE_EQ|INE545U01014\",\n",
    "    \"SBIN\":\"NSE_EQ|INE062A01020\",\n",
    "    \"BANKBARODA\":\"NSE_EQ|INE028A01039\",\n",
    "    \"PNB\":\"NSE_EQ|INE160A01022\",\n",
    "    \"INDIANB\":\"NSE_EQ|INE562A01011\",\n",
    "    \"CANBK\":\"NSE_EQ|INE476A01022\",\n",
    "    \"IOB\":\"NSE_EQ|INE565A01014\",\n",
    "    \"GUJGASLTD\":\"NSE_EQ|INE844O01030\",\n",
    "    \"MGL\":\"NSE_EQ|INE002S01010\",\n",
    "    \"IGL\":\"NSE_EQ|INE203G01027\",\n",
    "    \"GAIL\":\"NSE_EQ|INE129A01019\",\n",
    "    \"PETRONET\":\"NSE_EQ|INE347G01014\",\n",
    "    \"BPCL\":\"NSE_EQ|INE029A01011\",\n",
    "    \"IOC\":\"NSE_EQ|INE242A01010\",\n",
    "    \"RELIANCE\":\"NSE_EQ|INE002A01018\",\n",
    "    \"HINDPETRO\":\"NSE_EQ|INE094A01015\",\n",
    "    \"GSPL\":\"NSE_EQ|INE246F01010\",\n",
    "    \"AEGISLOG\":\"NSE_EQ|INE208C01025\",\n",
    "    \"CASTROLIND\":\"NSE_EQ|INE172A01027\",\n",
    "    \"IEX\":\"NSE_EQ|INE022Q01020\",\n",
    "    \"OIL\":\"NSE_EQ|INE274J01014\",\n",
    "    \"ONGC\":\"NSE_EQ|INE213A01029\",\n",
    "    \"RECLTD\":\"NSE_EQ|INE020B01018\",\n",
    "    \"PFC\":\"NSE_EQ|INE134E01011\",\n",
    "    \"CGPOWER\":\"NSE_EQ|INE067A01029\",\n",
    "    \"HBLENGINE\":\"NSE_EQ|INE292B01021\",\n",
    "    \"CUMMINSIND\":\"NSE_EQ|INE298A01020\",\n",
    "    \"CESC\":\"NSE_EQ|INE486A01021\",\n",
    "    \"TATAPOWER\":\"NSE_EQ|INE245A01021\",\n",
    "    \"TORNTPOWER\":\"NSE_EQ|INE813H01021\",\n",
    "    \"POWERGRID\":\"NSE_EQ|INE752E01010\",\n",
    "    \"COALINDIA\":\"NSE_EQ|INE522F01014\",\n",
    "    \"NTPC\":\"NSE_EQ|INE733E01010\",\n",
    "    \"BHEL\":\"NSE_EQ|INE257A01026\",\n",
    "    \"JSWENERGY\":\"NSE_EQ|INE121E01018\",\n",
    "    \"ADANIGREEN\":\"NSE_EQ|INE364U01010\",\n",
    "    \"ADANIPOWER\":\"NSE_EQ|INE814H01029\",\n",
    "    \"ADANIENT\":\"NSE_EQ|INE423A01024\",\n",
    "    \"EIDPARRY\":\"NSE_EQ|INE126A01031\",\n",
    "    \"TRIVENI\":\"NSE_EQ|INE256C01024\",\n",
    "    \"PRAJIND\":\"NSE_EQ|INE074A01025\", \n",
    "    \"WAAREEENER\":\"NSE_EQ||INE377N01017\",\n",
    "    \"IREDA\":\"NSE_EQ|INE202E01016\", \n",
    "    \"INOXWIND\":\"NSE_EQ|INE066P01011\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b171c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EUISTASBNK...\n",
      "Fetching data for AUBANK...\n",
      "Fetching data for AUBANK...\n",
      "Fetching data for CUB...\n",
      "Fetching data for CUB...\n",
      "Fetching data for KTKBANK...\n",
      "Fetching data for KTKBANK...\n",
      "Fetching data for ICICIBANK...\n",
      "Fetching data for ICICIBANK...\n",
      "Fetching data for KARURVYSYA...\n",
      "Fetching data for KARURVYSYA...\n",
      "Fetching data for INDUSINDBK...\n",
      "Fetching data for INDUSINDBK...\n",
      "Fetching data for KOTAKBANK...\n",
      "Fetching data for KOTAKBANK...\n",
      "Fetching data for HDFCBANK...\n",
      "Fetching data for HDFCBANK...\n",
      "Fetching data for AXISBANK...\n",
      "Fetching data for AXISBANK...\n",
      "Fetching data for IDFCFIRSTB...\n",
      "Fetching data for IDFCFIRSTB...\n",
      "Fetching data for FEDERALBNK...\n",
      "Fetching data for FEDERALBNK...\n",
      "Fetching data for BANDHANBNK...\n",
      "Fetching data for BANDHANBNK...\n",
      "Fetching data for SBIN...\n",
      "Fetching data for SBIN...\n",
      "Fetching data for BANKBARODA...\n",
      "Fetching data for BANKBARODA...\n",
      "Fetching data for PNB...\n",
      "Fetching data for PNB...\n",
      "Fetching data for INDIANB...\n",
      "Fetching data for INDIANB...\n",
      "Fetching data for CANBK...\n",
      "Fetching data for CANBK...\n",
      "Fetching data for IOB...\n",
      "Fetching data for IOB...\n",
      "Fetching data for GUJGASLTD...\n",
      "Fetching data for GUJGASLTD...\n",
      "Fetching data for MGL...\n",
      "Fetching data for MGL...\n",
      "Fetching data for IGL...\n",
      "Fetching data for IGL...\n",
      "Fetching data for GAIL...\n",
      "Fetching data for GAIL...\n",
      "Fetching data for PETRONET...\n",
      "Fetching data for PETRONET...\n",
      "Fetching data for BPCL...\n",
      "Fetching data for BPCL...\n",
      "Fetching data for IOC...\n",
      "Fetching data for IOC...\n",
      "Fetching data for RELIANCE...\n",
      "Fetching data for RELIANCE...\n",
      "Fetching data for HINDPETRO...\n",
      "Fetching data for HINDPETRO...\n",
      "Fetching data for GSPL...\n",
      "Fetching data for GSPL...\n",
      "Fetching data for AEGISLOG...\n",
      "Fetching data for AEGISLOG...\n",
      "Fetching data for CASTROLIND...\n",
      "Fetching data for CASTROLIND...\n",
      "Fetching data for IEX...\n",
      "Fetching data for IEX...\n",
      "Fetching data for OIL...\n",
      "Fetching data for OIL...\n",
      "Fetching data for ONGC...\n",
      "Fetching data for ONGC...\n",
      "Fetching data for RECLTD...\n",
      "Fetching data for RECLTD...\n",
      "Fetching data for PFC...\n",
      "Fetching data for PFC...\n",
      "Fetching data for CGPOWER...\n",
      "Fetching data for CGPOWER...\n",
      "Fetching data for HBLENGINE...\n",
      "Fetching data for HBLENGINE...\n",
      "Fetching data for CUMMINSIND...\n",
      "Fetching data for CUMMINSIND...\n",
      "Fetching data for CESC...\n",
      "Fetching data for CESC...\n",
      "Fetching data for TATAPOWER...\n",
      "Fetching data for TATAPOWER...\n",
      "Fetching data for TORNTPOWER...\n",
      "Fetching data for TORNTPOWER...\n",
      "Fetching data for POWERGRID...\n",
      "Fetching data for POWERGRID...\n",
      "Fetching data for COALINDIA...\n",
      "Fetching data for COALINDIA...\n",
      "Fetching data for NTPC...\n",
      "Fetching data for NTPC...\n",
      "Fetching data for BHEL...\n",
      "Fetching data for BHEL...\n",
      "Fetching data for JSWENERGY...\n",
      "Fetching data for JSWENERGY...\n",
      "Fetching data for ADANIGREEN...\n",
      "Fetching data for ADANIGREEN...\n",
      "Fetching data for ADANIPOWER...\n",
      "Fetching data for ADANIPOWER...\n",
      "Fetching data for ADANIENT...\n",
      "Fetching data for ADANIENT...\n",
      "Fetching data for EIDPARRY...\n",
      "Fetching data for EIDPARRY...\n",
      "Fetching data for TRIVENI...\n",
      "Fetching data for TRIVENI...\n",
      "Fetching data for PRAJIND...\n",
      "Fetching data for PRAJIND...\n",
      "Fetching data for WAAREEENER...\n",
      "Fetching data for WAAREEENER...\n",
      "❌ API Error for WAAREEENER: 400\n",
      "❌ API Error for WAAREEENER: 400\n",
      "Fetching data for IREDA...\n",
      "Fetching data for IREDA...\n",
      "Fetching data for INOXWIND...\n",
      "Fetching data for INOXWIND...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>ADANIGREEN</th>\n",
       "      <th>ADANIPOWER</th>\n",
       "      <th>AEGISLOG</th>\n",
       "      <th>AUBANK</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BANDHANBNK</th>\n",
       "      <th>BANKBARODA</th>\n",
       "      <th>BHEL</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>...</th>\n",
       "      <th>PFC</th>\n",
       "      <th>PNB</th>\n",
       "      <th>POWERGRID</th>\n",
       "      <th>PRAJIND</th>\n",
       "      <th>RECLTD</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBIN</th>\n",
       "      <th>TATAPOWER</th>\n",
       "      <th>TORNTPOWER</th>\n",
       "      <th>TRIVENI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, ADANIENT), (Close, ADANIGREEN), (Close, ADANIPOWER), (Close, AEGISLOG), (Close, AUBANK), (Close, AXISBANK), (Close, BANDHANBNK), (Close, BANKBARODA), (Close, BHEL), (Close, BPCL), (Close, CANBK), (Close, CASTROLIND), (Close, CESC), (Close, CGPOWER), (Close, COALINDIA), (Close, CUB), (Close, CUMMINSIND), (Close, EIDPARRY), (Close, EUISTASBNK), (Close, FEDERALBNK), (Close, GAIL), (Close, GSPL), (Close, GUJGASLTD), (Close, HBLENGINE), (Close, HDFCBANK), (Close, HINDPETRO), (Close, ICICIBANK), (Close, IDFCFIRSTB), (Close, IEX), (Close, IGL), (Close, INDIANB), (Close, INDUSINDBK), (Close, INOXWIND), (Close, IOB), (Close, IOC), (Close, IREDA), (Close, JSWENERGY), (Close, KARURVYSYA), (Close, KOTAKBANK), (Close, KTKBANK), (Close, MGL), (Close, NTPC), (Close, OIL), (Close, ONGC), (Close, PETRONET), (Close, PFC), (Close, PNB), (Close, POWERGRID), (Close, PRAJIND), (Close, RECLTD), (Close, RELIANCE), (Close, SBIN), (Close, TATAPOWER), (Close, TORNTPOWER), (Close, TRIVENI), (High, ADANIENT), (High, ADANIGREEN), (High, ADANIPOWER), (High, AEGISLOG), (High, AUBANK), (High, AXISBANK), (High, BANDHANBNK), (High, BANKBARODA), (High, BHEL), (High, BPCL), (High, CANBK), (High, CASTROLIND), (High, CESC), (High, CGPOWER), (High, COALINDIA), (High, CUB), (High, CUMMINSIND), (High, EIDPARRY), (High, EUISTASBNK), (High, FEDERALBNK), (High, GAIL), (High, GSPL), (High, GUJGASLTD), (High, HBLENGINE), (High, HDFCBANK), (High, HINDPETRO), (High, ICICIBANK), (High, IDFCFIRSTB), (High, IEX), (High, IGL), (High, INDIANB), (High, INDUSINDBK), (High, INOXWIND), (High, IOB), (High, IOC), (High, IREDA), (High, JSWENERGY), (High, KARURVYSYA), (High, KOTAKBANK), (High, KTKBANK), (High, MGL), (High, NTPC), (High, OIL), (High, ONGC), (High, PETRONET), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>ADANIGREEN</th>\n",
       "      <th>ADANIPOWER</th>\n",
       "      <th>AEGISLOG</th>\n",
       "      <th>AUBANK</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BANDHANBNK</th>\n",
       "      <th>BANKBARODA</th>\n",
       "      <th>BHEL</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>...</th>\n",
       "      <th>PFC</th>\n",
       "      <th>PNB</th>\n",
       "      <th>POWERGRID</th>\n",
       "      <th>PRAJIND</th>\n",
       "      <th>RECLTD</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBIN</th>\n",
       "      <th>TATAPOWER</th>\n",
       "      <th>TORNTPOWER</th>\n",
       "      <th>TRIVENI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>2536.6</td>\n",
       "      <td>1116.7</td>\n",
       "      <td>161.93</td>\n",
       "      <td>770.00</td>\n",
       "      <td>880.00</td>\n",
       "      <td>1239.5</td>\n",
       "      <td>172.23</td>\n",
       "      <td>275.20</td>\n",
       "      <td>251.90</td>\n",
       "      <td>353.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2211222.0</td>\n",
       "      <td>4395891.0</td>\n",
       "      <td>1427442.0</td>\n",
       "      <td>235437.0</td>\n",
       "      <td>4327970.0</td>\n",
       "      <td>1124793.0</td>\n",
       "      <td>2642302.0</td>\n",
       "      <td>1548246.0</td>\n",
       "      <td>54843.0</td>\n",
       "      <td>31144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>161.44</td>\n",
       "      <td>771.50</td>\n",
       "      <td>881.05</td>\n",
       "      <td>1243.3</td>\n",
       "      <td>172.25</td>\n",
       "      <td>275.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>357.35</td>\n",
       "      <td>...</td>\n",
       "      <td>513227.0</td>\n",
       "      <td>1982430.0</td>\n",
       "      <td>1028205.0</td>\n",
       "      <td>75090.0</td>\n",
       "      <td>856943.0</td>\n",
       "      <td>955893.0</td>\n",
       "      <td>1289851.0</td>\n",
       "      <td>504452.0</td>\n",
       "      <td>18005.0</td>\n",
       "      <td>7226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>2529.2</td>\n",
       "      <td>1112.3</td>\n",
       "      <td>162.05</td>\n",
       "      <td>768.05</td>\n",
       "      <td>881.00</td>\n",
       "      <td>1242.7</td>\n",
       "      <td>172.19</td>\n",
       "      <td>271.95</td>\n",
       "      <td>257.09</td>\n",
       "      <td>358.25</td>\n",
       "      <td>...</td>\n",
       "      <td>475667.0</td>\n",
       "      <td>2292011.0</td>\n",
       "      <td>1611081.0</td>\n",
       "      <td>91321.0</td>\n",
       "      <td>841857.0</td>\n",
       "      <td>1759711.0</td>\n",
       "      <td>2210969.0</td>\n",
       "      <td>436775.0</td>\n",
       "      <td>12695.0</td>\n",
       "      <td>11307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>2527.1</td>\n",
       "      <td>1113.4</td>\n",
       "      <td>163.99</td>\n",
       "      <td>768.40</td>\n",
       "      <td>877.75</td>\n",
       "      <td>1245.9</td>\n",
       "      <td>170.72</td>\n",
       "      <td>273.90</td>\n",
       "      <td>257.39</td>\n",
       "      <td>357.35</td>\n",
       "      <td>...</td>\n",
       "      <td>329843.0</td>\n",
       "      <td>6551641.0</td>\n",
       "      <td>1764834.0</td>\n",
       "      <td>41130.0</td>\n",
       "      <td>725675.0</td>\n",
       "      <td>617377.0</td>\n",
       "      <td>1694702.0</td>\n",
       "      <td>256770.0</td>\n",
       "      <td>11601.0</td>\n",
       "      <td>9483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>2521.3</td>\n",
       "      <td>1111.6</td>\n",
       "      <td>161.95</td>\n",
       "      <td>767.45</td>\n",
       "      <td>875.25</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>171.29</td>\n",
       "      <td>272.55</td>\n",
       "      <td>259.78</td>\n",
       "      <td>357.50</td>\n",
       "      <td>...</td>\n",
       "      <td>363638.0</td>\n",
       "      <td>4330709.0</td>\n",
       "      <td>1180316.0</td>\n",
       "      <td>61593.0</td>\n",
       "      <td>861264.0</td>\n",
       "      <td>995380.0</td>\n",
       "      <td>1414927.0</td>\n",
       "      <td>263258.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>14295.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                        Close                                         \\\n",
       "Ticker                    ADANIENT ADANIGREEN ADANIPOWER AEGISLOG  AUBANK   \n",
       "Datetime                                                                    \n",
       "2025-10-30 09:15:00+05:30   2536.6     1116.7     161.93   770.00  880.00   \n",
       "2025-10-30 10:15:00+05:30   2545.0     1103.0     161.44   771.50  881.05   \n",
       "2025-10-30 11:15:00+05:30   2529.2     1112.3     162.05   768.05  881.00   \n",
       "2025-10-30 12:15:00+05:30   2527.1     1113.4     163.99   768.40  877.75   \n",
       "2025-10-30 13:15:00+05:30   2521.3     1111.6     161.95   767.45  875.25   \n",
       "\n",
       "Field                                                                     ...  \\\n",
       "Ticker                    AXISBANK BANDHANBNK BANKBARODA    BHEL    BPCL  ...   \n",
       "Datetime                                                                  ...   \n",
       "2025-10-30 09:15:00+05:30   1239.5     172.23     275.20  251.90  353.75  ...   \n",
       "2025-10-30 10:15:00+05:30   1243.3     172.25     275.00  255.00  357.35  ...   \n",
       "2025-10-30 11:15:00+05:30   1242.7     172.19     271.95  257.09  358.25  ...   \n",
       "2025-10-30 12:15:00+05:30   1245.9     170.72     273.90  257.39  357.35  ...   \n",
       "2025-10-30 13:15:00+05:30   1243.0     171.29     272.55  259.78  357.50  ...   \n",
       "\n",
       "Field                         Volume                                  \\\n",
       "Ticker                           PFC        PNB  POWERGRID   PRAJIND   \n",
       "Datetime                                                               \n",
       "2025-10-30 09:15:00+05:30  2211222.0  4395891.0  1427442.0  235437.0   \n",
       "2025-10-30 10:15:00+05:30   513227.0  1982430.0  1028205.0   75090.0   \n",
       "2025-10-30 11:15:00+05:30   475667.0  2292011.0  1611081.0   91321.0   \n",
       "2025-10-30 12:15:00+05:30   329843.0  6551641.0  1764834.0   41130.0   \n",
       "2025-10-30 13:15:00+05:30   363638.0  4330709.0  1180316.0   61593.0   \n",
       "\n",
       "Field                                                                  \\\n",
       "Ticker                        RECLTD   RELIANCE       SBIN  TATAPOWER   \n",
       "Datetime                                                                \n",
       "2025-10-30 09:15:00+05:30  4327970.0  1124793.0  2642302.0  1548246.0   \n",
       "2025-10-30 10:15:00+05:30   856943.0   955893.0  1289851.0   504452.0   \n",
       "2025-10-30 11:15:00+05:30   841857.0  1759711.0  2210969.0   436775.0   \n",
       "2025-10-30 12:15:00+05:30   725675.0   617377.0  1694702.0   256770.0   \n",
       "2025-10-30 13:15:00+05:30   861264.0   995380.0  1414927.0   263258.0   \n",
       "\n",
       "Field                                          \n",
       "Ticker                    TORNTPOWER  TRIVENI  \n",
       "Datetime                                       \n",
       "2025-10-30 09:15:00+05:30    54843.0  31144.0  \n",
       "2025-10-30 10:15:00+05:30    18005.0   7226.0  \n",
       "2025-10-30 11:15:00+05:30    12695.0  11307.0  \n",
       "2025-10-30 12:15:00+05:30    11601.0   9483.0  \n",
       "2025-10-30 13:15:00+05:30     8644.0  14295.0  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intrday data for instrument key 2 \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS2 = instrumentkey2\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS2.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "\n",
    "    \n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index2 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index2\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ae44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>ADANIGREEN</th>\n",
       "      <th>ADANIPOWER</th>\n",
       "      <th>AEGISLOG</th>\n",
       "      <th>AUBANK</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BANDHANBNK</th>\n",
       "      <th>BANKBARODA</th>\n",
       "      <th>BHEL</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>...</th>\n",
       "      <th>PFC</th>\n",
       "      <th>PNB</th>\n",
       "      <th>POWERGRID</th>\n",
       "      <th>PRAJIND</th>\n",
       "      <th>RECLTD</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBIN</th>\n",
       "      <th>TATAPOWER</th>\n",
       "      <th>TORNTPOWER</th>\n",
       "      <th>TRIVENI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>2532.3</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>162.15</td>\n",
       "      <td>784.45</td>\n",
       "      <td>882.6</td>\n",
       "      <td>1249.5</td>\n",
       "      <td>172.11</td>\n",
       "      <td>274.4</td>\n",
       "      <td>244.90</td>\n",
       "      <td>347.65</td>\n",
       "      <td>...</td>\n",
       "      <td>919553.0</td>\n",
       "      <td>1917148.0</td>\n",
       "      <td>2725429.0</td>\n",
       "      <td>174048.0</td>\n",
       "      <td>2046976.0</td>\n",
       "      <td>2137758.0</td>\n",
       "      <td>2402740.0</td>\n",
       "      <td>1075089.0</td>\n",
       "      <td>47097.0</td>\n",
       "      <td>26396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>2553.5</td>\n",
       "      <td>1115.3</td>\n",
       "      <td>162.00</td>\n",
       "      <td>785.05</td>\n",
       "      <td>883.2</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>172.40</td>\n",
       "      <td>274.2</td>\n",
       "      <td>246.13</td>\n",
       "      <td>348.55</td>\n",
       "      <td>...</td>\n",
       "      <td>1685516.0</td>\n",
       "      <td>1385728.0</td>\n",
       "      <td>1348137.0</td>\n",
       "      <td>64186.0</td>\n",
       "      <td>1885190.0</td>\n",
       "      <td>492604.0</td>\n",
       "      <td>925145.0</td>\n",
       "      <td>1115101.0</td>\n",
       "      <td>33635.0</td>\n",
       "      <td>24277.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                        Close                                        \\\n",
       "Ticker                    ADANIENT ADANIGREEN ADANIPOWER AEGISLOG AUBANK   \n",
       "Datetime                                                                   \n",
       "2025-10-29 14:15:00+05:30   2532.3     1115.0     162.15   784.45  882.6   \n",
       "2025-10-29 15:15:00+05:30   2553.5     1115.3     162.00   785.05  883.2   \n",
       "\n",
       "Field                                                                     ...  \\\n",
       "Ticker                    AXISBANK BANDHANBNK BANKBARODA    BHEL    BPCL  ...   \n",
       "Datetime                                                                  ...   \n",
       "2025-10-29 14:15:00+05:30   1249.5     172.11      274.4  244.90  347.65  ...   \n",
       "2025-10-29 15:15:00+05:30   1249.0     172.40      274.2  246.13  348.55  ...   \n",
       "\n",
       "Field                         Volume                                  \\\n",
       "Ticker                           PFC        PNB  POWERGRID   PRAJIND   \n",
       "Datetime                                                               \n",
       "2025-10-29 14:15:00+05:30   919553.0  1917148.0  2725429.0  174048.0   \n",
       "2025-10-29 15:15:00+05:30  1685516.0  1385728.0  1348137.0   64186.0   \n",
       "\n",
       "Field                                                                  \\\n",
       "Ticker                        RECLTD   RELIANCE       SBIN  TATAPOWER   \n",
       "Datetime                                                                \n",
       "2025-10-29 14:15:00+05:30  2046976.0  2137758.0  2402740.0  1075089.0   \n",
       "2025-10-29 15:15:00+05:30  1885190.0   492604.0   925145.0  1115101.0   \n",
       "\n",
       "Field                                          \n",
       "Ticker                    TORNTPOWER  TRIVENI  \n",
       "Datetime                                       \n",
       "2025-10-29 14:15:00+05:30    47097.0  26396.0  \n",
       "2025-10-29 15:15:00+05:30    33635.0  24277.0  \n",
       "\n",
       "[2 rows x 265 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import historical data for instrument key 2 \n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik2.pkl\")\n",
    "\n",
    "df = pd.read_pickle(pkl_path)  # preserves MultiIndex, dtypes, timezone\n",
    "\n",
    "# Optional: sanity checks\n",
    "assert isinstance(df, pd.DataFrame)\n",
    "print(df.index.names)     # e.g., ['Datetime']\n",
    "print(df.columns.names)   # e.g., ['Field', 'Ticker']\n",
    "\n",
    "# Show like your earlier output (Jupyter renders MultiIndex headers)\n",
    "display(df)\n",
    "\n",
    "# If you want a concise sample similar to your 2-row view:\n",
    "# display(df.loc[\"2025-10-10 14:15:00+05:30\":\"2025-10-10 15:15:00+05:30\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5085761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 275)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>ADANIGREEN</th>\n",
       "      <th>ADANIPOWER</th>\n",
       "      <th>AEGISLOG</th>\n",
       "      <th>AUBANK</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BANDHANBNK</th>\n",
       "      <th>BANKBARODA</th>\n",
       "      <th>BHEL</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>...</th>\n",
       "      <th>PFC</th>\n",
       "      <th>PNB</th>\n",
       "      <th>POWERGRID</th>\n",
       "      <th>PRAJIND</th>\n",
       "      <th>RECLTD</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBIN</th>\n",
       "      <th>TATAPOWER</th>\n",
       "      <th>TORNTPOWER</th>\n",
       "      <th>TRIVENI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>2532.3</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>162.15</td>\n",
       "      <td>784.45</td>\n",
       "      <td>882.60</td>\n",
       "      <td>1249.5</td>\n",
       "      <td>172.11</td>\n",
       "      <td>274.40</td>\n",
       "      <td>244.90</td>\n",
       "      <td>347.65</td>\n",
       "      <td>...</td>\n",
       "      <td>919553.0</td>\n",
       "      <td>1917148.0</td>\n",
       "      <td>2725429.0</td>\n",
       "      <td>174048.0</td>\n",
       "      <td>2046976.0</td>\n",
       "      <td>2137758.0</td>\n",
       "      <td>2402740.0</td>\n",
       "      <td>1075089.0</td>\n",
       "      <td>47097.0</td>\n",
       "      <td>26396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>2553.5</td>\n",
       "      <td>1115.3</td>\n",
       "      <td>162.00</td>\n",
       "      <td>785.05</td>\n",
       "      <td>883.20</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>172.40</td>\n",
       "      <td>274.20</td>\n",
       "      <td>246.13</td>\n",
       "      <td>348.55</td>\n",
       "      <td>...</td>\n",
       "      <td>1685516.0</td>\n",
       "      <td>1385728.0</td>\n",
       "      <td>1348137.0</td>\n",
       "      <td>64186.0</td>\n",
       "      <td>1885190.0</td>\n",
       "      <td>492604.0</td>\n",
       "      <td>925145.0</td>\n",
       "      <td>1115101.0</td>\n",
       "      <td>33635.0</td>\n",
       "      <td>24277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>2536.6</td>\n",
       "      <td>1116.7</td>\n",
       "      <td>161.93</td>\n",
       "      <td>770.00</td>\n",
       "      <td>880.00</td>\n",
       "      <td>1239.5</td>\n",
       "      <td>172.23</td>\n",
       "      <td>275.20</td>\n",
       "      <td>251.90</td>\n",
       "      <td>353.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2211222.0</td>\n",
       "      <td>4395891.0</td>\n",
       "      <td>1427442.0</td>\n",
       "      <td>235437.0</td>\n",
       "      <td>4327970.0</td>\n",
       "      <td>1124793.0</td>\n",
       "      <td>2642302.0</td>\n",
       "      <td>1548246.0</td>\n",
       "      <td>54843.0</td>\n",
       "      <td>31144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>161.44</td>\n",
       "      <td>771.50</td>\n",
       "      <td>881.05</td>\n",
       "      <td>1243.3</td>\n",
       "      <td>172.25</td>\n",
       "      <td>275.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>357.35</td>\n",
       "      <td>...</td>\n",
       "      <td>513227.0</td>\n",
       "      <td>1982430.0</td>\n",
       "      <td>1028205.0</td>\n",
       "      <td>75090.0</td>\n",
       "      <td>856943.0</td>\n",
       "      <td>955893.0</td>\n",
       "      <td>1289851.0</td>\n",
       "      <td>504452.0</td>\n",
       "      <td>18005.0</td>\n",
       "      <td>7226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>2529.2</td>\n",
       "      <td>1112.3</td>\n",
       "      <td>162.05</td>\n",
       "      <td>768.05</td>\n",
       "      <td>881.00</td>\n",
       "      <td>1242.7</td>\n",
       "      <td>172.19</td>\n",
       "      <td>271.95</td>\n",
       "      <td>257.09</td>\n",
       "      <td>358.25</td>\n",
       "      <td>...</td>\n",
       "      <td>475667.0</td>\n",
       "      <td>2292011.0</td>\n",
       "      <td>1611081.0</td>\n",
       "      <td>91321.0</td>\n",
       "      <td>841857.0</td>\n",
       "      <td>1759711.0</td>\n",
       "      <td>2210969.0</td>\n",
       "      <td>436775.0</td>\n",
       "      <td>12695.0</td>\n",
       "      <td>11307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>2527.1</td>\n",
       "      <td>1113.4</td>\n",
       "      <td>163.99</td>\n",
       "      <td>768.40</td>\n",
       "      <td>877.75</td>\n",
       "      <td>1245.9</td>\n",
       "      <td>170.72</td>\n",
       "      <td>273.90</td>\n",
       "      <td>257.39</td>\n",
       "      <td>357.35</td>\n",
       "      <td>...</td>\n",
       "      <td>329843.0</td>\n",
       "      <td>6551641.0</td>\n",
       "      <td>1764834.0</td>\n",
       "      <td>41130.0</td>\n",
       "      <td>725675.0</td>\n",
       "      <td>617377.0</td>\n",
       "      <td>1694702.0</td>\n",
       "      <td>256770.0</td>\n",
       "      <td>11601.0</td>\n",
       "      <td>9483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>2521.3</td>\n",
       "      <td>1111.6</td>\n",
       "      <td>161.95</td>\n",
       "      <td>767.45</td>\n",
       "      <td>875.25</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>171.29</td>\n",
       "      <td>272.55</td>\n",
       "      <td>259.78</td>\n",
       "      <td>357.50</td>\n",
       "      <td>...</td>\n",
       "      <td>363638.0</td>\n",
       "      <td>4330709.0</td>\n",
       "      <td>1180316.0</td>\n",
       "      <td>61593.0</td>\n",
       "      <td>861264.0</td>\n",
       "      <td>995380.0</td>\n",
       "      <td>1414927.0</td>\n",
       "      <td>263258.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>14295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>2524.5</td>\n",
       "      <td>1141.6</td>\n",
       "      <td>162.53</td>\n",
       "      <td>770.70</td>\n",
       "      <td>879.00</td>\n",
       "      <td>1238.4</td>\n",
       "      <td>170.76</td>\n",
       "      <td>272.90</td>\n",
       "      <td>260.70</td>\n",
       "      <td>357.50</td>\n",
       "      <td>...</td>\n",
       "      <td>869081.0</td>\n",
       "      <td>2108631.0</td>\n",
       "      <td>2315162.0</td>\n",
       "      <td>84787.0</td>\n",
       "      <td>1177366.0</td>\n",
       "      <td>3194165.0</td>\n",
       "      <td>2824659.0</td>\n",
       "      <td>504623.0</td>\n",
       "      <td>46135.0</td>\n",
       "      <td>14285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>2528.8</td>\n",
       "      <td>1145.5</td>\n",
       "      <td>162.22</td>\n",
       "      <td>768.50</td>\n",
       "      <td>876.20</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>169.64</td>\n",
       "      <td>272.10</td>\n",
       "      <td>261.90</td>\n",
       "      <td>358.10</td>\n",
       "      <td>...</td>\n",
       "      <td>548244.0</td>\n",
       "      <td>1444730.0</td>\n",
       "      <td>1002371.0</td>\n",
       "      <td>56606.0</td>\n",
       "      <td>684996.0</td>\n",
       "      <td>669143.0</td>\n",
       "      <td>966233.0</td>\n",
       "      <td>267724.0</td>\n",
       "      <td>20453.0</td>\n",
       "      <td>10266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                        Close                                         \\\n",
       "Ticker                    ADANIENT ADANIGREEN ADANIPOWER AEGISLOG  AUBANK   \n",
       "Datetime                                                                    \n",
       "2025-10-29 14:15:00+05:30   2532.3     1115.0     162.15   784.45  882.60   \n",
       "2025-10-29 15:15:00+05:30   2553.5     1115.3     162.00   785.05  883.20   \n",
       "2025-10-30 09:15:00+05:30   2536.6     1116.7     161.93   770.00  880.00   \n",
       "2025-10-30 10:15:00+05:30   2545.0     1103.0     161.44   771.50  881.05   \n",
       "2025-10-30 11:15:00+05:30   2529.2     1112.3     162.05   768.05  881.00   \n",
       "2025-10-30 12:15:00+05:30   2527.1     1113.4     163.99   768.40  877.75   \n",
       "2025-10-30 13:15:00+05:30   2521.3     1111.6     161.95   767.45  875.25   \n",
       "2025-10-30 14:15:00+05:30   2524.5     1141.6     162.53   770.70  879.00   \n",
       "2025-10-30 15:15:00+05:30   2528.8     1145.5     162.22   768.50  876.20   \n",
       "\n",
       "Field                                                                     ...  \\\n",
       "Ticker                    AXISBANK BANDHANBNK BANKBARODA    BHEL    BPCL  ...   \n",
       "Datetime                                                                  ...   \n",
       "2025-10-29 14:15:00+05:30   1249.5     172.11     274.40  244.90  347.65  ...   \n",
       "2025-10-29 15:15:00+05:30   1249.0     172.40     274.20  246.13  348.55  ...   \n",
       "2025-10-30 09:15:00+05:30   1239.5     172.23     275.20  251.90  353.75  ...   \n",
       "2025-10-30 10:15:00+05:30   1243.3     172.25     275.00  255.00  357.35  ...   \n",
       "2025-10-30 11:15:00+05:30   1242.7     172.19     271.95  257.09  358.25  ...   \n",
       "2025-10-30 12:15:00+05:30   1245.9     170.72     273.90  257.39  357.35  ...   \n",
       "2025-10-30 13:15:00+05:30   1243.0     171.29     272.55  259.78  357.50  ...   \n",
       "2025-10-30 14:15:00+05:30   1238.4     170.76     272.90  260.70  357.50  ...   \n",
       "2025-10-30 15:15:00+05:30   1241.0     169.64     272.10  261.90  358.10  ...   \n",
       "\n",
       "Field                         Volume                                  \\\n",
       "Ticker                           PFC        PNB  POWERGRID   PRAJIND   \n",
       "Datetime                                                               \n",
       "2025-10-29 14:15:00+05:30   919553.0  1917148.0  2725429.0  174048.0   \n",
       "2025-10-29 15:15:00+05:30  1685516.0  1385728.0  1348137.0   64186.0   \n",
       "2025-10-30 09:15:00+05:30  2211222.0  4395891.0  1427442.0  235437.0   \n",
       "2025-10-30 10:15:00+05:30   513227.0  1982430.0  1028205.0   75090.0   \n",
       "2025-10-30 11:15:00+05:30   475667.0  2292011.0  1611081.0   91321.0   \n",
       "2025-10-30 12:15:00+05:30   329843.0  6551641.0  1764834.0   41130.0   \n",
       "2025-10-30 13:15:00+05:30   363638.0  4330709.0  1180316.0   61593.0   \n",
       "2025-10-30 14:15:00+05:30   869081.0  2108631.0  2315162.0   84787.0   \n",
       "2025-10-30 15:15:00+05:30   548244.0  1444730.0  1002371.0   56606.0   \n",
       "\n",
       "Field                                                                  \\\n",
       "Ticker                        RECLTD   RELIANCE       SBIN  TATAPOWER   \n",
       "Datetime                                                                \n",
       "2025-10-29 14:15:00+05:30  2046976.0  2137758.0  2402740.0  1075089.0   \n",
       "2025-10-29 15:15:00+05:30  1885190.0   492604.0   925145.0  1115101.0   \n",
       "2025-10-30 09:15:00+05:30  4327970.0  1124793.0  2642302.0  1548246.0   \n",
       "2025-10-30 10:15:00+05:30   856943.0   955893.0  1289851.0   504452.0   \n",
       "2025-10-30 11:15:00+05:30   841857.0  1759711.0  2210969.0   436775.0   \n",
       "2025-10-30 12:15:00+05:30   725675.0   617377.0  1694702.0   256770.0   \n",
       "2025-10-30 13:15:00+05:30   861264.0   995380.0  1414927.0   263258.0   \n",
       "2025-10-30 14:15:00+05:30  1177366.0  3194165.0  2824659.0   504623.0   \n",
       "2025-10-30 15:15:00+05:30   684996.0   669143.0   966233.0   267724.0   \n",
       "\n",
       "Field                                          \n",
       "Ticker                    TORNTPOWER  TRIVENI  \n",
       "Datetime                                       \n",
       "2025-10-29 14:15:00+05:30    47097.0  26396.0  \n",
       "2025-10-29 15:15:00+05:30    33635.0  24277.0  \n",
       "2025-10-30 09:15:00+05:30    54843.0  31144.0  \n",
       "2025-10-30 10:15:00+05:30    18005.0   7226.0  \n",
       "2025-10-30 11:15:00+05:30    12695.0  11307.0  \n",
       "2025-10-30 12:15:00+05:30    11601.0   9483.0  \n",
       "2025-10-30 13:15:00+05:30     8644.0  14295.0  \n",
       "2025-10-30 14:15:00+05:30    46135.0  14285.0  \n",
       "2025-10-30 15:15:00+05:30    20453.0  10266.0  \n",
       "\n",
       "[9 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Historical and intrday data combiner \n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik2.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index2  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df2 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df2 = combined_df2[~combined_df2.index.duplicated(keep=\"last\")]\n",
    "\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df2.shape)\n",
    "print(combined_df2.index.names)\n",
    "print(combined_df2.columns.names)\n",
    "display(combined_df2.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfc8bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing WAAREEENER: ('Open', 'WAAREEENER')\n",
      "\n",
      "FVG detection results saved to: C:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik2(30-10).pkl\n",
      "Master results updated at: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 2 (Banks, Oil & Gas, Power, etc.) (date: 2025-10-30):\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 15:15 ADANIGREEN 🟢 bullish 26.20 1114.80 - 1141.00 No previous FVGs\n",
      "2025-10-30 10:15   AEGISLOG 🔴 bearish  9.50   774.50 - 784.00 No previous FVGs\n",
      "2025-10-30 13:15     AUBANK 🔴 bearish  1.85   878.20 - 880.05 No previous FVGs\n",
      "2025-10-30 15:15   AXISBANK 🔴 bearish  0.70 1241.00 - 1241.70 No previous FVGs\n",
      "2025-10-30 10:15   AXISBANK 🔴 bearish  2.90 1243.70 - 1246.60 No previous FVGs\n",
      "2025-10-30 14:15       BHEL 🟢 bullish  0.89   258.45 - 259.34 No previous FVGs\n",
      "2025-10-30 12:15       BHEL 🟢 bullish  0.81   255.49 - 256.30 No previous FVGs\n",
      "2025-10-30 11:15       BHEL 🟢 bullish  0.27   254.65 - 254.92 No previous FVGs\n",
      "2025-10-30 10:15       BHEL 🟢 bullish  3.30   246.70 - 250.00 No previous FVGs\n",
      "2025-10-30 11:15       BPCL 🟢 bullish  2.80   353.85 - 356.65 No previous FVGs\n",
      "2025-10-30 10:15       BPCL 🟢 bullish  4.25   348.85 - 353.10 No previous FVGs\n",
      "2025-10-30 13:15      CANBK 🟢 bullish  2.62   129.49 - 132.11 No previous FVGs\n",
      "2025-10-30 15:15 CASTROLIND 🔴 bearish  0.26   196.75 - 197.01 No previous FVGs\n",
      "2025-10-30 10:15       CESC 🔴 bearish  1.41   179.90 - 181.31 No previous FVGs\n",
      "2025-10-30 10:15    CGPOWER 🔴 bearish  8.75   739.95 - 748.70 No previous FVGs\n",
      "2025-10-30 14:15  COALINDIA 🟢 bullish  0.45   386.25 - 386.70 No previous FVGs\n",
      "2025-10-30 10:15  COALINDIA 🟢 bullish  1.55   382.95 - 384.50 No previous FVGs\n",
      "2025-10-30 13:15        CUB 🟢 bullish  1.01   233.20 - 234.21 No previous FVGs\n",
      "2025-10-30 10:15        CUB 🔴 bearish  1.56   233.45 - 235.01 No previous FVGs\n",
      "2025-10-30 13:15 CUMMINSIND 🟢 bullish 12.60 4357.40 - 4370.00 No previous FVGs\n",
      "2025-10-30 10:15   EIDPARRY 🔴 bearish  1.30 1085.70 - 1087.00 No previous FVGs\n",
      "2025-10-30 10:15 EUISTASBNK 🔴 bearish  0.35     59.63 - 59.98 No previous FVGs\n",
      "2025-10-30 10:15       GAIL 🔴 bearish  0.34   183.99 - 184.33 No previous FVGs\n",
      "2025-10-30 10:15       GSPL 🔴 bearish  1.80   311.20 - 313.00 No previous FVGs\n",
      "2025-10-30 15:15  GUJGASLTD 🟢 bullish  1.90   409.10 - 411.00 No previous FVGs\n",
      "2025-10-30 15:15   HDFCBANK 🔴 bearish  0.40  999.95 - 1000.35 No previous FVGs\n",
      "2025-10-30 10:15  HINDPETRO 🟢 bullish  0.25   470.90 - 471.15 No previous FVGs\n",
      "2025-10-30 15:15  ICICIBANK 🔴 bearish  1.50 1362.70 - 1364.20 No previous FVGs\n",
      "2025-10-30 10:15  ICICIBANK 🔴 bearish  2.80 1366.80 - 1369.60 No previous FVGs\n",
      "2025-10-30 15:15 IDFCFIRSTB 🟢 bullish  0.04     78.76 - 78.80 No previous FVGs\n",
      "2025-10-30 10:15 IDFCFIRSTB 🔴 bearish  0.06     79.11 - 79.17 No previous FVGs\n",
      "2025-10-30 13:15        IEX 🔴 bearish  0.71   144.94 - 145.65 No previous FVGs\n",
      "2025-10-30 12:15        IEX 🔴 bearish  0.43   145.88 - 146.31 No previous FVGs\n",
      "2025-10-30 10:15        IEX 🔴 bearish  0.87   147.44 - 148.31 No previous FVGs\n",
      "2025-10-30 15:15        IGL 🟢 bullish  0.42   211.10 - 211.52 No previous FVGs\n",
      "2025-10-30 10:15        IGL 🔴 bearish  0.20   210.80 - 211.00 No previous FVGs\n",
      "2025-10-30 14:15 INDUSINDBK 🔴 bearish  1.25   800.95 - 802.20 No previous FVGs\n",
      "2025-10-30 10:15        IOB 🔴 bearish  0.28     40.14 - 40.42 No previous FVGs\n",
      "2025-10-30 13:15        IOC 🔴 bearish  1.13   163.76 - 164.89 No previous FVGs\n",
      "2025-10-30 10:15        IOC 🟢 bullish  1.42   163.38 - 164.80 No previous FVGs\n",
      "2025-10-30 15:15 KARURVYSYA 🔴 bearish  1.38   245.00 - 246.38 No previous FVGs\n",
      "2025-10-30 10:15  KOTAKBANK 🔴 bearish  7.00 2142.80 - 2149.80 No previous FVGs\n",
      "2025-10-30 13:15    KTKBANK 🟢 bullish  1.01   233.20 - 234.21 No previous FVGs\n",
      "2025-10-30 10:15    KTKBANK 🔴 bearish  1.56   233.45 - 235.01 No previous FVGs\n",
      "2025-10-30 10:15        MGL 🔴 bearish 20.50 1273.80 - 1294.30 No previous FVGs\n",
      "2025-10-30 10:15        OIL 🟢 bullish  6.60   421.95 - 428.55 No previous FVGs\n",
      "2025-10-30 10:15   PETRONET 🔴 bearish  0.40   282.80 - 283.20 No previous FVGs\n",
      "2025-10-30 14:15        PNB 🔴 bearish  0.17   120.28 - 120.45 No previous FVGs\n",
      "2025-10-30 10:15  POWERGRID 🔴 bearish  2.00   292.80 - 294.80 No previous FVGs\n",
      "2025-10-30 10:15     RECLTD 🔴 bearish  1.90   381.90 - 383.80 No previous FVGs\n",
      "2025-10-30 14:15   RELIANCE 🔴 bearish  1.20 1491.50 - 1492.70 No previous FVGs\n",
      "2025-10-30 10:15   RELIANCE 🔴 bearish  4.80 1498.30 - 1503.10 No previous FVGs\n",
      "2025-10-30 15:15       SBIN 🔴 bearish  0.35   934.50 - 934.85 No previous FVGs\n",
      "2025-10-30 14:15       SBIN 🔴 bearish  0.60   938.35 - 938.95 No previous FVGs\n",
      "2025-10-30 15:15 TORNTPOWER 🟢 bullish  0.20 1312.40 - 1312.60 No previous FVGs\n",
      "2025-10-30 11:15 TORNTPOWER 🔴 bearish  0.10 1309.90 - 1310.00 No previous FVGs\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 15:15 ADANIGREEN 🟢 bullish 26.20 1114.80 - 1141.00 No previous FVGs\n",
      "2025-10-30 10:15   AEGISLOG 🔴 bearish  9.50   774.50 - 784.00 No previous FVGs\n",
      "2025-10-30 13:15     AUBANK 🔴 bearish  1.85   878.20 - 880.05 No previous FVGs\n",
      "2025-10-30 15:15   AXISBANK 🔴 bearish  0.70 1241.00 - 1241.70 No previous FVGs\n",
      "2025-10-30 10:15   AXISBANK 🔴 bearish  2.90 1243.70 - 1246.60 No previous FVGs\n",
      "2025-10-30 14:15       BHEL 🟢 bullish  0.89   258.45 - 259.34 No previous FVGs\n",
      "2025-10-30 12:15       BHEL 🟢 bullish  0.81   255.49 - 256.30 No previous FVGs\n",
      "2025-10-30 11:15       BHEL 🟢 bullish  0.27   254.65 - 254.92 No previous FVGs\n",
      "2025-10-30 10:15       BHEL 🟢 bullish  3.30   246.70 - 250.00 No previous FVGs\n",
      "2025-10-30 11:15       BPCL 🟢 bullish  2.80   353.85 - 356.65 No previous FVGs\n",
      "2025-10-30 10:15       BPCL 🟢 bullish  4.25   348.85 - 353.10 No previous FVGs\n",
      "2025-10-30 13:15      CANBK 🟢 bullish  2.62   129.49 - 132.11 No previous FVGs\n",
      "2025-10-30 15:15 CASTROLIND 🔴 bearish  0.26   196.75 - 197.01 No previous FVGs\n",
      "2025-10-30 10:15       CESC 🔴 bearish  1.41   179.90 - 181.31 No previous FVGs\n",
      "2025-10-30 10:15    CGPOWER 🔴 bearish  8.75   739.95 - 748.70 No previous FVGs\n",
      "2025-10-30 14:15  COALINDIA 🟢 bullish  0.45   386.25 - 386.70 No previous FVGs\n",
      "2025-10-30 10:15  COALINDIA 🟢 bullish  1.55   382.95 - 384.50 No previous FVGs\n",
      "2025-10-30 13:15        CUB 🟢 bullish  1.01   233.20 - 234.21 No previous FVGs\n",
      "2025-10-30 10:15        CUB 🔴 bearish  1.56   233.45 - 235.01 No previous FVGs\n",
      "2025-10-30 13:15 CUMMINSIND 🟢 bullish 12.60 4357.40 - 4370.00 No previous FVGs\n",
      "2025-10-30 10:15   EIDPARRY 🔴 bearish  1.30 1085.70 - 1087.00 No previous FVGs\n",
      "2025-10-30 10:15 EUISTASBNK 🔴 bearish  0.35     59.63 - 59.98 No previous FVGs\n",
      "2025-10-30 10:15       GAIL 🔴 bearish  0.34   183.99 - 184.33 No previous FVGs\n",
      "2025-10-30 10:15       GSPL 🔴 bearish  1.80   311.20 - 313.00 No previous FVGs\n",
      "2025-10-30 15:15  GUJGASLTD 🟢 bullish  1.90   409.10 - 411.00 No previous FVGs\n",
      "2025-10-30 15:15   HDFCBANK 🔴 bearish  0.40  999.95 - 1000.35 No previous FVGs\n",
      "2025-10-30 10:15  HINDPETRO 🟢 bullish  0.25   470.90 - 471.15 No previous FVGs\n",
      "2025-10-30 15:15  ICICIBANK 🔴 bearish  1.50 1362.70 - 1364.20 No previous FVGs\n",
      "2025-10-30 10:15  ICICIBANK 🔴 bearish  2.80 1366.80 - 1369.60 No previous FVGs\n",
      "2025-10-30 15:15 IDFCFIRSTB 🟢 bullish  0.04     78.76 - 78.80 No previous FVGs\n",
      "2025-10-30 10:15 IDFCFIRSTB 🔴 bearish  0.06     79.11 - 79.17 No previous FVGs\n",
      "2025-10-30 13:15        IEX 🔴 bearish  0.71   144.94 - 145.65 No previous FVGs\n",
      "2025-10-30 12:15        IEX 🔴 bearish  0.43   145.88 - 146.31 No previous FVGs\n",
      "2025-10-30 10:15        IEX 🔴 bearish  0.87   147.44 - 148.31 No previous FVGs\n",
      "2025-10-30 15:15        IGL 🟢 bullish  0.42   211.10 - 211.52 No previous FVGs\n",
      "2025-10-30 10:15        IGL 🔴 bearish  0.20   210.80 - 211.00 No previous FVGs\n",
      "2025-10-30 14:15 INDUSINDBK 🔴 bearish  1.25   800.95 - 802.20 No previous FVGs\n",
      "2025-10-30 10:15        IOB 🔴 bearish  0.28     40.14 - 40.42 No previous FVGs\n",
      "2025-10-30 13:15        IOC 🔴 bearish  1.13   163.76 - 164.89 No previous FVGs\n",
      "2025-10-30 10:15        IOC 🟢 bullish  1.42   163.38 - 164.80 No previous FVGs\n",
      "2025-10-30 15:15 KARURVYSYA 🔴 bearish  1.38   245.00 - 246.38 No previous FVGs\n",
      "2025-10-30 10:15  KOTAKBANK 🔴 bearish  7.00 2142.80 - 2149.80 No previous FVGs\n",
      "2025-10-30 13:15    KTKBANK 🟢 bullish  1.01   233.20 - 234.21 No previous FVGs\n",
      "2025-10-30 10:15    KTKBANK 🔴 bearish  1.56   233.45 - 235.01 No previous FVGs\n",
      "2025-10-30 10:15        MGL 🔴 bearish 20.50 1273.80 - 1294.30 No previous FVGs\n",
      "2025-10-30 10:15        OIL 🟢 bullish  6.60   421.95 - 428.55 No previous FVGs\n",
      "2025-10-30 10:15   PETRONET 🔴 bearish  0.40   282.80 - 283.20 No previous FVGs\n",
      "2025-10-30 14:15        PNB 🔴 bearish  0.17   120.28 - 120.45 No previous FVGs\n",
      "2025-10-30 10:15  POWERGRID 🔴 bearish  2.00   292.80 - 294.80 No previous FVGs\n",
      "2025-10-30 10:15     RECLTD 🔴 bearish  1.90   381.90 - 383.80 No previous FVGs\n",
      "2025-10-30 14:15   RELIANCE 🔴 bearish  1.20 1491.50 - 1492.70 No previous FVGs\n",
      "2025-10-30 10:15   RELIANCE 🔴 bearish  4.80 1498.30 - 1503.10 No previous FVGs\n",
      "2025-10-30 15:15       SBIN 🔴 bearish  0.35   934.50 - 934.85 No previous FVGs\n",
      "2025-10-30 14:15       SBIN 🔴 bearish  0.60   938.35 - 938.95 No previous FVGs\n",
      "2025-10-30 15:15 TORNTPOWER 🟢 bullish  0.20 1312.40 - 1312.60 No previous FVGs\n",
      "2025-10-30 11:15 TORNTPOWER 🔴 bearish  0.10 1309.90 - 1310.00 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 56\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 2  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey2:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS2\n",
    "combined_df = combined_df2\n",
    "key_name = \"Instrument Key 2 (Banks, Oil & Gas, Power, etc.)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "\n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"C:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik2(30-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "\n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik2(28-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "    # Save combined/master data (overwrites master file — change path if you want daily snapshots)\n",
    "    master_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\")\n",
    "    if master_path.exists():\n",
    "        try:\n",
    "            prev_master = pd.read_pickle(master_path)\n",
    "            # concat and dedupe on Datetime + Ticker (use Datetime_dt when available)\n",
    "            prev_master['Datetime_dt'] = pd.to_datetime(prev_master['Datetime'])\n",
    "            combined_master = pd.concat([prev_master, df_display], ignore_index=True)\n",
    "            combined_master = combined_master.drop_duplicates(subset=['Ticker', 'Datetime_dt'])\n",
    "            combined_master = combined_master.sort_values(['Datetime_dt', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "            combined_master.to_pickle(master_path)\n",
    "        except Exception:\n",
    "            # fallback: overwrite if previous master can't be read\n",
    "            df_display.to_pickle(master_path)\n",
    "    else:\n",
    "        df_display.to_pickle(master_path)\n",
    "\n",
    "    print(f\"Master results updated at: {master_path}\")\n",
    "\n",
    "    # Prepare a friendly display including last-3 info\n",
    "    def format_row_with_prev(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "\n",
    "    # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fadfdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey3 = {\n",
    "    \"TIINDIA\":\"NSE_EQ|INE974X01010\",\n",
    "    \"WELCORP\":\"NSE_EQ|INE191B01025\",\n",
    "    \"LINDEINDIA\":\"NSE_EQ|INE473A01011\",\n",
    "    \"JINDALSAW\":\"NSE_EQ|INE324A01032\",\n",
    "    \"SHYAMMETL\":\"NSE_EQ|INE810G01011\",\n",
    "    \"GRAPHITE\":\"NSE_EQ|INE371A01025\",\n",
    "    \"USHAMART\":\"NSE_EQ|INE228A01035\",\n",
    "    \"APARINDS\":\"NSE_EQ|INE372A01015\",\n",
    "    \"POLYCAB\":\"NSE_EQ|INE455K01017\",\n",
    "    \"MAHSEAMLESS\":\"NSE_EQ|INE271B01025\",\n",
    "    \"KEC\":\"NSE_EQ|INE389H01022\",\n",
    "    \"KEI\":\"NSE_EQ|INE878B01027\",\n",
    "    \"APLAPOLLO\":\"NSE_EQ|INE702C01027\",\n",
    "    \"HINDCOPPER\":\"NSE_EQ|INE531E01026\",\n",
    "    \"HINDALCO\":\"NSE_EQ|INE038A01020\",\n",
    "    \"NATIONALUM\":\"NSE_EQ|INE139A01034\",\n",
    "    \"VEDL\":\"NSE_EQ|INE205A01025\",\n",
    "    \"TATASTEEL\":\"NSE_EQ|INE081A01020\",\n",
    "    \"JSWSTEEL\":\"NSE_EQ|INE019A01038\",\n",
    "    \"JINDALSTEL\":\"NSE_EQ|INE749A01030\",\n",
    "    \"SAIL\":\"NSE_EQ|INE114A01011\",\n",
    "    \"NMDC\":\"NSE_EQ|INE584A01023\",\n",
    "    \"VGUARD\":\"NSE_EQ|INE951I01027\",\n",
    "    \"THERMAX\":\"NSE_EQ|INE152A01029\",\n",
    "    \"SUPREMEIND\":\"NSE_EQ|INE195A01028\",\n",
    "    \"ASTRAL\":\"NSE_EQ|INE006I01046\",\n",
    "    \"ABB\":\"NSE_EQ|INE117A01022\",\n",
    "    \"SIEMENS\":\"NSE_EQ|INE003A01024\",\n",
    "    \"HEROMOTOCO\":\"NSE_EQ|INE158A01026\",\n",
    "    \"TVSMOTOR\":\"NSE_EQ|INE494B01023\",\n",
    "    \"EICHERMOT\":\"NSE_EQ|INE066A01021\",\n",
    "    \"BAJAJ-AUTO\":\"NSE_EQ|INE917I01010\",\n",
    "    \"TATAMOTORS\":\"NSE_EQ|INE155A01022\",\n",
    "    \"MARUTI\":\"NSE_EQ|INE585B01010\",\n",
    "    \"HYUNDAI\":\"NSE_EQ|INE0V6F01027\",\n",
    "    \"M&M\":\"NSE_EQ|INE0V6F01027\",\n",
    "    \"BOSCHLTD\":\"NSE_EQ|INE323A01026\",\n",
    "    \"MOTHERSON\":\"NSE_EQ|INE775A01035\",\n",
    "    \"ASHOKLEY\":\"NSE_EQ|INE208A01029\",\n",
    "    \"CEATLTD\":\"NSE_EQ|INE482A01020\",\n",
    "    \"MRF\":\"NSE_EQ|INE883A01011\",\n",
    "    \"APOLLOTYRE\":\"NSE_EQ|INE438A01022\",\n",
    "    \"JKTYRE\":\"NSE_EQ|INE573A01042\",\n",
    "    \"ARE&M\":\"NSE_EQ|INE885A01032\",\n",
    "    \"EXIDEIND\":\"NSE_EQ|INE302A01020\",\n",
    "    \"CRAFTSMAN\":\"NSE_EQ|INE00LO01017\",\n",
    "    \"SONACOMS\":\"NSE_EQ|INE073K01018\",\n",
    "    \"MINDACORP\":\"NSE_EQ|INE842C01021\",\n",
    "    \"BALKRISIND\":\"NSE_EQ|INE787D01026\",\n",
    "    \"BHARATFORG\":\"NSE_EQ|INE465A01025\",\n",
    "    \"ESCORTS\":\"NSE_EQ|INE042A01014\",\n",
    "    \"ENDURANCE\":\"NSE_EQ|INE913H01037\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c24ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TIINDIA...\n",
      "Fetching data for WELCORP...\n",
      "Fetching data for WELCORP...\n",
      "Fetching data for LINDEINDIA...\n",
      "Fetching data for LINDEINDIA...\n",
      "Fetching data for JINDALSAW...\n",
      "Fetching data for JINDALSAW...\n",
      "Fetching data for SHYAMMETL...\n",
      "Fetching data for SHYAMMETL...\n",
      "Fetching data for GRAPHITE...\n",
      "Fetching data for GRAPHITE...\n",
      "Fetching data for USHAMART...\n",
      "Fetching data for USHAMART...\n",
      "Fetching data for APARINDS...\n",
      "Fetching data for APARINDS...\n",
      "Fetching data for POLYCAB...\n",
      "Fetching data for POLYCAB...\n",
      "Fetching data for MAHSEAMLESS...\n",
      "Fetching data for MAHSEAMLESS...\n",
      "Fetching data for KEC...\n",
      "Fetching data for KEC...\n",
      "Fetching data for KEI...\n",
      "Fetching data for KEI...\n",
      "Fetching data for APLAPOLLO...\n",
      "Fetching data for APLAPOLLO...\n",
      "Fetching data for HINDCOPPER...\n",
      "Fetching data for HINDCOPPER...\n",
      "Fetching data for HINDALCO...\n",
      "Fetching data for HINDALCO...\n",
      "Fetching data for NATIONALUM...\n",
      "Fetching data for NATIONALUM...\n",
      "Fetching data for VEDL...\n",
      "Fetching data for VEDL...\n",
      "Fetching data for TATASTEEL...\n",
      "Fetching data for TATASTEEL...\n",
      "Fetching data for JSWSTEEL...\n",
      "Fetching data for JSWSTEEL...\n",
      "Fetching data for JINDALSTEL...\n",
      "Fetching data for JINDALSTEL...\n",
      "Fetching data for SAIL...\n",
      "Fetching data for SAIL...\n",
      "Fetching data for NMDC...\n",
      "Fetching data for NMDC...\n",
      "Fetching data for VGUARD...\n",
      "Fetching data for VGUARD...\n",
      "Fetching data for THERMAX...\n",
      "Fetching data for THERMAX...\n",
      "Fetching data for SUPREMEIND...\n",
      "Fetching data for SUPREMEIND...\n",
      "Fetching data for ASTRAL...\n",
      "Fetching data for ASTRAL...\n",
      "Fetching data for ABB...\n",
      "Fetching data for ABB...\n",
      "Fetching data for SIEMENS...\n",
      "Fetching data for SIEMENS...\n",
      "Fetching data for HEROMOTOCO...\n",
      "Fetching data for HEROMOTOCO...\n",
      "Fetching data for TVSMOTOR...\n",
      "Fetching data for TVSMOTOR...\n",
      "Fetching data for EICHERMOT...\n",
      "Fetching data for EICHERMOT...\n",
      "Fetching data for BAJAJ-AUTO...\n",
      "Fetching data for BAJAJ-AUTO...\n",
      "Fetching data for TATAMOTORS...\n",
      "Fetching data for TATAMOTORS...\n",
      "Fetching data for MARUTI...\n",
      "Fetching data for MARUTI...\n",
      "Fetching data for HYUNDAI...\n",
      "Fetching data for HYUNDAI...\n",
      "Fetching data for M&M...\n",
      "Fetching data for M&M...\n",
      "Fetching data for BOSCHLTD...\n",
      "Fetching data for BOSCHLTD...\n",
      "Fetching data for MOTHERSON...\n",
      "Fetching data for MOTHERSON...\n",
      "Fetching data for ASHOKLEY...\n",
      "Fetching data for ASHOKLEY...\n",
      "Fetching data for CEATLTD...\n",
      "Fetching data for CEATLTD...\n",
      "Fetching data for MRF...\n",
      "Fetching data for MRF...\n",
      "Fetching data for APOLLOTYRE...\n",
      "Fetching data for APOLLOTYRE...\n",
      "Fetching data for JKTYRE...\n",
      "Fetching data for JKTYRE...\n",
      "Fetching data for ARE&M...\n",
      "Fetching data for ARE&M...\n",
      "Fetching data for EXIDEIND...\n",
      "Fetching data for EXIDEIND...\n",
      "Fetching data for CRAFTSMAN...\n",
      "Fetching data for CRAFTSMAN...\n",
      "Fetching data for SONACOMS...\n",
      "Fetching data for SONACOMS...\n",
      "Fetching data for MINDACORP...\n",
      "Fetching data for MINDACORP...\n",
      "Fetching data for BALKRISIND...\n",
      "Fetching data for BALKRISIND...\n",
      "Fetching data for BHARATFORG...\n",
      "Fetching data for BHARATFORG...\n",
      "Fetching data for ESCORTS...\n",
      "Fetching data for ESCORTS...\n",
      "Fetching data for ENDURANCE...\n",
      "Fetching data for ENDURANCE...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABB</th>\n",
       "      <th>APARINDS</th>\n",
       "      <th>APLAPOLLO</th>\n",
       "      <th>APOLLOTYRE</th>\n",
       "      <th>ARE&amp;M</th>\n",
       "      <th>ASHOKLEY</th>\n",
       "      <th>ASTRAL</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BALKRISIND</th>\n",
       "      <th>BHARATFORG</th>\n",
       "      <th>...</th>\n",
       "      <th>SUPREMEIND</th>\n",
       "      <th>TATAMOTORS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>THERMAX</th>\n",
       "      <th>TIINDIA</th>\n",
       "      <th>TVSMOTOR</th>\n",
       "      <th>USHAMART</th>\n",
       "      <th>VEDL</th>\n",
       "      <th>VGUARD</th>\n",
       "      <th>WELCORP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, ABB), (Close, APARINDS), (Close, APLAPOLLO), (Close, APOLLOTYRE), (Close, ARE&M), (Close, ASHOKLEY), (Close, ASTRAL), (Close, BAJAJ-AUTO), (Close, BALKRISIND), (Close, BHARATFORG), (Close, BOSCHLTD), (Close, CEATLTD), (Close, CRAFTSMAN), (Close, EICHERMOT), (Close, ENDURANCE), (Close, ESCORTS), (Close, EXIDEIND), (Close, GRAPHITE), (Close, HEROMOTOCO), (Close, HINDALCO), (Close, HINDCOPPER), (Close, HYUNDAI), (Close, JINDALSAW), (Close, JINDALSTEL), (Close, JKTYRE), (Close, JSWSTEEL), (Close, KEC), (Close, KEI), (Close, LINDEINDIA), (Close, M&M), (Close, MAHSEAMLESS), (Close, MARUTI), (Close, MINDACORP), (Close, MOTHERSON), (Close, MRF), (Close, NATIONALUM), (Close, NMDC), (Close, POLYCAB), (Close, SAIL), (Close, SHYAMMETL), (Close, SIEMENS), (Close, SONACOMS), (Close, SUPREMEIND), (Close, TATAMOTORS), (Close, TATASTEEL), (Close, THERMAX), (Close, TIINDIA), (Close, TVSMOTOR), (Close, USHAMART), (Close, VEDL), (Close, VGUARD), (Close, WELCORP), (High, ABB), (High, APARINDS), (High, APLAPOLLO), (High, APOLLOTYRE), (High, ARE&M), (High, ASHOKLEY), (High, ASTRAL), (High, BAJAJ-AUTO), (High, BALKRISIND), (High, BHARATFORG), (High, BOSCHLTD), (High, CEATLTD), (High, CRAFTSMAN), (High, EICHERMOT), (High, ENDURANCE), (High, ESCORTS), (High, EXIDEIND), (High, GRAPHITE), (High, HEROMOTOCO), (High, HINDALCO), (High, HINDCOPPER), (High, HYUNDAI), (High, JINDALSAW), (High, JINDALSTEL), (High, JKTYRE), (High, JSWSTEEL), (High, KEC), (High, KEI), (High, LINDEINDIA), (High, M&M), (High, MAHSEAMLESS), (High, MARUTI), (High, MINDACORP), (High, MOTHERSON), (High, MRF), (High, NATIONALUM), (High, NMDC), (High, POLYCAB), (High, SAIL), (High, SHYAMMETL), (High, SIEMENS), (High, SONACOMS), (High, SUPREMEIND), (High, TATAMOTORS), (High, TATASTEEL), (High, THERMAX), (High, TIINDIA), (High, TVSMOTOR), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABB</th>\n",
       "      <th>APARINDS</th>\n",
       "      <th>APLAPOLLO</th>\n",
       "      <th>APOLLOTYRE</th>\n",
       "      <th>ARE&amp;M</th>\n",
       "      <th>ASHOKLEY</th>\n",
       "      <th>ASTRAL</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BALKRISIND</th>\n",
       "      <th>BHARATFORG</th>\n",
       "      <th>...</th>\n",
       "      <th>SUPREMEIND</th>\n",
       "      <th>TATAMOTORS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>THERMAX</th>\n",
       "      <th>TIINDIA</th>\n",
       "      <th>TVSMOTOR</th>\n",
       "      <th>USHAMART</th>\n",
       "      <th>VEDL</th>\n",
       "      <th>VGUARD</th>\n",
       "      <th>WELCORP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>5265.5</td>\n",
       "      <td>9316.0</td>\n",
       "      <td>1774.1</td>\n",
       "      <td>506.15</td>\n",
       "      <td>1009.85</td>\n",
       "      <td>139.61</td>\n",
       "      <td>1454.5</td>\n",
       "      <td>9000.5</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>1317.8</td>\n",
       "      <td>...</td>\n",
       "      <td>99415.0</td>\n",
       "      <td>2770340.0</td>\n",
       "      <td>5878317.0</td>\n",
       "      <td>6239.0</td>\n",
       "      <td>58691.0</td>\n",
       "      <td>714026.0</td>\n",
       "      <td>57627.0</td>\n",
       "      <td>3159925.0</td>\n",
       "      <td>67998.0</td>\n",
       "      <td>383084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>5262.0</td>\n",
       "      <td>9292.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>504.60</td>\n",
       "      <td>1011.90</td>\n",
       "      <td>139.79</td>\n",
       "      <td>1456.8</td>\n",
       "      <td>9002.5</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>1317.1</td>\n",
       "      <td>...</td>\n",
       "      <td>18720.0</td>\n",
       "      <td>1074884.0</td>\n",
       "      <td>2466398.0</td>\n",
       "      <td>4499.0</td>\n",
       "      <td>55303.0</td>\n",
       "      <td>108747.0</td>\n",
       "      <td>34822.0</td>\n",
       "      <td>748315.0</td>\n",
       "      <td>1700592.0</td>\n",
       "      <td>119558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>5272.5</td>\n",
       "      <td>9268.0</td>\n",
       "      <td>1796.1</td>\n",
       "      <td>505.15</td>\n",
       "      <td>1012.50</td>\n",
       "      <td>140.40</td>\n",
       "      <td>1458.2</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145167.0</td>\n",
       "      <td>721659.0</td>\n",
       "      <td>6689984.0</td>\n",
       "      <td>27878.0</td>\n",
       "      <td>35105.0</td>\n",
       "      <td>81297.0</td>\n",
       "      <td>8559.0</td>\n",
       "      <td>944928.0</td>\n",
       "      <td>44827.0</td>\n",
       "      <td>378151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>5277.0</td>\n",
       "      <td>9275.0</td>\n",
       "      <td>1781.2</td>\n",
       "      <td>504.55</td>\n",
       "      <td>1011.55</td>\n",
       "      <td>140.24</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>8992.0</td>\n",
       "      <td>2322.1</td>\n",
       "      <td>1320.9</td>\n",
       "      <td>...</td>\n",
       "      <td>13561.0</td>\n",
       "      <td>672939.0</td>\n",
       "      <td>1480598.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>98206.0</td>\n",
       "      <td>179184.0</td>\n",
       "      <td>11986.0</td>\n",
       "      <td>475640.0</td>\n",
       "      <td>54466.0</td>\n",
       "      <td>155238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>5265.0</td>\n",
       "      <td>9255.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>501.70</td>\n",
       "      <td>1011.55</td>\n",
       "      <td>140.36</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>2310.2</td>\n",
       "      <td>1316.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26842.0</td>\n",
       "      <td>647315.0</td>\n",
       "      <td>2142891.0</td>\n",
       "      <td>5832.0</td>\n",
       "      <td>53643.0</td>\n",
       "      <td>86239.0</td>\n",
       "      <td>27713.0</td>\n",
       "      <td>558322.0</td>\n",
       "      <td>61125.0</td>\n",
       "      <td>271744.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                           ...     Volume                                                             \\\n",
       "Ticker                        ABB APARINDS APLAPOLLO APOLLOTYRE    ARE&M ASHOKLEY  ASTRAL BAJAJ-AUTO BALKRISIND BHARATFORG  ... SUPREMEIND TATAMOTORS  TATASTEEL  THERMAX  TIINDIA  TVSMOTOR USHAMART   \n",
       "Datetime                                                                                                                    ...                                                                         \n",
       "2025-10-30 09:15:00+05:30  5265.5   9316.0    1774.1     506.15  1009.85   139.61  1454.5     9000.5     2330.0     1317.8  ...    99415.0  2770340.0  5878317.0   6239.0  58691.0  714026.0  57627.0   \n",
       "2025-10-30 10:15:00+05:30  5262.0   9292.0    1790.0     504.60  1011.90   139.79  1456.8     9002.5     2335.0     1317.1  ...    18720.0  1074884.0  2466398.0   4499.0  55303.0  108747.0  34822.0   \n",
       "2025-10-30 11:15:00+05:30  5272.5   9268.0    1796.1     505.15  1012.50   140.40  1458.2     9003.0     2324.0     1317.0  ...   145167.0   721659.0  6689984.0  27878.0  35105.0   81297.0   8559.0   \n",
       "2025-10-30 12:15:00+05:30  5277.0   9275.0    1781.2     504.55  1011.55   140.24  1467.0     8992.0     2322.1     1320.9  ...    13561.0   672939.0  1480598.0   5455.0  98206.0  179184.0  11986.0   \n",
       "2025-10-30 13:15:00+05:30  5265.0   9255.0    1784.0     501.70  1011.55   140.36  1463.0     8922.0     2310.2     1316.5  ...    26842.0   647315.0  2142891.0   5832.0  53643.0   86239.0  27713.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                          VEDL     VGUARD   WELCORP  \n",
       "Datetime                                                   \n",
       "2025-10-30 09:15:00+05:30  3159925.0    67998.0  383084.0  \n",
       "2025-10-30 10:15:00+05:30   748315.0  1700592.0  119558.0  \n",
       "2025-10-30 11:15:00+05:30   944928.0    44827.0  378151.0  \n",
       "2025-10-30 12:15:00+05:30   475640.0    54466.0  155238.0  \n",
       "2025-10-30 13:15:00+05:30   558322.0    61125.0  271744.0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intrday data for instrument key 3 \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS3 = instrumentkey3\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS3.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "\n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index3 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index3\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf77e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 260)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABB</th>\n",
       "      <th>APARINDS</th>\n",
       "      <th>APLAPOLLO</th>\n",
       "      <th>APOLLOTYRE</th>\n",
       "      <th>ARE&amp;M</th>\n",
       "      <th>ASHOKLEY</th>\n",
       "      <th>ASTRAL</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BALKRISIND</th>\n",
       "      <th>BHARATFORG</th>\n",
       "      <th>...</th>\n",
       "      <th>SUPREMEIND</th>\n",
       "      <th>TATAMOTORS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>THERMAX</th>\n",
       "      <th>TIINDIA</th>\n",
       "      <th>TVSMOTOR</th>\n",
       "      <th>USHAMART</th>\n",
       "      <th>VEDL</th>\n",
       "      <th>VGUARD</th>\n",
       "      <th>WELCORP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>5281.5</td>\n",
       "      <td>9460.0</td>\n",
       "      <td>1802.6</td>\n",
       "      <td>505.20</td>\n",
       "      <td>1012.95</td>\n",
       "      <td>139.35</td>\n",
       "      <td>1464.4</td>\n",
       "      <td>9031.5</td>\n",
       "      <td>2332.3</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115915.0</td>\n",
       "      <td>1442446.0</td>\n",
       "      <td>5286364.0</td>\n",
       "      <td>5378.0</td>\n",
       "      <td>96026.0</td>\n",
       "      <td>176829.0</td>\n",
       "      <td>43720.0</td>\n",
       "      <td>7724821.0</td>\n",
       "      <td>295691.0</td>\n",
       "      <td>148278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>5298.0</td>\n",
       "      <td>9475.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>505.00</td>\n",
       "      <td>1014.50</td>\n",
       "      <td>139.80</td>\n",
       "      <td>1465.7</td>\n",
       "      <td>9034.5</td>\n",
       "      <td>2327.0</td>\n",
       "      <td>1323.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31730.0</td>\n",
       "      <td>937657.0</td>\n",
       "      <td>2980099.0</td>\n",
       "      <td>5196.0</td>\n",
       "      <td>18792.0</td>\n",
       "      <td>123621.0</td>\n",
       "      <td>33927.0</td>\n",
       "      <td>2010908.0</td>\n",
       "      <td>34108.0</td>\n",
       "      <td>68880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>5265.5</td>\n",
       "      <td>9316.0</td>\n",
       "      <td>1774.1</td>\n",
       "      <td>506.15</td>\n",
       "      <td>1009.85</td>\n",
       "      <td>139.61</td>\n",
       "      <td>1454.5</td>\n",
       "      <td>9000.5</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>1317.8</td>\n",
       "      <td>...</td>\n",
       "      <td>99415.0</td>\n",
       "      <td>2770340.0</td>\n",
       "      <td>5878317.0</td>\n",
       "      <td>6239.0</td>\n",
       "      <td>58691.0</td>\n",
       "      <td>714026.0</td>\n",
       "      <td>57627.0</td>\n",
       "      <td>3159925.0</td>\n",
       "      <td>67998.0</td>\n",
       "      <td>383084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>5262.0</td>\n",
       "      <td>9292.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>504.60</td>\n",
       "      <td>1011.90</td>\n",
       "      <td>139.79</td>\n",
       "      <td>1456.8</td>\n",
       "      <td>9002.5</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>1317.1</td>\n",
       "      <td>...</td>\n",
       "      <td>18720.0</td>\n",
       "      <td>1074884.0</td>\n",
       "      <td>2466398.0</td>\n",
       "      <td>4499.0</td>\n",
       "      <td>55303.0</td>\n",
       "      <td>108747.0</td>\n",
       "      <td>34822.0</td>\n",
       "      <td>748315.0</td>\n",
       "      <td>1700592.0</td>\n",
       "      <td>119558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>5272.5</td>\n",
       "      <td>9268.0</td>\n",
       "      <td>1796.1</td>\n",
       "      <td>505.15</td>\n",
       "      <td>1012.50</td>\n",
       "      <td>140.40</td>\n",
       "      <td>1458.2</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145167.0</td>\n",
       "      <td>721659.0</td>\n",
       "      <td>6689984.0</td>\n",
       "      <td>27878.0</td>\n",
       "      <td>35105.0</td>\n",
       "      <td>81297.0</td>\n",
       "      <td>8559.0</td>\n",
       "      <td>944928.0</td>\n",
       "      <td>44827.0</td>\n",
       "      <td>378151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>5277.0</td>\n",
       "      <td>9275.0</td>\n",
       "      <td>1781.2</td>\n",
       "      <td>504.55</td>\n",
       "      <td>1011.55</td>\n",
       "      <td>140.24</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>8992.0</td>\n",
       "      <td>2322.1</td>\n",
       "      <td>1320.9</td>\n",
       "      <td>...</td>\n",
       "      <td>13561.0</td>\n",
       "      <td>672939.0</td>\n",
       "      <td>1480598.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>98206.0</td>\n",
       "      <td>179184.0</td>\n",
       "      <td>11986.0</td>\n",
       "      <td>475640.0</td>\n",
       "      <td>54466.0</td>\n",
       "      <td>155238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>5265.0</td>\n",
       "      <td>9255.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>501.70</td>\n",
       "      <td>1011.55</td>\n",
       "      <td>140.36</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>2310.2</td>\n",
       "      <td>1316.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26842.0</td>\n",
       "      <td>647315.0</td>\n",
       "      <td>2142891.0</td>\n",
       "      <td>5832.0</td>\n",
       "      <td>53643.0</td>\n",
       "      <td>86239.0</td>\n",
       "      <td>27713.0</td>\n",
       "      <td>558322.0</td>\n",
       "      <td>61125.0</td>\n",
       "      <td>271744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>5279.0</td>\n",
       "      <td>9228.0</td>\n",
       "      <td>1783.5</td>\n",
       "      <td>503.50</td>\n",
       "      <td>1016.45</td>\n",
       "      <td>140.90</td>\n",
       "      <td>1466.9</td>\n",
       "      <td>8921.0</td>\n",
       "      <td>2327.6</td>\n",
       "      <td>1317.3</td>\n",
       "      <td>...</td>\n",
       "      <td>53421.0</td>\n",
       "      <td>1617030.0</td>\n",
       "      <td>4007134.0</td>\n",
       "      <td>6129.0</td>\n",
       "      <td>51002.0</td>\n",
       "      <td>162350.0</td>\n",
       "      <td>20064.0</td>\n",
       "      <td>1014880.0</td>\n",
       "      <td>68328.0</td>\n",
       "      <td>1494778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>5272.0</td>\n",
       "      <td>9230.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>503.35</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>140.75</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>8914.0</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>1318.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44487.0</td>\n",
       "      <td>1279374.0</td>\n",
       "      <td>1582984.0</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>67196.0</td>\n",
       "      <td>121204.0</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>535633.0</td>\n",
       "      <td>30897.0</td>\n",
       "      <td>102574.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                           ...     Volume                                                             \\\n",
       "Ticker                        ABB APARINDS APLAPOLLO APOLLOTYRE    ARE&M ASHOKLEY  ASTRAL BAJAJ-AUTO BALKRISIND BHARATFORG  ... SUPREMEIND TATAMOTORS  TATASTEEL  THERMAX  TIINDIA  TVSMOTOR USHAMART   \n",
       "Datetime                                                                                                                    ...                                                                         \n",
       "2025-10-29 14:15:00+05:30  5281.5   9460.0    1802.6     505.20  1012.95   139.35  1464.4     9031.5     2332.3     1321.0  ...   115915.0  1442446.0  5286364.0   5378.0  96026.0  176829.0  43720.0   \n",
       "2025-10-29 15:15:00+05:30  5298.0   9475.0    1810.0     505.00  1014.50   139.80  1465.7     9034.5     2327.0     1323.1  ...    31730.0   937657.0  2980099.0   5196.0  18792.0  123621.0  33927.0   \n",
       "2025-10-30 09:15:00+05:30  5265.5   9316.0    1774.1     506.15  1009.85   139.61  1454.5     9000.5     2330.0     1317.8  ...    99415.0  2770340.0  5878317.0   6239.0  58691.0  714026.0  57627.0   \n",
       "2025-10-30 10:15:00+05:30  5262.0   9292.0    1790.0     504.60  1011.90   139.79  1456.8     9002.5     2335.0     1317.1  ...    18720.0  1074884.0  2466398.0   4499.0  55303.0  108747.0  34822.0   \n",
       "2025-10-30 11:15:00+05:30  5272.5   9268.0    1796.1     505.15  1012.50   140.40  1458.2     9003.0     2324.0     1317.0  ...   145167.0   721659.0  6689984.0  27878.0  35105.0   81297.0   8559.0   \n",
       "2025-10-30 12:15:00+05:30  5277.0   9275.0    1781.2     504.55  1011.55   140.24  1467.0     8992.0     2322.1     1320.9  ...    13561.0   672939.0  1480598.0   5455.0  98206.0  179184.0  11986.0   \n",
       "2025-10-30 13:15:00+05:30  5265.0   9255.0    1784.0     501.70  1011.55   140.36  1463.0     8922.0     2310.2     1316.5  ...    26842.0   647315.0  2142891.0   5832.0  53643.0   86239.0  27713.0   \n",
       "2025-10-30 14:15:00+05:30  5279.0   9228.0    1783.5     503.50  1016.45   140.90  1466.9     8921.0     2327.6     1317.3  ...    53421.0  1617030.0  4007134.0   6129.0  51002.0  162350.0  20064.0   \n",
       "2025-10-30 15:15:00+05:30  5272.0   9230.0    1784.0     503.35  1017.00   140.75  1463.0     8914.0     2330.0     1318.9  ...    44487.0  1279374.0  1582984.0   4668.0  67196.0  121204.0  26159.0   \n",
       "\n",
       "Field                                                       \n",
       "Ticker                          VEDL     VGUARD    WELCORP  \n",
       "Datetime                                                    \n",
       "2025-10-29 14:15:00+05:30  7724821.0   295691.0   148278.0  \n",
       "2025-10-29 15:15:00+05:30  2010908.0    34108.0    68880.0  \n",
       "2025-10-30 09:15:00+05:30  3159925.0    67998.0   383084.0  \n",
       "2025-10-30 10:15:00+05:30   748315.0  1700592.0   119558.0  \n",
       "2025-10-30 11:15:00+05:30   944928.0    44827.0   378151.0  \n",
       "2025-10-30 12:15:00+05:30   475640.0    54466.0   155238.0  \n",
       "2025-10-30 13:15:00+05:30   558322.0    61125.0   271744.0  \n",
       "2025-10-30 14:15:00+05:30  1014880.0    68328.0  1494778.0  \n",
       "2025-10-30 15:15:00+05:30   535633.0    30897.0   102574.0  \n",
       "\n",
       "[9 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik3.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index3  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df3 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df3 = combined_df3[~combined_df3.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df3.shape)\n",
    "print(combined_df3.index.names)\n",
    "print(combined_df3.columns.names)\n",
    "display(combined_df3.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FVG detection results saved to: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik3(30-10).pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 3 (Metals and Auto) (date: 2025-10-30):\n",
      "        Datetime     Ticker   Pattern    Gap                 Range    Previous_FVGs\n",
      "2025-10-30 10:15        ABB 🔴 bearish  14.00     5266.00 - 5280.00 No previous FVGs\n",
      "2025-10-30 10:15   APARINDS 🔴 bearish  27.00     9345.00 - 9372.00 No previous FVGs\n",
      "2025-10-30 10:15  APLAPOLLO 🔴 bearish   3.40     1799.00 - 1802.40 No previous FVGs\n",
      "2025-10-30 15:15      ARE&M 🟢 bullish   0.70     1013.35 - 1014.05 No previous FVGs\n",
      "2025-10-30 12:15   ASHOKLEY 🟢 bullish   0.04       140.10 - 140.14 No previous FVGs\n",
      "2025-10-30 13:15     ASTRAL 🟢 bullish   0.70     1459.90 - 1460.60 No previous FVGs\n",
      "2025-10-30 10:15     ASTRAL 🔴 bearish   6.30     1457.70 - 1464.00 No previous FVGs\n",
      "2025-10-30 14:15 BAJAJ-AUTO 🔴 bearish  39.00     8936.50 - 8975.50 No previous FVGs\n",
      "2025-10-30 10:15 BAJAJ-AUTO 🔴 bearish  17.00     9013.00 - 9030.00 No previous FVGs\n",
      "2025-10-30 10:15 BHARATFORG 🔴 bearish   1.70     1318.40 - 1320.10 No previous FVGs\n",
      "2025-10-30 11:15    CEATLTD 🟢 bullish  33.40     4063.00 - 4096.40 No previous FVGs\n",
      "2025-10-30 15:15  CRAFTSMAN 🟢 bullish  38.00     6617.00 - 6655.00 No previous FVGs\n",
      "2025-10-30 10:15  CRAFTSMAN 🟢 bullish  49.50     6480.50 - 6530.00 No previous FVGs\n",
      "2025-10-30 10:15   EXIDEIND 🔴 bearish   1.95       382.30 - 384.25 No previous FVGs\n",
      "2025-10-30 15:15   HINDALCO 🟢 bullish   2.80       858.20 - 861.00 No previous FVGs\n",
      "2025-10-30 10:15 HINDCOPPER 🔴 bearish   2.45       347.95 - 350.40 No previous FVGs\n",
      "2025-10-30 15:15    HYUNDAI 🟢 bullish  46.70     2358.20 - 2404.90 No previous FVGs\n",
      "2025-10-30 10:15  JINDALSAW 🔴 bearish   1.10       176.49 - 177.59 No previous FVGs\n",
      "2025-10-30 15:15 JINDALSTEL 🟢 bullish   1.10     1068.00 - 1069.10 No previous FVGs\n",
      "2025-10-30 12:15     JKTYRE 🟢 bullish   2.15       430.70 - 432.85 No previous FVGs\n",
      "2025-10-30 15:15        KEC 🟢 bullish   3.10       821.90 - 825.00 No previous FVGs\n",
      "2025-10-30 10:15        KEC 🔴 bearish   1.80       823.65 - 825.45 No previous FVGs\n",
      "2025-10-30 13:15        KEI 🟢 bullish  10.20     4094.90 - 4105.10 No previous FVGs\n",
      "2025-10-30 15:15        M&M 🟢 bullish  46.70     2358.20 - 2404.90 No previous FVGs\n",
      "2025-10-30 10:15  MOTHERSON 🔴 bearish   0.05       107.36 - 107.41 No previous FVGs\n",
      "2025-10-30 10:15        MRF 🔴 bearish 380.00 159365.00 - 159745.00 No previous FVGs\n",
      "2025-10-30 15:15 NATIONALUM 🟢 bullish   1.04       236.60 - 237.64 No previous FVGs\n",
      "2025-10-30 10:15 NATIONALUM 🔴 bearish   0.99       236.55 - 237.54 No previous FVGs\n",
      "2025-10-30 12:15    POLYCAB 🟢 bullish  18.50     7791.00 - 7809.50 No previous FVGs\n",
      "2025-10-30 15:15       SAIL 🟢 bullish   0.12       136.46 - 136.58 No previous FVGs\n",
      "2025-10-30 11:15       SAIL 🔴 bearish   0.37       136.83 - 137.20 No previous FVGs\n",
      "2025-10-30 10:15       SAIL 🔴 bearish   1.11       138.40 - 139.51 No previous FVGs\n",
      "2025-10-30 10:15  SHYAMMETL 🔴 bearish   4.15       908.00 - 912.15 No previous FVGs\n",
      "2025-10-30 10:15 SUPREMEIND 🔴 bearish  21.40     3822.70 - 3844.10 No previous FVGs\n",
      "2025-10-30 10:15 TATAMOTORS 🔴 bearish   0.20       410.85 - 411.05 No previous FVGs\n",
      "2025-10-30 15:15  TATASTEEL 🟢 bullish   0.75       183.46 - 184.21 No previous FVGs\n",
      "2025-10-30 10:15  TATASTEEL 🔴 bearish   0.68       184.20 - 184.88 No previous FVGs\n",
      "2025-10-30 14:15    TIINDIA 🔴 bearish  26.10     3075.00 - 3101.10 No previous FVGs\n",
      "2025-10-30 12:15    TIINDIA 🔴 bearish   0.70     3117.90 - 3118.60 No previous FVGs\n",
      "2025-10-30 13:15   TVSMOTOR 🔴 bearish   3.00     3498.00 - 3501.00 No previous FVGs\n",
      "2025-10-30 15:15       VEDL 🟢 bullish   0.40       505.75 - 506.15 No previous FVGs\n",
      "2025-10-30 10:15     VGUARD 🔴 bearish   2.55       377.45 - 380.00 No previous FVGs\n",
      "2025-10-30 12:15    WELCORP 🟢 bullish   8.05       912.00 - 920.05 No previous FVGs\n",
      "        Datetime     Ticker   Pattern    Gap                 Range    Previous_FVGs\n",
      "2025-10-30 10:15        ABB 🔴 bearish  14.00     5266.00 - 5280.00 No previous FVGs\n",
      "2025-10-30 10:15   APARINDS 🔴 bearish  27.00     9345.00 - 9372.00 No previous FVGs\n",
      "2025-10-30 10:15  APLAPOLLO 🔴 bearish   3.40     1799.00 - 1802.40 No previous FVGs\n",
      "2025-10-30 15:15      ARE&M 🟢 bullish   0.70     1013.35 - 1014.05 No previous FVGs\n",
      "2025-10-30 12:15   ASHOKLEY 🟢 bullish   0.04       140.10 - 140.14 No previous FVGs\n",
      "2025-10-30 13:15     ASTRAL 🟢 bullish   0.70     1459.90 - 1460.60 No previous FVGs\n",
      "2025-10-30 10:15     ASTRAL 🔴 bearish   6.30     1457.70 - 1464.00 No previous FVGs\n",
      "2025-10-30 14:15 BAJAJ-AUTO 🔴 bearish  39.00     8936.50 - 8975.50 No previous FVGs\n",
      "2025-10-30 10:15 BAJAJ-AUTO 🔴 bearish  17.00     9013.00 - 9030.00 No previous FVGs\n",
      "2025-10-30 10:15 BHARATFORG 🔴 bearish   1.70     1318.40 - 1320.10 No previous FVGs\n",
      "2025-10-30 11:15    CEATLTD 🟢 bullish  33.40     4063.00 - 4096.40 No previous FVGs\n",
      "2025-10-30 15:15  CRAFTSMAN 🟢 bullish  38.00     6617.00 - 6655.00 No previous FVGs\n",
      "2025-10-30 10:15  CRAFTSMAN 🟢 bullish  49.50     6480.50 - 6530.00 No previous FVGs\n",
      "2025-10-30 10:15   EXIDEIND 🔴 bearish   1.95       382.30 - 384.25 No previous FVGs\n",
      "2025-10-30 15:15   HINDALCO 🟢 bullish   2.80       858.20 - 861.00 No previous FVGs\n",
      "2025-10-30 10:15 HINDCOPPER 🔴 bearish   2.45       347.95 - 350.40 No previous FVGs\n",
      "2025-10-30 15:15    HYUNDAI 🟢 bullish  46.70     2358.20 - 2404.90 No previous FVGs\n",
      "2025-10-30 10:15  JINDALSAW 🔴 bearish   1.10       176.49 - 177.59 No previous FVGs\n",
      "2025-10-30 15:15 JINDALSTEL 🟢 bullish   1.10     1068.00 - 1069.10 No previous FVGs\n",
      "2025-10-30 12:15     JKTYRE 🟢 bullish   2.15       430.70 - 432.85 No previous FVGs\n",
      "2025-10-30 15:15        KEC 🟢 bullish   3.10       821.90 - 825.00 No previous FVGs\n",
      "2025-10-30 10:15        KEC 🔴 bearish   1.80       823.65 - 825.45 No previous FVGs\n",
      "2025-10-30 13:15        KEI 🟢 bullish  10.20     4094.90 - 4105.10 No previous FVGs\n",
      "2025-10-30 15:15        M&M 🟢 bullish  46.70     2358.20 - 2404.90 No previous FVGs\n",
      "2025-10-30 10:15  MOTHERSON 🔴 bearish   0.05       107.36 - 107.41 No previous FVGs\n",
      "2025-10-30 10:15        MRF 🔴 bearish 380.00 159365.00 - 159745.00 No previous FVGs\n",
      "2025-10-30 15:15 NATIONALUM 🟢 bullish   1.04       236.60 - 237.64 No previous FVGs\n",
      "2025-10-30 10:15 NATIONALUM 🔴 bearish   0.99       236.55 - 237.54 No previous FVGs\n",
      "2025-10-30 12:15    POLYCAB 🟢 bullish  18.50     7791.00 - 7809.50 No previous FVGs\n",
      "2025-10-30 15:15       SAIL 🟢 bullish   0.12       136.46 - 136.58 No previous FVGs\n",
      "2025-10-30 11:15       SAIL 🔴 bearish   0.37       136.83 - 137.20 No previous FVGs\n",
      "2025-10-30 10:15       SAIL 🔴 bearish   1.11       138.40 - 139.51 No previous FVGs\n",
      "2025-10-30 10:15  SHYAMMETL 🔴 bearish   4.15       908.00 - 912.15 No previous FVGs\n",
      "2025-10-30 10:15 SUPREMEIND 🔴 bearish  21.40     3822.70 - 3844.10 No previous FVGs\n",
      "2025-10-30 10:15 TATAMOTORS 🔴 bearish   0.20       410.85 - 411.05 No previous FVGs\n",
      "2025-10-30 15:15  TATASTEEL 🟢 bullish   0.75       183.46 - 184.21 No previous FVGs\n",
      "2025-10-30 10:15  TATASTEEL 🔴 bearish   0.68       184.20 - 184.88 No previous FVGs\n",
      "2025-10-30 14:15    TIINDIA 🔴 bearish  26.10     3075.00 - 3101.10 No previous FVGs\n",
      "2025-10-30 12:15    TIINDIA 🔴 bearish   0.70     3117.90 - 3118.60 No previous FVGs\n",
      "2025-10-30 13:15   TVSMOTOR 🔴 bearish   3.00     3498.00 - 3501.00 No previous FVGs\n",
      "2025-10-30 15:15       VEDL 🟢 bullish   0.40       505.75 - 506.15 No previous FVGs\n",
      "2025-10-30 10:15     VGUARD 🔴 bearish   2.55       377.45 - 380.00 No previous FVGs\n",
      "2025-10-30 12:15    WELCORP 🟢 bullish   8.05       912.00 - 920.05 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 43\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 3  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey2:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS3\n",
    "combined_df = combined_df3\n",
    "key_name = \"Instrument Key 3 (Metals and Auto)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"C:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik3(31-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "    \n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik3(24-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "\n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "\n",
    "    # Add colored symbols and format\n",
    "    def format_row(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "    \n",
    "     # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2f1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey4 = {\n",
    "    \"IRFC\":\"NSE_EQ|INE053F01010\",\n",
    "    \"MAZDOCK\":\"NSE_EQ|INE249Z01020\",\n",
    "    \"BEL\":\"NSE_EQ|INE263A01024\",\n",
    "    \"SOLARINDS\":\"NSE_EQ|INE343H01029\",\n",
    "    \"HAL\":\"NSE_EQ|INE066F01020\",\n",
    "    \"ADANIPORTS\":\"NSE_EQ|INE742F01042\",\n",
    "    \"DELHIVERY\":\"NSE_EQ|INE148O01028\",\n",
    "    \"BLUEDART\":\"NSE_EQ|INE233B01017\",\n",
    "    \"CONCOR\":\"NSE_EQ|INE111A01025\",\n",
    "    \"GODREJAGRO\":\"NSE_EQ|INE850D01014\",\n",
    "    \"DEEPAKFERT\":\"NSE_EQ|INE501A01019\",\n",
    "    \"PIIND\":\"NSE_EQ|INE603J01030\",\n",
    "    \"COROMANDEL\":\"NSE_EQ|INE169A01031\",\n",
    "    \"AARTIIND\":\"NSE_EQ|INE769A01020\",\n",
    "    \"BAYERCROP\":\"NSE_EQ|INE462A01022\",\n",
    "    \"CHAMBLFERT\":\"NSE_EQ|INE085A01013\",\n",
    "    \"ALKYLAMINE\":\"NSE_EQ|INE150B01039\",\n",
    "    \"NAVINFLUOR\":\"NSE_EQ|INE048G01026\",\n",
    "    \"TATACHEM\":\"NSE_EQ|INE092A01019\",\n",
    "    \"SRF\":\"NSE_EQ|INE647A01010\",\n",
    "    \"ANURAS\":\"NSE_EQ|INE930P01018\",\n",
    "    \"UPL\":\"NSE_EQ|INE628A01036\",\n",
    "    \"PIDILITIND\":\"NSE_EQ|INE318A01026\",\n",
    "    \"ATUL\":\"NSE_EQ|INE100A01010\",\n",
    "    \"HSCL\":\"NSE_EQ|INE019C01026\",\n",
    "    \"GODREJIND\":\"NSE_EQ|INE233A01035\",\n",
    "    \"APLLTD\":\"NSE_EQ|INE901L01018\",\n",
    "    \"ERIS\":\"NSE_EQ|INE406M01024\",\n",
    "    \"PFIZER\":\"NSE_EQ|INE182A01018\",\n",
    "    \"DRREDDY\":\"NSE_EQ|INE089A01031\",\n",
    "    \"AJANTPHARM\":\"NSE_EQ|INE031B01049\",\n",
    "    \"LAURUSLABS\":\"NSE_EQ|INE947Q01028\",\n",
    "    \"TORNTPHARM\":\"NSE_EQ|INE685A01028\",\n",
    "    \"JBCHEPHARM\":\"NSE_EQ|INE572A01036\",\n",
    "    \"MANKIND\":\"NSE_EQ|INE634S01028\",\n",
    "    \"ZYDUSLIFE\":\"NSE_EQ|INE010B01027\",\n",
    "    \"COLPAL\":\"NSE_EQ|INE259A01022\",\n",
    "    \"NATCOPHARM\":\"NSE_EQ|INE987B01026\",\n",
    "    \"SANOFI\":\"NSE_EQ|INE058A01010\",\n",
    "    \"GLENMARK\":\"NSE_EQ|INE935A01035\",\n",
    "    \"GRANULES\":\"NSE_EQ|INE101D01020\",\n",
    "    \"ALKEM\":\"NSE_EQ|INE540L01014\",\n",
    "    \"BIOCON\":\"NSE_EQ|INE376G01013\",\n",
    "    \"AUROPHARMA\":\"NSE_EQ|INE406A01037\",\n",
    "    \"DIVISLAB\":\"NSE_EQ|INE361B01024\",\n",
    "    \"GLAXO\":\"NSE_EQ|INE159A01016\",\n",
    "    \"CIPLA\":\"NSE_EQ|INE059A01026\",\n",
    "    \"LUPIN\":\"NSE_EQ|INE326A01037\",\n",
    "    \"ASTRAZEN\":\"NSE_EQ|INE203A01020\",\n",
    "    \"PPLPHARMA\":\"NSE_EQ|INE0DK501011\",\n",
    "    \"SYNGENE\":\"NSE_EQ|INE398R01022\",\n",
    "    \"GLAND\":\"NSE_EQ|INE068V01023\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30911400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for IRFC...\n",
      "Fetching data for MAZDOCK...\n",
      "Fetching data for MAZDOCK...\n",
      "Fetching data for BEL...\n",
      "Fetching data for BEL...\n",
      "Fetching data for SOLARINDS...\n",
      "Fetching data for SOLARINDS...\n",
      "Fetching data for HAL...\n",
      "Fetching data for HAL...\n",
      "Fetching data for ADANIPORTS...\n",
      "Fetching data for ADANIPORTS...\n",
      "Fetching data for DELHIVERY...\n",
      "Fetching data for DELHIVERY...\n",
      "Fetching data for BLUEDART...\n",
      "Fetching data for BLUEDART...\n",
      "Fetching data for CONCOR...\n",
      "Fetching data for CONCOR...\n",
      "Fetching data for GODREJAGRO...\n",
      "Fetching data for GODREJAGRO...\n",
      "Fetching data for DEEPAKFERT...\n",
      "Fetching data for DEEPAKFERT...\n",
      "Fetching data for PIIND...\n",
      "Fetching data for PIIND...\n",
      "Fetching data for COROMANDEL...\n",
      "Fetching data for COROMANDEL...\n",
      "Fetching data for AARTIIND...\n",
      "Fetching data for AARTIIND...\n",
      "Fetching data for BAYERCROP...\n",
      "Fetching data for BAYERCROP...\n",
      "Fetching data for CHAMBLFERT...\n",
      "Fetching data for CHAMBLFERT...\n",
      "Fetching data for ALKYLAMINE...\n",
      "Fetching data for ALKYLAMINE...\n",
      "Fetching data for NAVINFLUOR...\n",
      "Fetching data for NAVINFLUOR...\n",
      "Fetching data for TATACHEM...\n",
      "Fetching data for TATACHEM...\n",
      "Fetching data for SRF...\n",
      "Fetching data for SRF...\n",
      "Fetching data for ANURAS...\n",
      "Fetching data for ANURAS...\n",
      "Fetching data for UPL...\n",
      "Fetching data for UPL...\n",
      "Fetching data for PIDILITIND...\n",
      "Fetching data for PIDILITIND...\n",
      "Fetching data for ATUL...\n",
      "Fetching data for ATUL...\n",
      "Fetching data for HSCL...\n",
      "Fetching data for HSCL...\n",
      "Fetching data for GODREJIND...\n",
      "Fetching data for GODREJIND...\n",
      "Fetching data for APLLTD...\n",
      "Fetching data for APLLTD...\n",
      "Fetching data for ERIS...\n",
      "Fetching data for ERIS...\n",
      "Fetching data for PFIZER...\n",
      "Fetching data for PFIZER...\n",
      "Fetching data for DRREDDY...\n",
      "Fetching data for DRREDDY...\n",
      "Fetching data for AJANTPHARM...\n",
      "Fetching data for AJANTPHARM...\n",
      "Fetching data for LAURUSLABS...\n",
      "Fetching data for LAURUSLABS...\n",
      "Fetching data for TORNTPHARM...\n",
      "Fetching data for TORNTPHARM...\n",
      "Fetching data for JBCHEPHARM...\n",
      "Fetching data for JBCHEPHARM...\n",
      "Fetching data for MANKIND...\n",
      "Fetching data for MANKIND...\n",
      "Fetching data for ZYDUSLIFE...\n",
      "Fetching data for ZYDUSLIFE...\n",
      "Fetching data for COLPAL...\n",
      "Fetching data for COLPAL...\n",
      "Fetching data for NATCOPHARM...\n",
      "Fetching data for NATCOPHARM...\n",
      "Fetching data for SANOFI...\n",
      "Fetching data for SANOFI...\n",
      "Fetching data for GLENMARK...\n",
      "Fetching data for GLENMARK...\n",
      "Fetching data for GRANULES...\n",
      "Fetching data for GRANULES...\n",
      "Fetching data for ALKEM...\n",
      "Fetching data for ALKEM...\n",
      "Fetching data for BIOCON...\n",
      "Fetching data for BIOCON...\n",
      "Fetching data for AUROPHARMA...\n",
      "Fetching data for AUROPHARMA...\n",
      "Fetching data for DIVISLAB...\n",
      "Fetching data for DIVISLAB...\n",
      "Fetching data for GLAXO...\n",
      "Fetching data for GLAXO...\n",
      "Fetching data for CIPLA...\n",
      "Fetching data for CIPLA...\n",
      "Fetching data for LUPIN...\n",
      "Fetching data for LUPIN...\n",
      "Fetching data for ASTRAZEN...\n",
      "Fetching data for ASTRAZEN...\n",
      "Fetching data for PPLPHARMA...\n",
      "Fetching data for PPLPHARMA...\n",
      "Fetching data for SYNGENE...\n",
      "Fetching data for SYNGENE...\n",
      "Fetching data for GLAND...\n",
      "Fetching data for GLAND...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AARTIIND</th>\n",
       "      <th>ADANIPORTS</th>\n",
       "      <th>AJANTPHARM</th>\n",
       "      <th>ALKEM</th>\n",
       "      <th>ALKYLAMINE</th>\n",
       "      <th>ANURAS</th>\n",
       "      <th>APLLTD</th>\n",
       "      <th>ASTRAZEN</th>\n",
       "      <th>ATUL</th>\n",
       "      <th>AUROPHARMA</th>\n",
       "      <th>...</th>\n",
       "      <th>PIIND</th>\n",
       "      <th>PPLPHARMA</th>\n",
       "      <th>SANOFI</th>\n",
       "      <th>SOLARINDS</th>\n",
       "      <th>SRF</th>\n",
       "      <th>SYNGENE</th>\n",
       "      <th>TATACHEM</th>\n",
       "      <th>TORNTPHARM</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ZYDUSLIFE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, AARTIIND), (Close, ADANIPORTS), (Close, AJANTPHARM), (Close, ALKEM), (Close, ALKYLAMINE), (Close, ANURAS), (Close, APLLTD), (Close, ASTRAZEN), (Close, ATUL), (Close, AUROPHARMA), (Close, BAYERCROP), (Close, BEL), (Close, BIOCON), (Close, BLUEDART), (Close, CHAMBLFERT), (Close, CIPLA), (Close, COLPAL), (Close, CONCOR), (Close, COROMANDEL), (Close, DEEPAKFERT), (Close, DELHIVERY), (Close, DIVISLAB), (Close, DRREDDY), (Close, ERIS), (Close, GLAND), (Close, GLAXO), (Close, GLENMARK), (Close, GODREJAGRO), (Close, GODREJIND), (Close, GRANULES), (Close, HAL), (Close, HSCL), (Close, IRFC), (Close, JBCHEPHARM), (Close, LAURUSLABS), (Close, LUPIN), (Close, MANKIND), (Close, MAZDOCK), (Close, NATCOPHARM), (Close, NAVINFLUOR), (Close, PFIZER), (Close, PIDILITIND), (Close, PIIND), (Close, PPLPHARMA), (Close, SANOFI), (Close, SOLARINDS), (Close, SRF), (Close, SYNGENE), (Close, TATACHEM), (Close, TORNTPHARM), (Close, UPL), (Close, ZYDUSLIFE), (High, AARTIIND), (High, ADANIPORTS), (High, AJANTPHARM), (High, ALKEM), (High, ALKYLAMINE), (High, ANURAS), (High, APLLTD), (High, ASTRAZEN), (High, ATUL), (High, AUROPHARMA), (High, BAYERCROP), (High, BEL), (High, BIOCON), (High, BLUEDART), (High, CHAMBLFERT), (High, CIPLA), (High, COLPAL), (High, CONCOR), (High, COROMANDEL), (High, DEEPAKFERT), (High, DELHIVERY), (High, DIVISLAB), (High, DRREDDY), (High, ERIS), (High, GLAND), (High, GLAXO), (High, GLENMARK), (High, GODREJAGRO), (High, GODREJIND), (High, GRANULES), (High, HAL), (High, HSCL), (High, IRFC), (High, JBCHEPHARM), (High, LAURUSLABS), (High, LUPIN), (High, MANKIND), (High, MAZDOCK), (High, NATCOPHARM), (High, NAVINFLUOR), (High, PFIZER), (High, PIDILITIND), (High, PIIND), (High, PPLPHARMA), (High, SANOFI), (High, SOLARINDS), (High, SRF), (High, SYNGENE), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AARTIIND</th>\n",
       "      <th>ADANIPORTS</th>\n",
       "      <th>AJANTPHARM</th>\n",
       "      <th>ALKEM</th>\n",
       "      <th>ALKYLAMINE</th>\n",
       "      <th>ANURAS</th>\n",
       "      <th>APLLTD</th>\n",
       "      <th>ASTRAZEN</th>\n",
       "      <th>ATUL</th>\n",
       "      <th>AUROPHARMA</th>\n",
       "      <th>...</th>\n",
       "      <th>PIIND</th>\n",
       "      <th>PPLPHARMA</th>\n",
       "      <th>SANOFI</th>\n",
       "      <th>SOLARINDS</th>\n",
       "      <th>SRF</th>\n",
       "      <th>SYNGENE</th>\n",
       "      <th>TATACHEM</th>\n",
       "      <th>TORNTPHARM</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ZYDUSLIFE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>383.70</td>\n",
       "      <td>1454.4</td>\n",
       "      <td>2448.2</td>\n",
       "      <td>5476.5</td>\n",
       "      <td>1885.8</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>895.35</td>\n",
       "      <td>9283.5</td>\n",
       "      <td>5840.0</td>\n",
       "      <td>1097.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14098.0</td>\n",
       "      <td>690550.0</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>56588.0</td>\n",
       "      <td>149605.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>21003.0</td>\n",
       "      <td>365709.0</td>\n",
       "      <td>172675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>382.20</td>\n",
       "      <td>1462.7</td>\n",
       "      <td>2463.8</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>1889.6</td>\n",
       "      <td>1087.3</td>\n",
       "      <td>899.00</td>\n",
       "      <td>9306.5</td>\n",
       "      <td>5830.0</td>\n",
       "      <td>1103.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>350920.0</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>3396.0</td>\n",
       "      <td>68575.0</td>\n",
       "      <td>22970.0</td>\n",
       "      <td>42999.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>89098.0</td>\n",
       "      <td>97046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>383.20</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>2469.4</td>\n",
       "      <td>5503.0</td>\n",
       "      <td>1892.1</td>\n",
       "      <td>1090.4</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9372.0</td>\n",
       "      <td>5825.5</td>\n",
       "      <td>1104.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5090.0</td>\n",
       "      <td>459225.0</td>\n",
       "      <td>5093.0</td>\n",
       "      <td>7227.0</td>\n",
       "      <td>45366.0</td>\n",
       "      <td>35750.0</td>\n",
       "      <td>24766.0</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>260647.0</td>\n",
       "      <td>66629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>382.45</td>\n",
       "      <td>1455.8</td>\n",
       "      <td>2472.2</td>\n",
       "      <td>5510.5</td>\n",
       "      <td>1889.9</td>\n",
       "      <td>1088.5</td>\n",
       "      <td>898.05</td>\n",
       "      <td>9353.5</td>\n",
       "      <td>5824.0</td>\n",
       "      <td>1107.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.0</td>\n",
       "      <td>186060.0</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>6690.0</td>\n",
       "      <td>62676.0</td>\n",
       "      <td>13610.0</td>\n",
       "      <td>25833.0</td>\n",
       "      <td>10070.0</td>\n",
       "      <td>1169716.0</td>\n",
       "      <td>65964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>381.50</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>2460.9</td>\n",
       "      <td>5519.5</td>\n",
       "      <td>1886.6</td>\n",
       "      <td>1097.6</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9359.5</td>\n",
       "      <td>5826.5</td>\n",
       "      <td>1104.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17753.0</td>\n",
       "      <td>303598.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>40491.0</td>\n",
       "      <td>71429.0</td>\n",
       "      <td>63360.0</td>\n",
       "      <td>33356.0</td>\n",
       "      <td>424469.0</td>\n",
       "      <td>130853.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                        Close                                                                                       ...   Volume                                                           \\\n",
       "Ticker                    AARTIIND ADANIPORTS AJANTPHARM   ALKEM ALKYLAMINE  ANURAS  APLLTD ASTRAZEN    ATUL AUROPHARMA  ...    PIIND PPLPHARMA   SANOFI SOLARINDS      SRF   SYNGENE TATACHEM   \n",
       "Datetime                                                                                                                 ...                                                                     \n",
       "2025-10-30 09:15:00+05:30   383.70     1454.4     2448.2  5476.5     1885.8  1086.5  895.35   9283.5  5840.0     1097.8  ...  14098.0  690550.0  13644.0    9125.0  56588.0  149605.0  65534.0   \n",
       "2025-10-30 10:15:00+05:30   382.20     1462.7     2463.8  5506.0     1889.6  1087.3  899.00   9306.5  5830.0     1103.2  ...   3074.0  350920.0   3785.0    3396.0  68575.0   22970.0  42999.0   \n",
       "2025-10-30 11:15:00+05:30   383.20     1459.0     2469.4  5503.0     1892.1  1090.4  900.00   9372.0  5825.5     1104.3  ...   5090.0  459225.0   5093.0    7227.0  45366.0   35750.0  24766.0   \n",
       "2025-10-30 12:15:00+05:30   382.45     1455.8     2472.2  5510.5     1889.9  1088.5  898.05   9353.5  5824.0     1107.5  ...   8138.0  186060.0   2819.0    6690.0  62676.0   13610.0  25833.0   \n",
       "2025-10-30 13:15:00+05:30   381.50     1456.0     2460.9  5519.5     1886.6  1097.6  900.00   9359.5  5826.5     1104.4  ...  17753.0  303598.0   1691.0    3991.0  40491.0   71429.0  63360.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                    TORNTPHARM        UPL ZYDUSLIFE  \n",
       "Datetime                                                   \n",
       "2025-10-30 09:15:00+05:30    21003.0   365709.0  172675.0  \n",
       "2025-10-30 10:15:00+05:30     9208.0    89098.0   97046.0  \n",
       "2025-10-30 11:15:00+05:30     8033.0   260647.0   66629.0  \n",
       "2025-10-30 12:15:00+05:30    10070.0  1169716.0   65964.0  \n",
       "2025-10-30 13:15:00+05:30    33356.0   424469.0  130853.0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intraday data for instruement key 4 \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS4 = instrumentkey4\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS4.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "    \n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "\n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index4 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index4\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5e1ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 260)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AARTIIND</th>\n",
       "      <th>ADANIPORTS</th>\n",
       "      <th>AJANTPHARM</th>\n",
       "      <th>ALKEM</th>\n",
       "      <th>ALKYLAMINE</th>\n",
       "      <th>ANURAS</th>\n",
       "      <th>APLLTD</th>\n",
       "      <th>ASTRAZEN</th>\n",
       "      <th>ATUL</th>\n",
       "      <th>AUROPHARMA</th>\n",
       "      <th>...</th>\n",
       "      <th>PIIND</th>\n",
       "      <th>PPLPHARMA</th>\n",
       "      <th>SANOFI</th>\n",
       "      <th>SOLARINDS</th>\n",
       "      <th>SRF</th>\n",
       "      <th>SYNGENE</th>\n",
       "      <th>TATACHEM</th>\n",
       "      <th>TORNTPHARM</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ZYDUSLIFE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>385.55</td>\n",
       "      <td>1456.2</td>\n",
       "      <td>2460.8</td>\n",
       "      <td>5527.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1088.5</td>\n",
       "      <td>901.00</td>\n",
       "      <td>9344.5</td>\n",
       "      <td>5892.5</td>\n",
       "      <td>1110.4</td>\n",
       "      <td>...</td>\n",
       "      <td>24004.0</td>\n",
       "      <td>294062.0</td>\n",
       "      <td>26157.0</td>\n",
       "      <td>4721.0</td>\n",
       "      <td>113077.0</td>\n",
       "      <td>29888.0</td>\n",
       "      <td>60326.0</td>\n",
       "      <td>22757.0</td>\n",
       "      <td>579944.0</td>\n",
       "      <td>133850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>386.00</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>2456.9</td>\n",
       "      <td>5544.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1091.6</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9338.0</td>\n",
       "      <td>5888.0</td>\n",
       "      <td>1111.2</td>\n",
       "      <td>...</td>\n",
       "      <td>12849.0</td>\n",
       "      <td>213786.0</td>\n",
       "      <td>6459.0</td>\n",
       "      <td>4957.0</td>\n",
       "      <td>30443.0</td>\n",
       "      <td>34130.0</td>\n",
       "      <td>49007.0</td>\n",
       "      <td>10475.0</td>\n",
       "      <td>446874.0</td>\n",
       "      <td>124475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>383.70</td>\n",
       "      <td>1454.4</td>\n",
       "      <td>2448.2</td>\n",
       "      <td>5476.5</td>\n",
       "      <td>1885.8</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>895.35</td>\n",
       "      <td>9283.5</td>\n",
       "      <td>5840.0</td>\n",
       "      <td>1097.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14098.0</td>\n",
       "      <td>690550.0</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>56588.0</td>\n",
       "      <td>149605.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>21003.0</td>\n",
       "      <td>365709.0</td>\n",
       "      <td>172675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>382.20</td>\n",
       "      <td>1462.7</td>\n",
       "      <td>2463.8</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>1889.6</td>\n",
       "      <td>1087.3</td>\n",
       "      <td>899.00</td>\n",
       "      <td>9306.5</td>\n",
       "      <td>5830.0</td>\n",
       "      <td>1103.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>350920.0</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>3396.0</td>\n",
       "      <td>68575.0</td>\n",
       "      <td>22970.0</td>\n",
       "      <td>42999.0</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>89098.0</td>\n",
       "      <td>97046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>383.20</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>2469.4</td>\n",
       "      <td>5503.0</td>\n",
       "      <td>1892.1</td>\n",
       "      <td>1090.4</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9372.0</td>\n",
       "      <td>5825.5</td>\n",
       "      <td>1104.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5090.0</td>\n",
       "      <td>459225.0</td>\n",
       "      <td>5093.0</td>\n",
       "      <td>7227.0</td>\n",
       "      <td>45366.0</td>\n",
       "      <td>35750.0</td>\n",
       "      <td>24766.0</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>260647.0</td>\n",
       "      <td>66629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>382.45</td>\n",
       "      <td>1455.8</td>\n",
       "      <td>2472.2</td>\n",
       "      <td>5510.5</td>\n",
       "      <td>1889.9</td>\n",
       "      <td>1088.5</td>\n",
       "      <td>898.05</td>\n",
       "      <td>9353.5</td>\n",
       "      <td>5824.0</td>\n",
       "      <td>1107.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.0</td>\n",
       "      <td>186060.0</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>6690.0</td>\n",
       "      <td>62676.0</td>\n",
       "      <td>13610.0</td>\n",
       "      <td>25833.0</td>\n",
       "      <td>10070.0</td>\n",
       "      <td>1169716.0</td>\n",
       "      <td>65964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>381.50</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>2460.9</td>\n",
       "      <td>5519.5</td>\n",
       "      <td>1886.6</td>\n",
       "      <td>1097.6</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9359.5</td>\n",
       "      <td>5826.5</td>\n",
       "      <td>1104.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17753.0</td>\n",
       "      <td>303598.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>40491.0</td>\n",
       "      <td>71429.0</td>\n",
       "      <td>63360.0</td>\n",
       "      <td>33356.0</td>\n",
       "      <td>424469.0</td>\n",
       "      <td>130853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>382.65</td>\n",
       "      <td>1456.4</td>\n",
       "      <td>2469.9</td>\n",
       "      <td>5530.5</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1097.2</td>\n",
       "      <td>899.45</td>\n",
       "      <td>9462.5</td>\n",
       "      <td>5814.5</td>\n",
       "      <td>1102.9</td>\n",
       "      <td>...</td>\n",
       "      <td>15339.0</td>\n",
       "      <td>280004.0</td>\n",
       "      <td>2839.0</td>\n",
       "      <td>9137.0</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>50352.0</td>\n",
       "      <td>37543.0</td>\n",
       "      <td>35598.0</td>\n",
       "      <td>904683.0</td>\n",
       "      <td>132690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>383.00</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>2463.8</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>900.00</td>\n",
       "      <td>9469.0</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9092.0</td>\n",
       "      <td>225184.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>5470.0</td>\n",
       "      <td>41017.0</td>\n",
       "      <td>36233.0</td>\n",
       "      <td>31896.0</td>\n",
       "      <td>13760.0</td>\n",
       "      <td>358864.0</td>\n",
       "      <td>84553.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                        Close                                                                                       ...   Volume                                                            \\\n",
       "Ticker                    AARTIIND ADANIPORTS AJANTPHARM   ALKEM ALKYLAMINE  ANURAS  APLLTD ASTRAZEN    ATUL AUROPHARMA  ...    PIIND PPLPHARMA   SANOFI SOLARINDS       SRF   SYNGENE TATACHEM   \n",
       "Datetime                                                                                                                 ...                                                                      \n",
       "2025-10-29 14:15:00+05:30   385.55     1456.2     2460.8  5527.0     1905.0  1088.5  901.00   9344.5  5892.5     1110.4  ...  24004.0  294062.0  26157.0    4721.0  113077.0   29888.0  60326.0   \n",
       "2025-10-29 15:15:00+05:30   386.00     1456.0     2456.9  5544.0     1910.0  1091.6  900.00   9338.0  5888.0     1111.2  ...  12849.0  213786.0   6459.0    4957.0   30443.0   34130.0  49007.0   \n",
       "2025-10-30 09:15:00+05:30   383.70     1454.4     2448.2  5476.5     1885.8  1086.5  895.35   9283.5  5840.0     1097.8  ...  14098.0  690550.0  13644.0    9125.0   56588.0  149605.0  65534.0   \n",
       "2025-10-30 10:15:00+05:30   382.20     1462.7     2463.8  5506.0     1889.6  1087.3  899.00   9306.5  5830.0     1103.2  ...   3074.0  350920.0   3785.0    3396.0   68575.0   22970.0  42999.0   \n",
       "2025-10-30 11:15:00+05:30   383.20     1459.0     2469.4  5503.0     1892.1  1090.4  900.00   9372.0  5825.5     1104.3  ...   5090.0  459225.0   5093.0    7227.0   45366.0   35750.0  24766.0   \n",
       "2025-10-30 12:15:00+05:30   382.45     1455.8     2472.2  5510.5     1889.9  1088.5  898.05   9353.5  5824.0     1107.5  ...   8138.0  186060.0   2819.0    6690.0   62676.0   13610.0  25833.0   \n",
       "2025-10-30 13:15:00+05:30   381.50     1456.0     2460.9  5519.5     1886.6  1097.6  900.00   9359.5  5826.5     1104.4  ...  17753.0  303598.0   1691.0    3991.0   40491.0   71429.0  63360.0   \n",
       "2025-10-30 14:15:00+05:30   382.65     1456.4     2469.9  5530.5     1884.0  1097.2  899.45   9462.5  5814.5     1102.9  ...  15339.0  280004.0   2839.0    9137.0   81892.0   50352.0  37543.0   \n",
       "2025-10-30 15:15:00+05:30   383.00     1458.0     2463.8  5510.0     1895.0  1097.0  900.00   9469.0  5810.0     1105.0  ...   9092.0  225184.0   3013.0    5470.0   41017.0   36233.0  31896.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                    TORNTPHARM        UPL ZYDUSLIFE  \n",
       "Datetime                                                   \n",
       "2025-10-29 14:15:00+05:30    22757.0   579944.0  133850.0  \n",
       "2025-10-29 15:15:00+05:30    10475.0   446874.0  124475.0  \n",
       "2025-10-30 09:15:00+05:30    21003.0   365709.0  172675.0  \n",
       "2025-10-30 10:15:00+05:30     9208.0    89098.0   97046.0  \n",
       "2025-10-30 11:15:00+05:30     8033.0   260647.0   66629.0  \n",
       "2025-10-30 12:15:00+05:30    10070.0  1169716.0   65964.0  \n",
       "2025-10-30 13:15:00+05:30    33356.0   424469.0  130853.0  \n",
       "2025-10-30 14:15:00+05:30    35598.0   904683.0  132690.0  \n",
       "2025-10-30 15:15:00+05:30    13760.0   358864.0   84553.0  \n",
       "\n",
       "[9 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik4.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index4  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df4 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df4 = combined_df4[~combined_df4.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df4.shape)\n",
    "print(combined_df4.index.names)\n",
    "print(combined_df4.columns.names)\n",
    "display(combined_df4.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac9aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FVG detection results saved to: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik4(30-10).pkl\n",
      "Master results updated at: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 4 (Defence, Chemical and Pharma etc.) (date: 2025-10-30):\n",
      "        Datetime     Ticker   Pattern    Gap               Range    Previous_FVGs\n",
      "2025-10-30 10:15   AARTIIND 🔴 bearish   1.70     383.70 - 385.40 No previous FVGs\n",
      "2025-10-30 10:15 ALKYLAMINE 🔴 bearish   5.20   1890.00 - 1895.20 No previous FVGs\n",
      "2025-10-30 14:15     ANURAS 🟢 bullish   0.90   1092.30 - 1093.20 No previous FVGs\n",
      "2025-10-30 15:15   ASTRAZEN 🟢 bullish  54.50   9390.50 - 9445.00 No previous FVGs\n",
      "2025-10-30 12:15   ASTRAZEN 🟢 bullish  31.00   9319.50 - 9350.50 No previous FVGs\n",
      "2025-10-30 10:15   ASTRAZEN 🔴 bearish  18.50   9319.50 - 9338.00 No previous FVGs\n",
      "2025-10-30 10:15       ATUL 🔴 bearish  34.00   5854.00 - 5888.00 No previous FVGs\n",
      "2025-10-30 10:15 AUROPHARMA 🔴 bearish   5.60   1104.70 - 1110.30 No previous FVGs\n",
      "2025-10-30 11:15        BEL 🟢 bullish   0.35     408.50 - 408.85 No previous FVGs\n",
      "2025-10-30 15:15   BLUEDART 🔴 bearish  35.00   6745.00 - 6780.00 No previous FVGs\n",
      "2025-10-30 10:15   BLUEDART 🟢 bullish 111.00   6645.00 - 6756.00 No previous FVGs\n",
      "2025-10-30 10:15 CHAMBLFERT 🔴 bearish   7.65     486.65 - 494.30 No previous FVGs\n",
      "2025-10-30 14:15      CIPLA 🔴 bearish  14.70   1551.60 - 1566.30 No previous FVGs\n",
      "2025-10-30 10:15      CIPLA 🔴 bearish   5.70   1573.00 - 1578.70 No previous FVGs\n",
      "2025-10-30 10:15     COLPAL 🔴 bearish   6.40   2258.20 - 2264.60 No previous FVGs\n",
      "2025-10-30 14:15 COROMANDEL 🔴 bearish  27.90   2202.10 - 2230.00 No previous FVGs\n",
      "2025-10-30 10:15 COROMANDEL 🔴 bearish   7.90   2243.00 - 2250.90 No previous FVGs\n",
      "2025-10-30 10:15 DEEPAKFERT 🔴 bearish   5.40   1494.60 - 1500.00 No previous FVGs\n",
      "2025-10-30 10:15  DELHIVERY 🔴 bearish   3.50     477.05 - 480.55 No previous FVGs\n",
      "2025-10-30 11:15   DIVISLAB 🟢 bullish  36.50   6610.00 - 6646.50 No previous FVGs\n",
      "2025-10-30 10:15   DIVISLAB 🟢 bullish  83.00   6525.50 - 6608.50 No previous FVGs\n",
      "2025-10-30 09:15    DRREDDY 🔴 bearish  34.60   1200.40 - 1235.00 No previous FVGs\n",
      "2025-10-30 10:15       ERIS 🔴 bearish  13.20   1613.90 - 1627.10 No previous FVGs\n",
      "2025-10-30 15:15      GLAND 🟢 bullish   2.10   1907.60 - 1909.70 No previous FVGs\n",
      "2025-10-30 10:15      GLAXO 🔴 bearish   1.20   2632.80 - 2634.00 No previous FVGs\n",
      "2025-10-30 15:15   GLENMARK 🟢 bullish   0.60   1880.40 - 1881.00 No previous FVGs\n",
      "2025-10-30 11:15   GLENMARK 🟢 bullish   3.60   1853.00 - 1856.60 No previous FVGs\n",
      "2025-10-30 10:15 GODREJAGRO 🔴 bearish   1.50     663.50 - 665.00 No previous FVGs\n",
      "2025-10-30 15:15  GODREJIND 🟢 bullish   2.00   1093.00 - 1095.00 No previous FVGs\n",
      "2025-10-30 10:15        HAL 🔴 bearish  24.30   4667.80 - 4692.10 No previous FVGs\n",
      "2025-10-30 10:15       IRFC 🔴 bearish   0.50     124.46 - 124.96 No previous FVGs\n",
      "2025-10-30 15:15 JBCHEPHARM 🟢 bullish   3.20   1701.90 - 1705.10 No previous FVGs\n",
      "2025-10-30 15:15 LAURUSLABS 🟢 bullish   0.95     963.80 - 964.75 No previous FVGs\n",
      "2025-10-30 13:15 LAURUSLABS 🟢 bullish   0.30     959.50 - 959.80 No previous FVGs\n",
      "2025-10-30 10:15      LUPIN 🔴 bearish  15.10   1938.30 - 1953.40 No previous FVGs\n",
      "2025-10-30 12:15    MAZDOCK 🔴 bearish   0.70   2752.30 - 2753.00 No previous FVGs\n",
      "2025-10-30 15:15 NATCOPHARM 🟢 bullish   2.45     828.20 - 830.65 No previous FVGs\n",
      "2025-10-30 15:15 NAVINFLUOR 🟢 bullish  50.20   4922.00 - 4972.20 No previous FVGs\n",
      "2025-10-30 13:15 NAVINFLUOR 🔴 bearish  21.10   4922.00 - 4943.10 No previous FVGs\n",
      "2025-10-30 10:15 NAVINFLUOR 🔴 bearish   2.20   4969.80 - 4972.00 No previous FVGs\n",
      "2025-10-30 15:15     PFIZER 🟢 bullish  41.50   5252.00 - 5293.50 No previous FVGs\n",
      "2025-10-30 10:15     PFIZER 🔴 bearish   7.50   5252.50 - 5260.00 No previous FVGs\n",
      "2025-10-30 15:15 PIDILITIND 🔴 bearish   6.10   1489.00 - 1495.10 No previous FVGs\n",
      "2025-10-30 10:15 PIDILITIND 🔴 bearish   5.20   1501.80 - 1507.00 No previous FVGs\n",
      "2025-10-30 10:15      PIIND 🔴 bearish   7.50   3592.60 - 3600.10 No previous FVGs\n",
      "2025-10-30 10:15  PPLPHARMA 🔴 bearish   0.07     203.45 - 203.52 No previous FVGs\n",
      "2025-10-30 15:15  SOLARINDS 🟢 bullish  25.00 13870.00 - 13895.00 No previous FVGs\n",
      "2025-10-30 10:15  SOLARINDS 🔴 bearish  39.00 13893.00 - 13932.00 No previous FVGs\n",
      "2025-10-30 10:15        SRF 🔴 bearish  11.80   2999.10 - 3010.90 No previous FVGs\n",
      "2025-10-30 12:15    SYNGENE 🔴 bearish   0.05     653.15 - 653.20 No previous FVGs\n",
      "2025-10-30 10:15    SYNGENE 🔴 bearish   1.15     657.20 - 658.35 No previous FVGs\n",
      "2025-10-30 13:15   TATACHEM 🔴 bearish   0.85     902.65 - 903.50 No previous FVGs\n",
      "2025-10-30 10:15   TATACHEM 🔴 bearish   3.45     907.05 - 910.50 No previous FVGs\n",
      "2025-10-30 15:15 TORNTPHARM 🟢 bullish   7.00   3594.50 - 3601.50 No previous FVGs\n",
      "2025-10-30 10:15        UPL 🔴 bearish   0.65     716.10 - 716.75 No previous FVGs\n",
      "2025-10-30 10:15  ZYDUSLIFE 🔴 bearish   8.30    993.15 - 1001.45 No previous FVGs\n",
      "        Datetime     Ticker   Pattern    Gap               Range    Previous_FVGs\n",
      "2025-10-30 10:15   AARTIIND 🔴 bearish   1.70     383.70 - 385.40 No previous FVGs\n",
      "2025-10-30 10:15 ALKYLAMINE 🔴 bearish   5.20   1890.00 - 1895.20 No previous FVGs\n",
      "2025-10-30 14:15     ANURAS 🟢 bullish   0.90   1092.30 - 1093.20 No previous FVGs\n",
      "2025-10-30 15:15   ASTRAZEN 🟢 bullish  54.50   9390.50 - 9445.00 No previous FVGs\n",
      "2025-10-30 12:15   ASTRAZEN 🟢 bullish  31.00   9319.50 - 9350.50 No previous FVGs\n",
      "2025-10-30 10:15   ASTRAZEN 🔴 bearish  18.50   9319.50 - 9338.00 No previous FVGs\n",
      "2025-10-30 10:15       ATUL 🔴 bearish  34.00   5854.00 - 5888.00 No previous FVGs\n",
      "2025-10-30 10:15 AUROPHARMA 🔴 bearish   5.60   1104.70 - 1110.30 No previous FVGs\n",
      "2025-10-30 11:15        BEL 🟢 bullish   0.35     408.50 - 408.85 No previous FVGs\n",
      "2025-10-30 15:15   BLUEDART 🔴 bearish  35.00   6745.00 - 6780.00 No previous FVGs\n",
      "2025-10-30 10:15   BLUEDART 🟢 bullish 111.00   6645.00 - 6756.00 No previous FVGs\n",
      "2025-10-30 10:15 CHAMBLFERT 🔴 bearish   7.65     486.65 - 494.30 No previous FVGs\n",
      "2025-10-30 14:15      CIPLA 🔴 bearish  14.70   1551.60 - 1566.30 No previous FVGs\n",
      "2025-10-30 10:15      CIPLA 🔴 bearish   5.70   1573.00 - 1578.70 No previous FVGs\n",
      "2025-10-30 10:15     COLPAL 🔴 bearish   6.40   2258.20 - 2264.60 No previous FVGs\n",
      "2025-10-30 14:15 COROMANDEL 🔴 bearish  27.90   2202.10 - 2230.00 No previous FVGs\n",
      "2025-10-30 10:15 COROMANDEL 🔴 bearish   7.90   2243.00 - 2250.90 No previous FVGs\n",
      "2025-10-30 10:15 DEEPAKFERT 🔴 bearish   5.40   1494.60 - 1500.00 No previous FVGs\n",
      "2025-10-30 10:15  DELHIVERY 🔴 bearish   3.50     477.05 - 480.55 No previous FVGs\n",
      "2025-10-30 11:15   DIVISLAB 🟢 bullish  36.50   6610.00 - 6646.50 No previous FVGs\n",
      "2025-10-30 10:15   DIVISLAB 🟢 bullish  83.00   6525.50 - 6608.50 No previous FVGs\n",
      "2025-10-30 09:15    DRREDDY 🔴 bearish  34.60   1200.40 - 1235.00 No previous FVGs\n",
      "2025-10-30 10:15       ERIS 🔴 bearish  13.20   1613.90 - 1627.10 No previous FVGs\n",
      "2025-10-30 15:15      GLAND 🟢 bullish   2.10   1907.60 - 1909.70 No previous FVGs\n",
      "2025-10-30 10:15      GLAXO 🔴 bearish   1.20   2632.80 - 2634.00 No previous FVGs\n",
      "2025-10-30 15:15   GLENMARK 🟢 bullish   0.60   1880.40 - 1881.00 No previous FVGs\n",
      "2025-10-30 11:15   GLENMARK 🟢 bullish   3.60   1853.00 - 1856.60 No previous FVGs\n",
      "2025-10-30 10:15 GODREJAGRO 🔴 bearish   1.50     663.50 - 665.00 No previous FVGs\n",
      "2025-10-30 15:15  GODREJIND 🟢 bullish   2.00   1093.00 - 1095.00 No previous FVGs\n",
      "2025-10-30 10:15        HAL 🔴 bearish  24.30   4667.80 - 4692.10 No previous FVGs\n",
      "2025-10-30 10:15       IRFC 🔴 bearish   0.50     124.46 - 124.96 No previous FVGs\n",
      "2025-10-30 15:15 JBCHEPHARM 🟢 bullish   3.20   1701.90 - 1705.10 No previous FVGs\n",
      "2025-10-30 15:15 LAURUSLABS 🟢 bullish   0.95     963.80 - 964.75 No previous FVGs\n",
      "2025-10-30 13:15 LAURUSLABS 🟢 bullish   0.30     959.50 - 959.80 No previous FVGs\n",
      "2025-10-30 10:15      LUPIN 🔴 bearish  15.10   1938.30 - 1953.40 No previous FVGs\n",
      "2025-10-30 12:15    MAZDOCK 🔴 bearish   0.70   2752.30 - 2753.00 No previous FVGs\n",
      "2025-10-30 15:15 NATCOPHARM 🟢 bullish   2.45     828.20 - 830.65 No previous FVGs\n",
      "2025-10-30 15:15 NAVINFLUOR 🟢 bullish  50.20   4922.00 - 4972.20 No previous FVGs\n",
      "2025-10-30 13:15 NAVINFLUOR 🔴 bearish  21.10   4922.00 - 4943.10 No previous FVGs\n",
      "2025-10-30 10:15 NAVINFLUOR 🔴 bearish   2.20   4969.80 - 4972.00 No previous FVGs\n",
      "2025-10-30 15:15     PFIZER 🟢 bullish  41.50   5252.00 - 5293.50 No previous FVGs\n",
      "2025-10-30 10:15     PFIZER 🔴 bearish   7.50   5252.50 - 5260.00 No previous FVGs\n",
      "2025-10-30 15:15 PIDILITIND 🔴 bearish   6.10   1489.00 - 1495.10 No previous FVGs\n",
      "2025-10-30 10:15 PIDILITIND 🔴 bearish   5.20   1501.80 - 1507.00 No previous FVGs\n",
      "2025-10-30 10:15      PIIND 🔴 bearish   7.50   3592.60 - 3600.10 No previous FVGs\n",
      "2025-10-30 10:15  PPLPHARMA 🔴 bearish   0.07     203.45 - 203.52 No previous FVGs\n",
      "2025-10-30 15:15  SOLARINDS 🟢 bullish  25.00 13870.00 - 13895.00 No previous FVGs\n",
      "2025-10-30 10:15  SOLARINDS 🔴 bearish  39.00 13893.00 - 13932.00 No previous FVGs\n",
      "2025-10-30 10:15        SRF 🔴 bearish  11.80   2999.10 - 3010.90 No previous FVGs\n",
      "2025-10-30 12:15    SYNGENE 🔴 bearish   0.05     653.15 - 653.20 No previous FVGs\n",
      "2025-10-30 10:15    SYNGENE 🔴 bearish   1.15     657.20 - 658.35 No previous FVGs\n",
      "2025-10-30 13:15   TATACHEM 🔴 bearish   0.85     902.65 - 903.50 No previous FVGs\n",
      "2025-10-30 10:15   TATACHEM 🔴 bearish   3.45     907.05 - 910.50 No previous FVGs\n",
      "2025-10-30 15:15 TORNTPHARM 🟢 bullish   7.00   3594.50 - 3601.50 No previous FVGs\n",
      "2025-10-30 10:15        UPL 🔴 bearish   0.65     716.10 - 716.75 No previous FVGs\n",
      "2025-10-30 10:15  ZYDUSLIFE 🔴 bearish   8.30    993.15 - 1001.45 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 56\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 4  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey2:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS4\n",
    "combined_df = combined_df4\n",
    "key_name = \"Instrument Key 4 (Defence, Chemical and Pharma etc.)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "\n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik4(30-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "\n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik4(24-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "    # Save combined/master data (overwrites master file — change path if you want daily snapshots)\n",
    "    master_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\")\n",
    "    if master_path.exists():\n",
    "        try:\n",
    "            prev_master = pd.read_pickle(master_path)\n",
    "            # concat and dedupe on Datetime + Ticker (use Datetime_dt when available)\n",
    "            prev_master['Datetime_dt'] = pd.to_datetime(prev_master['Datetime'])\n",
    "            combined_master = pd.concat([prev_master, df_display], ignore_index=True)\n",
    "            combined_master = combined_master.drop_duplicates(subset=['Ticker', 'Datetime_dt'])\n",
    "            combined_master = combined_master.sort_values(['Datetime_dt', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "            combined_master.to_pickle(master_path)\n",
    "        except Exception:\n",
    "            # fallback: overwrite if previous master can't be read\n",
    "            df_display.to_pickle(master_path)\n",
    "    else:\n",
    "        df_display.to_pickle(master_path)\n",
    "\n",
    "    print(f\"Master results updated at: {master_path}\")\n",
    "\n",
    "    # Prepare a friendly display including last-3 info\n",
    "    def format_row_with_prev(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "\n",
    "    # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95de5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey5 = {\n",
    "    \"DLF\":\"NSE_EQ|INE271C01023\",\n",
    "    \"PHOENIXLTD\":\"NSE_EQ|INE211B01039\",\n",
    "    \"PRESTIGE\":\"NSE_EQ|INE811K01011\",\n",
    "    \"ABREL\":\"NSE_EQ|INE055A01016\",\n",
    "    \"OBEROIRLTY\":\"NSE_EQ|INE093I01010\",\n",
    "    \"LODHA\":\"NSE_EQ|INE670K01029\",\n",
    "    \"BRIGADE\":\"NSE_EQ|INE791I01019\",\n",
    "    \"BERGEPAINT\":\"NSE_EQ|INE463A01038\",\n",
    "    \"ASIANPAINT\":\"NSE_EQ|INE021A01026\",\n",
    "    \"RAMCOCEM\":\"NSE_EQ|INE331A01037\",\n",
    "    \"JKCEMENT\":\"NSE_EQ|INE823G01014\",\n",
    "    \"JKLAKSHMI\":\"NSE_EQ|INE786A01032\",\n",
    "    \"ULTRACEMCO\":\"NSE_EQ|INE481G01011\",\n",
    "    \"NUVOCO\":\"NSE_EQ|INE118D01016\",\n",
    "    \"GRASIM\":\"NSE_EQ|INE047A01021\",\n",
    "    \"INDIACEM\":\"NSE_EQ|INE383A01012\",\n",
    "    \"SHREECEM\":\"NSE_EQ|INE070A01015\",\n",
    "    \"ACC\":\"NSE_EQ|INE012A01025\",\n",
    "    \"AMBUJACEM\":\"NSE_EQ|INE079A01024\",\n",
    "    \"PRSMJOHNSN\":\"NSE_EQ|INE010A01011\",\n",
    "    \"HAVELLS\":\"NSE_EQ|INE176B01034\",\n",
    "    \"KAJARIACER\":\"NSE_EQ|INE217B01036\",\n",
    "    \"AMBER\":\"NSE_EQ|INE371P01015\",\n",
    "    \"VOLTAS\":\"NSE_EQ|INE226A01021\",\n",
    "    \"SYMPHONY\":\"NSE_EQ|INE225D01027\",\n",
    "    \"DIXON\":\"NSE_EQ|INE935N01020\",\n",
    "    \"WHIRLPOOL\":\"NSE_EQ|INE716A01013\",\n",
    "    \"BLUESTARCO\":\"NSE_EQ|INE472A01039\",\n",
    "    \"CENTURYPLY\":\"NSE_EQ|INE348B01021\",\n",
    "    \"CROMPTON\":\"NSE_EQ|INE299U01018\",\n",
    "    \"CERA\":\"NSE_EQ|INE739E01017\",\n",
    "    \"BHARTIARTL\":\"NSE_EQ|INE397D01024\",\n",
    "    \"IDEA\":\"NSE_EQ|INE669E01016\",\n",
    "    \"BHARTIHEXA\":\"NSE_EQ|INE343G01021\",\n",
    "    \"INDUSTOWER\":\"NSE_EQ|INE121J01017\",\n",
    "    \"TATACOMM\":\"NSE_EQ|INE151A01013\",\n",
    "    \"AIAENG\":\"NSE_EQ|INE212H01026\",\n",
    "    \"KNRCON\":\"NSE_EQ|INE634I01029\",\n",
    "    \"KPIL\":\"NSE_EQ|INE220B01022\",\n",
    "    \"LT\":\"NSE_EQ|INE018A01030\",\n",
    "    \"ANGELONE\":\"NSE_EQ|INE732I01013\",\n",
    "    \"360ONE\":\"NSE_EQ|INE466L01038\",\n",
    "    \"MOTILALOFS\":\"NSE_EQ|INE338I01027\",\n",
    "    \"HDFCAMC\":\"NSE_EQ|INE127D01025\",\n",
    "    \"UTIAMC\":\"NSE_EQ|INE094J01016\",\n",
    "    \"ABSLAMC\":\"NSE_EQ|INE404A01024\",\n",
    "    \"ANANDRATHI\":\"NSE_EQ|INE463V01026\",\n",
    "    \"NAM-INDIA\":\"NSE_EQ|INE298J01013\",\n",
    "    \"SBICARD\":\"NSE_EQ|INE018E01016\",\n",
    "    \"LTF\":\"NSE_EQ|INE498L01015\",\n",
    "    \"CREDITACC\":\"NSE_EQ|INE741K01010\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8fa168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DLF...\n",
      "Fetching data for PHOENIXLTD...\n",
      "Fetching data for PHOENIXLTD...\n",
      "Fetching data for PRESTIGE...\n",
      "Fetching data for PRESTIGE...\n",
      "Fetching data for ABREL...\n",
      "Fetching data for ABREL...\n",
      "Fetching data for OBEROIRLTY...\n",
      "Fetching data for OBEROIRLTY...\n",
      "Fetching data for LODHA...\n",
      "Fetching data for LODHA...\n",
      "Fetching data for BRIGADE...\n",
      "Fetching data for BRIGADE...\n",
      "Fetching data for BERGEPAINT...\n",
      "Fetching data for BERGEPAINT...\n",
      "Fetching data for ASIANPAINT...\n",
      "Fetching data for ASIANPAINT...\n",
      "Fetching data for RAMCOCEM...\n",
      "Fetching data for RAMCOCEM...\n",
      "Fetching data for JKCEMENT...\n",
      "Fetching data for JKCEMENT...\n",
      "Fetching data for JKLAKSHMI...\n",
      "Fetching data for JKLAKSHMI...\n",
      "Fetching data for ULTRACEMCO...\n",
      "Fetching data for ULTRACEMCO...\n",
      "Fetching data for NUVOCO...\n",
      "Fetching data for NUVOCO...\n",
      "Fetching data for GRASIM...\n",
      "Fetching data for GRASIM...\n",
      "Fetching data for INDIACEM...\n",
      "Fetching data for INDIACEM...\n",
      "Fetching data for SHREECEM...\n",
      "Fetching data for SHREECEM...\n",
      "Fetching data for ACC...\n",
      "Fetching data for ACC...\n",
      "Fetching data for AMBUJACEM...\n",
      "Fetching data for AMBUJACEM...\n",
      "Fetching data for PRSMJOHNSN...\n",
      "Fetching data for PRSMJOHNSN...\n",
      "Fetching data for HAVELLS...\n",
      "Fetching data for HAVELLS...\n",
      "Fetching data for KAJARIACER...\n",
      "Fetching data for KAJARIACER...\n",
      "Fetching data for AMBER...\n",
      "Fetching data for AMBER...\n",
      "Fetching data for VOLTAS...\n",
      "Fetching data for VOLTAS...\n",
      "Fetching data for SYMPHONY...\n",
      "Fetching data for SYMPHONY...\n",
      "Fetching data for DIXON...\n",
      "Fetching data for DIXON...\n",
      "Fetching data for WHIRLPOOL...\n",
      "Fetching data for WHIRLPOOL...\n",
      "Fetching data for BLUESTARCO...\n",
      "Fetching data for BLUESTARCO...\n",
      "Fetching data for CENTURYPLY...\n",
      "Fetching data for CENTURYPLY...\n",
      "Fetching data for CROMPTON...\n",
      "Fetching data for CROMPTON...\n",
      "Fetching data for CERA...\n",
      "Fetching data for CERA...\n",
      "Fetching data for BHARTIARTL...\n",
      "Fetching data for BHARTIARTL...\n",
      "Fetching data for IDEA...\n",
      "Fetching data for IDEA...\n",
      "Fetching data for BHARTIHEXA...\n",
      "Fetching data for BHARTIHEXA...\n",
      "Fetching data for INDUSTOWER...\n",
      "Fetching data for INDUSTOWER...\n",
      "Fetching data for TATACOMM...\n",
      "Fetching data for TATACOMM...\n",
      "Fetching data for AIAENG...\n",
      "Fetching data for AIAENG...\n",
      "Fetching data for KNRCON...\n",
      "Fetching data for KNRCON...\n",
      "Fetching data for KPIL...\n",
      "Fetching data for KPIL...\n",
      "Fetching data for LT...\n",
      "Fetching data for LT...\n",
      "Fetching data for ANGELONE...\n",
      "Fetching data for ANGELONE...\n",
      "Fetching data for 360ONE...\n",
      "Fetching data for 360ONE...\n",
      "Fetching data for MOTILALOFS...\n",
      "Fetching data for MOTILALOFS...\n",
      "Fetching data for HDFCAMC...\n",
      "Fetching data for HDFCAMC...\n",
      "Fetching data for UTIAMC...\n",
      "Fetching data for UTIAMC...\n",
      "Fetching data for ABSLAMC...\n",
      "Fetching data for ABSLAMC...\n",
      "Fetching data for ANANDRATHI...\n",
      "Fetching data for ANANDRATHI...\n",
      "Fetching data for NAM-INDIA...\n",
      "Fetching data for NAM-INDIA...\n",
      "Fetching data for SBICARD...\n",
      "Fetching data for SBICARD...\n",
      "Fetching data for LTF...\n",
      "Fetching data for LTF...\n",
      "Fetching data for CREDITACC...\n",
      "Fetching data for CREDITACC...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>360ONE</th>\n",
       "      <th>ABREL</th>\n",
       "      <th>ABSLAMC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AIAENG</th>\n",
       "      <th>AMBER</th>\n",
       "      <th>AMBUJACEM</th>\n",
       "      <th>ANANDRATHI</th>\n",
       "      <th>ANGELONE</th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>...</th>\n",
       "      <th>PRSMJOHNSN</th>\n",
       "      <th>RAMCOCEM</th>\n",
       "      <th>SBICARD</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>SYMPHONY</th>\n",
       "      <th>TATACOMM</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>UTIAMC</th>\n",
       "      <th>VOLTAS</th>\n",
       "      <th>WHIRLPOOL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, 360ONE), (Close, ABREL), (Close, ABSLAMC), (Close, ACC), (Close, AIAENG), (Close, AMBER), (Close, AMBUJACEM), (Close, ANANDRATHI), (Close, ANGELONE), (Close, ASIANPAINT), (Close, BERGEPAINT), (Close, BHARTIARTL), (Close, BHARTIHEXA), (Close, BLUESTARCO), (Close, BRIGADE), (Close, CENTURYPLY), (Close, CERA), (Close, CREDITACC), (Close, CROMPTON), (Close, DIXON), (Close, DLF), (Close, GRASIM), (Close, HAVELLS), (Close, HDFCAMC), (Close, IDEA), (Close, INDIACEM), (Close, INDUSTOWER), (Close, JKCEMENT), (Close, JKLAKSHMI), (Close, KAJARIACER), (Close, KNRCON), (Close, KPIL), (Close, LODHA), (Close, LT), (Close, LTF), (Close, MOTILALOFS), (Close, NAM-INDIA), (Close, NUVOCO), (Close, OBEROIRLTY), (Close, PHOENIXLTD), (Close, PRESTIGE), (Close, PRSMJOHNSN), (Close, RAMCOCEM), (Close, SBICARD), (Close, SHREECEM), (Close, SYMPHONY), (Close, TATACOMM), (Close, ULTRACEMCO), (Close, UTIAMC), (Close, VOLTAS), (Close, WHIRLPOOL), (High, 360ONE), (High, ABREL), (High, ABSLAMC), (High, ACC), (High, AIAENG), (High, AMBER), (High, AMBUJACEM), (High, ANANDRATHI), (High, ANGELONE), (High, ASIANPAINT), (High, BERGEPAINT), (High, BHARTIARTL), (High, BHARTIHEXA), (High, BLUESTARCO), (High, BRIGADE), (High, CENTURYPLY), (High, CERA), (High, CREDITACC), (High, CROMPTON), (High, DIXON), (High, DLF), (High, GRASIM), (High, HAVELLS), (High, HDFCAMC), (High, IDEA), (High, INDIACEM), (High, INDUSTOWER), (High, JKCEMENT), (High, JKLAKSHMI), (High, KAJARIACER), (High, KNRCON), (High, KPIL), (High, LODHA), (High, LT), (High, LTF), (High, MOTILALOFS), (High, NAM-INDIA), (High, NUVOCO), (High, OBEROIRLTY), (High, PHOENIXLTD), (High, PRESTIGE), (High, PRSMJOHNSN), (High, RAMCOCEM), (High, SBICARD), (High, SHREECEM), (High, SYMPHONY), (High, TATACOMM), (High, ULTRACEMCO), (High, UTIAMC), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 255 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>360ONE</th>\n",
       "      <th>ABREL</th>\n",
       "      <th>ABSLAMC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AIAENG</th>\n",
       "      <th>AMBER</th>\n",
       "      <th>AMBUJACEM</th>\n",
       "      <th>ANANDRATHI</th>\n",
       "      <th>ANGELONE</th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>...</th>\n",
       "      <th>PRSMJOHNSN</th>\n",
       "      <th>RAMCOCEM</th>\n",
       "      <th>SBICARD</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>SYMPHONY</th>\n",
       "      <th>TATACOMM</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>UTIAMC</th>\n",
       "      <th>VOLTAS</th>\n",
       "      <th>WHIRLPOOL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1852.9</td>\n",
       "      <td>772.20</td>\n",
       "      <td>1877.5</td>\n",
       "      <td>3312.9</td>\n",
       "      <td>8142.5</td>\n",
       "      <td>569.20</td>\n",
       "      <td>3140.6</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>2516.9</td>\n",
       "      <td>...</td>\n",
       "      <td>23372.0</td>\n",
       "      <td>32477.0</td>\n",
       "      <td>125495.0</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>17522.0</td>\n",
       "      <td>97819.0</td>\n",
       "      <td>16770.0</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>122290.0</td>\n",
       "      <td>50004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>1133.1</td>\n",
       "      <td>1872.1</td>\n",
       "      <td>778.45</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>3306.2</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>570.50</td>\n",
       "      <td>3150.4</td>\n",
       "      <td>2518.6</td>\n",
       "      <td>2525.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21870.0</td>\n",
       "      <td>21701.0</td>\n",
       "      <td>104245.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>4202.0</td>\n",
       "      <td>33596.0</td>\n",
       "      <td>11830.0</td>\n",
       "      <td>51098.0</td>\n",
       "      <td>40179.0</td>\n",
       "      <td>22153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>1123.2</td>\n",
       "      <td>1890.3</td>\n",
       "      <td>779.10</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3299.5</td>\n",
       "      <td>8182.0</td>\n",
       "      <td>567.25</td>\n",
       "      <td>3121.6</td>\n",
       "      <td>2511.8</td>\n",
       "      <td>2525.1</td>\n",
       "      <td>...</td>\n",
       "      <td>114194.0</td>\n",
       "      <td>21501.0</td>\n",
       "      <td>102488.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>8715.0</td>\n",
       "      <td>205216.0</td>\n",
       "      <td>23852.0</td>\n",
       "      <td>78086.0</td>\n",
       "      <td>118005.0</td>\n",
       "      <td>31890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1887.9</td>\n",
       "      <td>776.90</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3296.1</td>\n",
       "      <td>8143.5</td>\n",
       "      <td>567.15</td>\n",
       "      <td>3114.4</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>2527.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37511.0</td>\n",
       "      <td>11271.0</td>\n",
       "      <td>160066.0</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>13594.0</td>\n",
       "      <td>52662.0</td>\n",
       "      <td>12737.0</td>\n",
       "      <td>20958.0</td>\n",
       "      <td>75449.0</td>\n",
       "      <td>42605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>1120.0</td>\n",
       "      <td>1889.7</td>\n",
       "      <td>778.50</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3284.1</td>\n",
       "      <td>8096.5</td>\n",
       "      <td>565.40</td>\n",
       "      <td>3112.3</td>\n",
       "      <td>2507.2</td>\n",
       "      <td>2526.8</td>\n",
       "      <td>...</td>\n",
       "      <td>26395.0</td>\n",
       "      <td>14694.0</td>\n",
       "      <td>178735.0</td>\n",
       "      <td>2737.0</td>\n",
       "      <td>10643.0</td>\n",
       "      <td>31974.0</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>41143.0</td>\n",
       "      <td>88024.0</td>\n",
       "      <td>71688.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                   ...     Volume                                                                     \\\n",
       "Ticker                     360ONE   ABREL ABSLAMC     ACC  AIAENG   AMBER AMBUJACEM ANANDRATHI ANGELONE ASIANPAINT  ... PRSMJOHNSN RAMCOCEM   SBICARD SHREECEM SYMPHONY  TATACOMM ULTRACEMCO   UTIAMC   \n",
       "Datetime                                                                                                            ...                                                                                 \n",
       "2025-10-30 09:15:00+05:30  1125.0  1852.9  772.20  1877.5  3312.9  8142.5    569.20     3140.6   2508.0     2516.9  ...    23372.0  32477.0  125495.0   4707.0  17522.0   97819.0    16770.0  37977.0   \n",
       "2025-10-30 10:15:00+05:30  1133.1  1872.1  778.45  1870.0  3306.2  8149.0    570.50     3150.4   2518.6     2525.9  ...    21870.0  21701.0  104245.0   1624.0   4202.0   33596.0    11830.0  51098.0   \n",
       "2025-10-30 11:15:00+05:30  1123.2  1890.3  779.10  1860.0  3299.5  8182.0    567.25     3121.6   2511.8     2525.1  ...   114194.0  21501.0  102488.0   2874.0   8715.0  205216.0    23852.0  78086.0   \n",
       "2025-10-30 12:15:00+05:30  1125.0  1887.9  776.90  1860.0  3296.1  8143.5    567.15     3114.4   2508.0     2527.1  ...    37511.0  11271.0  160066.0   2079.0  13594.0   52662.0    12737.0  20958.0   \n",
       "2025-10-30 13:15:00+05:30  1120.0  1889.7  778.50  1860.0  3284.1  8096.5    565.40     3112.3   2507.2     2526.8  ...    26395.0  14694.0  178735.0   2737.0  10643.0   31974.0    22838.0  41143.0   \n",
       "\n",
       "Field                                          \n",
       "Ticker                       VOLTAS WHIRLPOOL  \n",
       "Datetime                                       \n",
       "2025-10-30 09:15:00+05:30  122290.0   50004.0  \n",
       "2025-10-30 10:15:00+05:30   40179.0   22153.0  \n",
       "2025-10-30 11:15:00+05:30  118005.0   31890.0  \n",
       "2025-10-30 12:15:00+05:30   75449.0   42605.0  \n",
       "2025-10-30 13:15:00+05:30   88024.0   71688.0  \n",
       "\n",
       "[5 rows x 255 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intrday data for instrument key 5 \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS5 = instrumentkey5\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS5.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "    \n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "    \n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None, index5=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index5 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index5\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc8f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 255)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>360ONE</th>\n",
       "      <th>ABREL</th>\n",
       "      <th>ABSLAMC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AIAENG</th>\n",
       "      <th>AMBER</th>\n",
       "      <th>AMBUJACEM</th>\n",
       "      <th>ANANDRATHI</th>\n",
       "      <th>ANGELONE</th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>...</th>\n",
       "      <th>PRSMJOHNSN</th>\n",
       "      <th>RAMCOCEM</th>\n",
       "      <th>SBICARD</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>SYMPHONY</th>\n",
       "      <th>TATACOMM</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>UTIAMC</th>\n",
       "      <th>VOLTAS</th>\n",
       "      <th>WHIRLPOOL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>1124.2</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>781.35</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>8308.5</td>\n",
       "      <td>570.30</td>\n",
       "      <td>3056.2</td>\n",
       "      <td>2508.7</td>\n",
       "      <td>2537.2</td>\n",
       "      <td>...</td>\n",
       "      <td>23835.0</td>\n",
       "      <td>24134.0</td>\n",
       "      <td>120991.0</td>\n",
       "      <td>6980.0</td>\n",
       "      <td>8845.0</td>\n",
       "      <td>42072.0</td>\n",
       "      <td>87867.0</td>\n",
       "      <td>42478.0</td>\n",
       "      <td>125493.0</td>\n",
       "      <td>88551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>1129.1</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>781.95</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>8310.0</td>\n",
       "      <td>573.00</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2513.6</td>\n",
       "      <td>2539.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7309.0</td>\n",
       "      <td>13566.0</td>\n",
       "      <td>100733.0</td>\n",
       "      <td>6210.0</td>\n",
       "      <td>3178.0</td>\n",
       "      <td>16283.0</td>\n",
       "      <td>60958.0</td>\n",
       "      <td>16236.0</td>\n",
       "      <td>52338.0</td>\n",
       "      <td>115283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1852.9</td>\n",
       "      <td>772.20</td>\n",
       "      <td>1877.5</td>\n",
       "      <td>3312.9</td>\n",
       "      <td>8142.5</td>\n",
       "      <td>569.20</td>\n",
       "      <td>3140.6</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>2516.9</td>\n",
       "      <td>...</td>\n",
       "      <td>23372.0</td>\n",
       "      <td>32477.0</td>\n",
       "      <td>125495.0</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>17522.0</td>\n",
       "      <td>97819.0</td>\n",
       "      <td>16770.0</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>122290.0</td>\n",
       "      <td>50004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>1133.1</td>\n",
       "      <td>1872.1</td>\n",
       "      <td>778.45</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>3306.2</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>570.50</td>\n",
       "      <td>3150.4</td>\n",
       "      <td>2518.6</td>\n",
       "      <td>2525.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21870.0</td>\n",
       "      <td>21701.0</td>\n",
       "      <td>104245.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>4202.0</td>\n",
       "      <td>33596.0</td>\n",
       "      <td>11830.0</td>\n",
       "      <td>51098.0</td>\n",
       "      <td>40179.0</td>\n",
       "      <td>22153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>1123.2</td>\n",
       "      <td>1890.3</td>\n",
       "      <td>779.10</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3299.5</td>\n",
       "      <td>8182.0</td>\n",
       "      <td>567.25</td>\n",
       "      <td>3121.6</td>\n",
       "      <td>2511.8</td>\n",
       "      <td>2525.1</td>\n",
       "      <td>...</td>\n",
       "      <td>114194.0</td>\n",
       "      <td>21501.0</td>\n",
       "      <td>102488.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>8715.0</td>\n",
       "      <td>205216.0</td>\n",
       "      <td>23852.0</td>\n",
       "      <td>78086.0</td>\n",
       "      <td>118005.0</td>\n",
       "      <td>31890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1887.9</td>\n",
       "      <td>776.90</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3296.1</td>\n",
       "      <td>8143.5</td>\n",
       "      <td>567.15</td>\n",
       "      <td>3114.4</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>2527.1</td>\n",
       "      <td>...</td>\n",
       "      <td>37511.0</td>\n",
       "      <td>11271.0</td>\n",
       "      <td>160066.0</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>13594.0</td>\n",
       "      <td>52662.0</td>\n",
       "      <td>12737.0</td>\n",
       "      <td>20958.0</td>\n",
       "      <td>75449.0</td>\n",
       "      <td>42605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>1120.0</td>\n",
       "      <td>1889.7</td>\n",
       "      <td>778.50</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3284.1</td>\n",
       "      <td>8096.5</td>\n",
       "      <td>565.40</td>\n",
       "      <td>3112.3</td>\n",
       "      <td>2507.2</td>\n",
       "      <td>2526.8</td>\n",
       "      <td>...</td>\n",
       "      <td>26395.0</td>\n",
       "      <td>14694.0</td>\n",
       "      <td>178735.0</td>\n",
       "      <td>2737.0</td>\n",
       "      <td>10643.0</td>\n",
       "      <td>31974.0</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>41143.0</td>\n",
       "      <td>88024.0</td>\n",
       "      <td>71688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>1119.9</td>\n",
       "      <td>1892.8</td>\n",
       "      <td>775.85</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>3298.9</td>\n",
       "      <td>8074.5</td>\n",
       "      <td>567.40</td>\n",
       "      <td>3136.2</td>\n",
       "      <td>2514.9</td>\n",
       "      <td>2522.3</td>\n",
       "      <td>...</td>\n",
       "      <td>16064.0</td>\n",
       "      <td>18913.0</td>\n",
       "      <td>325276.0</td>\n",
       "      <td>5035.0</td>\n",
       "      <td>9362.0</td>\n",
       "      <td>106459.0</td>\n",
       "      <td>50936.0</td>\n",
       "      <td>25777.0</td>\n",
       "      <td>387931.0</td>\n",
       "      <td>160738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>1121.5</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>779.00</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3289.7</td>\n",
       "      <td>8119.0</td>\n",
       "      <td>567.20</td>\n",
       "      <td>3125.7</td>\n",
       "      <td>2513.0</td>\n",
       "      <td>2523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37743.0</td>\n",
       "      <td>11062.0</td>\n",
       "      <td>325961.0</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>14677.0</td>\n",
       "      <td>38597.0</td>\n",
       "      <td>20973.0</td>\n",
       "      <td>43168.0</td>\n",
       "      <td>109566.0</td>\n",
       "      <td>80850.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                   ...     Volume                                                                     \\\n",
       "Ticker                     360ONE   ABREL ABSLAMC     ACC  AIAENG   AMBER AMBUJACEM ANANDRATHI ANGELONE ASIANPAINT  ... PRSMJOHNSN RAMCOCEM   SBICARD SHREECEM SYMPHONY  TATACOMM ULTRACEMCO   UTIAMC   \n",
       "Datetime                                                                                                            ...                                                                                 \n",
       "2025-10-29 14:15:00+05:30  1124.2  1815.0  781.35  1878.0  3329.0  8308.5    570.30     3056.2   2508.7     2537.2  ...    23835.0  24134.0  120991.0   6980.0   8845.0   42072.0    87867.0  42478.0   \n",
       "2025-10-29 15:15:00+05:30  1129.1  1815.0  781.95  1875.0  3335.0  8310.0    573.00     3100.0   2513.6     2539.4  ...     7309.0  13566.0  100733.0   6210.0   3178.0   16283.0    60958.0  16236.0   \n",
       "2025-10-30 09:15:00+05:30  1125.0  1852.9  772.20  1877.5  3312.9  8142.5    569.20     3140.6   2508.0     2516.9  ...    23372.0  32477.0  125495.0   4707.0  17522.0   97819.0    16770.0  37977.0   \n",
       "2025-10-30 10:15:00+05:30  1133.1  1872.1  778.45  1870.0  3306.2  8149.0    570.50     3150.4   2518.6     2525.9  ...    21870.0  21701.0  104245.0   1624.0   4202.0   33596.0    11830.0  51098.0   \n",
       "2025-10-30 11:15:00+05:30  1123.2  1890.3  779.10  1860.0  3299.5  8182.0    567.25     3121.6   2511.8     2525.1  ...   114194.0  21501.0  102488.0   2874.0   8715.0  205216.0    23852.0  78086.0   \n",
       "2025-10-30 12:15:00+05:30  1125.0  1887.9  776.90  1860.0  3296.1  8143.5    567.15     3114.4   2508.0     2527.1  ...    37511.0  11271.0  160066.0   2079.0  13594.0   52662.0    12737.0  20958.0   \n",
       "2025-10-30 13:15:00+05:30  1120.0  1889.7  778.50  1860.0  3284.1  8096.5    565.40     3112.3   2507.2     2526.8  ...    26395.0  14694.0  178735.0   2737.0  10643.0   31974.0    22838.0  41143.0   \n",
       "2025-10-30 14:15:00+05:30  1119.9  1892.8  775.85  1864.0  3298.9  8074.5    567.40     3136.2   2514.9     2522.3  ...    16064.0  18913.0  325276.0   5035.0   9362.0  106459.0    50936.0  25777.0   \n",
       "2025-10-30 15:15:00+05:30  1121.5  1880.0  779.00  1860.0  3289.7  8119.0    567.20     3125.7   2513.0     2523.0  ...    37743.0  11062.0  325961.0   3335.0  14677.0   38597.0    20973.0  43168.0   \n",
       "\n",
       "Field                                          \n",
       "Ticker                       VOLTAS WHIRLPOOL  \n",
       "Datetime                                       \n",
       "2025-10-29 14:15:00+05:30  125493.0   88551.0  \n",
       "2025-10-29 15:15:00+05:30   52338.0  115283.0  \n",
       "2025-10-30 09:15:00+05:30  122290.0   50004.0  \n",
       "2025-10-30 10:15:00+05:30   40179.0   22153.0  \n",
       "2025-10-30 11:15:00+05:30  118005.0   31890.0  \n",
       "2025-10-30 12:15:00+05:30   75449.0   42605.0  \n",
       "2025-10-30 13:15:00+05:30   88024.0   71688.0  \n",
       "2025-10-30 14:15:00+05:30  387931.0  160738.0  \n",
       "2025-10-30 15:15:00+05:30  109566.0   80850.0  \n",
       "\n",
       "[9 rows x 255 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Historical and intrday data combine for ik5\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik5.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index5  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df5 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df5 = combined_df5[~combined_df5.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df5.shape)\n",
    "print(combined_df5.index.names)\n",
    "print(combined_df5.columns.names)\n",
    "display(combined_df5.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd1707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FVG detection results saved to: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik5(30-10).pkl\n",
      "Master results updated at: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 5 (Realty, Consumer Durables etc.) (date: 2025-10-30):\n",
      "        Datetime     Ticker   Pattern    Gap             Range    Previous_FVGs\n",
      "2025-10-30 10:15      ABREL 🟢 bullish  26.60 1824.90 - 1851.50 No previous FVGs\n",
      "2025-10-30 12:15        ACC 🔴 bearish   2.60 1865.10 - 1867.70 No previous FVGs\n",
      "2025-10-30 11:15        ACC 🔴 bearish   1.50 1871.00 - 1872.50 No previous FVGs\n",
      "2025-10-30 10:15     AIAENG 🔴 bearish  10.90 3311.50 - 3322.40 No previous FVGs\n",
      "2025-10-30 10:15      AMBER 🔴 bearish 110.50 8182.00 - 8292.50 No previous FVGs\n",
      "2025-10-30 15:15 ANANDRATHI 🟢 bullish   4.10 3121.50 - 3125.60 No previous FVGs\n",
      "2025-10-30 10:15 ANANDRATHI 🟢 bullish   8.20 3112.40 - 3120.60 No previous FVGs\n",
      "2025-10-30 09:15 ANANDRATHI 🟢 bullish   3.50 3083.00 - 3086.50 No previous FVGs\n",
      "2025-10-30 10:15 ASIANPAINT 🔴 bearish   9.40 2526.30 - 2535.70 No previous FVGs\n",
      "2025-10-30 10:15 BERGEPAINT 🔴 bearish   1.35   543.25 - 544.60 No previous FVGs\n",
      "2025-10-30 10:15 BHARTIHEXA 🔴 bearish   6.60 1865.40 - 1872.00 No previous FVGs\n",
      "2025-10-30 10:15 BLUESTARCO 🔴 bearish   8.70 1950.00 - 1958.70 No previous FVGs\n",
      "2025-10-30 15:15    BRIGADE 🟢 bullish   0.45 1035.00 - 1035.45 No previous FVGs\n",
      "2025-10-30 10:15    BRIGADE 🔴 bearish   0.25 1032.40 - 1032.65 No previous FVGs\n",
      "2025-10-30 15:15       CERA 🟢 bullish  31.00 6142.00 - 6173.00 No previous FVGs\n",
      "2025-10-30 14:15  CREDITACC 🔴 bearish   0.60 1470.40 - 1471.00 No previous FVGs\n",
      "2025-10-30 12:15  CREDITACC 🟢 bullish  30.20 1440.80 - 1471.00 No previous FVGs\n",
      "2025-10-30 10:15  CREDITACC 🟢 bullish  18.00 1411.90 - 1429.90 No previous FVGs\n",
      "2025-10-30 10:15   CROMPTON 🔴 bearish   3.60   286.45 - 290.05 No previous FVGs\n",
      "2025-10-30 10:15        DLF 🔴 bearish   2.05   775.30 - 777.35 No previous FVGs\n",
      "2025-10-30 10:15     GRASIM 🔴 bearish   4.00 2950.80 - 2954.80 No previous FVGs\n",
      "2025-10-30 10:15       IDEA 🔴 bearish   0.53       8.79 - 9.32 No previous FVGs\n",
      "2025-10-30 15:15   INDIACEM 🔴 bearish  10.00   400.05 - 410.05 No previous FVGs\n",
      "2025-10-30 11:15   INDIACEM 🟢 bullish   0.10   411.90 - 412.00 No previous FVGs\n",
      "2025-10-30 10:15   INDIACEM 🟢 bullish  16.15   391.05 - 407.20 No previous FVGs\n",
      "2025-10-30 10:15 INDUSTOWER 🔴 bearish   9.60   370.85 - 380.45 No previous FVGs\n",
      "2025-10-30 09:15 INDUSTOWER 🔴 bearish   1.35   378.00 - 379.35 No previous FVGs\n",
      "2025-10-30 10:15   JKCEMENT 🔴 bearish  12.50 6307.50 - 6320.00 No previous FVGs\n",
      "2025-10-30 11:15  JKLAKSHMI 🟢 bullish  12.05   848.50 - 860.55 No previous FVGs\n",
      "2025-10-30 15:15     KNRCON 🔴 bearish   0.13   184.42 - 184.55 No previous FVGs\n",
      "2025-10-30 12:15     KNRCON 🔴 bearish   0.19   185.36 - 185.55 No previous FVGs\n",
      "2025-10-30 13:15      LODHA 🔴 bearish   1.40 1171.10 - 1172.50 No previous FVGs\n",
      "2025-10-30 10:15      LODHA 🔴 bearish   1.10 1175.00 - 1176.10 No previous FVGs\n",
      "2025-10-30 10:15         LT 🟢 bullish  28.40 3970.80 - 3999.20 No previous FVGs\n",
      "2025-10-30 10:15 MOTILALOFS 🟢 bullish   7.75 1009.00 - 1016.75 No previous FVGs\n",
      "2025-10-30 15:15  NAM-INDIA 🟢 bullish   4.65   862.50 - 867.15 No previous FVGs\n",
      "2025-10-30 15:15     NUVOCO 🔴 bearish   0.30   422.25 - 422.55 No previous FVGs\n",
      "2025-10-30 10:15     NUVOCO 🟢 bullish   1.00   422.00 - 423.00 No previous FVGs\n",
      "2025-10-30 09:15     NUVOCO 🟢 bullish   1.25   416.15 - 417.40 No previous FVGs\n",
      "2025-10-30 11:15 OBEROIRLTY 🟢 bullish  14.40 1738.60 - 1753.00 No previous FVGs\n",
      "2025-10-30 09:15 OBEROIRLTY 🟢 bullish   7.20 1714.30 - 1721.50 No previous FVGs\n",
      "2025-10-30 13:15 PHOENIXLTD 🔴 bearish   3.20 1701.60 - 1704.80 No previous FVGs\n",
      "2025-10-30 15:15   RAMCOCEM 🟢 bullish   3.15 1049.20 - 1052.35 No previous FVGs\n",
      "2025-10-30 15:15    SBICARD 🔴 bearish   1.35   887.45 - 888.80 No previous FVGs\n",
      "2025-10-30 13:15    SBICARD 🔴 bearish   8.15   895.40 - 903.55 No previous FVGs\n",
      "2025-10-30 12:15    SBICARD 🔴 bearish   0.90   905.20 - 906.10 No previous FVGs\n",
      "2025-10-30 12:15   SYMPHONY 🟢 bullish   3.95   918.00 - 921.95 No previous FVGs\n",
      "2025-10-30 12:15   TATACOMM 🟢 bullish   1.40 1914.20 - 1915.60 No previous FVGs\n",
      "2025-10-30 11:15     UTIAMC 🔴 bearish   3.40 1246.60 - 1250.00 No previous FVGs\n",
      "2025-10-30 10:15     UTIAMC 🔴 bearish  23.80 1250.60 - 1274.40 No previous FVGs\n",
      "2025-10-30 15:15  WHIRLPOOL 🟢 bullish   2.40 1416.90 - 1419.30 No previous FVGs\n",
      "        Datetime     Ticker   Pattern    Gap             Range    Previous_FVGs\n",
      "2025-10-30 10:15      ABREL 🟢 bullish  26.60 1824.90 - 1851.50 No previous FVGs\n",
      "2025-10-30 12:15        ACC 🔴 bearish   2.60 1865.10 - 1867.70 No previous FVGs\n",
      "2025-10-30 11:15        ACC 🔴 bearish   1.50 1871.00 - 1872.50 No previous FVGs\n",
      "2025-10-30 10:15     AIAENG 🔴 bearish  10.90 3311.50 - 3322.40 No previous FVGs\n",
      "2025-10-30 10:15      AMBER 🔴 bearish 110.50 8182.00 - 8292.50 No previous FVGs\n",
      "2025-10-30 15:15 ANANDRATHI 🟢 bullish   4.10 3121.50 - 3125.60 No previous FVGs\n",
      "2025-10-30 10:15 ANANDRATHI 🟢 bullish   8.20 3112.40 - 3120.60 No previous FVGs\n",
      "2025-10-30 09:15 ANANDRATHI 🟢 bullish   3.50 3083.00 - 3086.50 No previous FVGs\n",
      "2025-10-30 10:15 ASIANPAINT 🔴 bearish   9.40 2526.30 - 2535.70 No previous FVGs\n",
      "2025-10-30 10:15 BERGEPAINT 🔴 bearish   1.35   543.25 - 544.60 No previous FVGs\n",
      "2025-10-30 10:15 BHARTIHEXA 🔴 bearish   6.60 1865.40 - 1872.00 No previous FVGs\n",
      "2025-10-30 10:15 BLUESTARCO 🔴 bearish   8.70 1950.00 - 1958.70 No previous FVGs\n",
      "2025-10-30 15:15    BRIGADE 🟢 bullish   0.45 1035.00 - 1035.45 No previous FVGs\n",
      "2025-10-30 10:15    BRIGADE 🔴 bearish   0.25 1032.40 - 1032.65 No previous FVGs\n",
      "2025-10-30 15:15       CERA 🟢 bullish  31.00 6142.00 - 6173.00 No previous FVGs\n",
      "2025-10-30 14:15  CREDITACC 🔴 bearish   0.60 1470.40 - 1471.00 No previous FVGs\n",
      "2025-10-30 12:15  CREDITACC 🟢 bullish  30.20 1440.80 - 1471.00 No previous FVGs\n",
      "2025-10-30 10:15  CREDITACC 🟢 bullish  18.00 1411.90 - 1429.90 No previous FVGs\n",
      "2025-10-30 10:15   CROMPTON 🔴 bearish   3.60   286.45 - 290.05 No previous FVGs\n",
      "2025-10-30 10:15        DLF 🔴 bearish   2.05   775.30 - 777.35 No previous FVGs\n",
      "2025-10-30 10:15     GRASIM 🔴 bearish   4.00 2950.80 - 2954.80 No previous FVGs\n",
      "2025-10-30 10:15       IDEA 🔴 bearish   0.53       8.79 - 9.32 No previous FVGs\n",
      "2025-10-30 15:15   INDIACEM 🔴 bearish  10.00   400.05 - 410.05 No previous FVGs\n",
      "2025-10-30 11:15   INDIACEM 🟢 bullish   0.10   411.90 - 412.00 No previous FVGs\n",
      "2025-10-30 10:15   INDIACEM 🟢 bullish  16.15   391.05 - 407.20 No previous FVGs\n",
      "2025-10-30 10:15 INDUSTOWER 🔴 bearish   9.60   370.85 - 380.45 No previous FVGs\n",
      "2025-10-30 09:15 INDUSTOWER 🔴 bearish   1.35   378.00 - 379.35 No previous FVGs\n",
      "2025-10-30 10:15   JKCEMENT 🔴 bearish  12.50 6307.50 - 6320.00 No previous FVGs\n",
      "2025-10-30 11:15  JKLAKSHMI 🟢 bullish  12.05   848.50 - 860.55 No previous FVGs\n",
      "2025-10-30 15:15     KNRCON 🔴 bearish   0.13   184.42 - 184.55 No previous FVGs\n",
      "2025-10-30 12:15     KNRCON 🔴 bearish   0.19   185.36 - 185.55 No previous FVGs\n",
      "2025-10-30 13:15      LODHA 🔴 bearish   1.40 1171.10 - 1172.50 No previous FVGs\n",
      "2025-10-30 10:15      LODHA 🔴 bearish   1.10 1175.00 - 1176.10 No previous FVGs\n",
      "2025-10-30 10:15         LT 🟢 bullish  28.40 3970.80 - 3999.20 No previous FVGs\n",
      "2025-10-30 10:15 MOTILALOFS 🟢 bullish   7.75 1009.00 - 1016.75 No previous FVGs\n",
      "2025-10-30 15:15  NAM-INDIA 🟢 bullish   4.65   862.50 - 867.15 No previous FVGs\n",
      "2025-10-30 15:15     NUVOCO 🔴 bearish   0.30   422.25 - 422.55 No previous FVGs\n",
      "2025-10-30 10:15     NUVOCO 🟢 bullish   1.00   422.00 - 423.00 No previous FVGs\n",
      "2025-10-30 09:15     NUVOCO 🟢 bullish   1.25   416.15 - 417.40 No previous FVGs\n",
      "2025-10-30 11:15 OBEROIRLTY 🟢 bullish  14.40 1738.60 - 1753.00 No previous FVGs\n",
      "2025-10-30 09:15 OBEROIRLTY 🟢 bullish   7.20 1714.30 - 1721.50 No previous FVGs\n",
      "2025-10-30 13:15 PHOENIXLTD 🔴 bearish   3.20 1701.60 - 1704.80 No previous FVGs\n",
      "2025-10-30 15:15   RAMCOCEM 🟢 bullish   3.15 1049.20 - 1052.35 No previous FVGs\n",
      "2025-10-30 15:15    SBICARD 🔴 bearish   1.35   887.45 - 888.80 No previous FVGs\n",
      "2025-10-30 13:15    SBICARD 🔴 bearish   8.15   895.40 - 903.55 No previous FVGs\n",
      "2025-10-30 12:15    SBICARD 🔴 bearish   0.90   905.20 - 906.10 No previous FVGs\n",
      "2025-10-30 12:15   SYMPHONY 🟢 bullish   3.95   918.00 - 921.95 No previous FVGs\n",
      "2025-10-30 12:15   TATACOMM 🟢 bullish   1.40 1914.20 - 1915.60 No previous FVGs\n",
      "2025-10-30 11:15     UTIAMC 🔴 bearish   3.40 1246.60 - 1250.00 No previous FVGs\n",
      "2025-10-30 10:15     UTIAMC 🔴 bearish  23.80 1250.60 - 1274.40 No previous FVGs\n",
      "2025-10-30 15:15  WHIRLPOOL 🟢 bullish   2.40 1416.90 - 1419.30 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 51\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 5  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey2:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS5\n",
    "combined_df = combined_df5\n",
    "key_name = \"Instrument Key 5 (Realty, Consumer Durables etc.)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "\n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik5(30-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "\n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik5(24-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "    # Save combined/master data (overwrites master file — change path if you want daily snapshots)\n",
    "    master_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\")\n",
    "    if master_path.exists():\n",
    "        try:\n",
    "            prev_master = pd.read_pickle(master_path)\n",
    "            # concat and dedupe on Datetime + Ticker (use Datetime_dt when available)\n",
    "            prev_master['Datetime_dt'] = pd.to_datetime(prev_master['Datetime'])\n",
    "            combined_master = pd.concat([prev_master, df_display], ignore_index=True)\n",
    "            combined_master = combined_master.drop_duplicates(subset=['Ticker', 'Datetime_dt'])\n",
    "            combined_master = combined_master.sort_values(['Datetime_dt', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "            combined_master.to_pickle(master_path)\n",
    "        except Exception:\n",
    "            # fallback: overwrite if previous master can't be read\n",
    "            df_display.to_pickle(master_path)\n",
    "    else:\n",
    "        df_display.to_pickle(master_path)\n",
    "\n",
    "    print(f\"Master results updated at: {master_path}\")\n",
    "\n",
    "    # Prepare a friendly display including last-3 info\n",
    "    def format_row_with_prev(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "\n",
    "    # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b5e953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey6 = {\n",
    "    \"ZEEL\":\"NSE_EQ|INE256A01028\",\n",
    "    \"SUNTV\":\"NSE_EQ|INE424H01027\",\n",
    "    \"NYKAA\":\"NSE_EQ|INE388Y01029\",\n",
    "    \"PAYTM\":\"NSE_EQ|INE982J01020\",\n",
    "    \"ETERNAL\": \"NSE_EQ|INE758T01015\",\n",
    "    \"SWIGGY\":\"NSE_EQ|INE00H001014\",\n",
    "    \"MANAPPURAM\":\"NSE_EQ|INE522D01027\",\n",
    "    \"SUNDARAMFIN\":\"NSE_EQ|INE660A01013\",\n",
    "    \"BAJAJFINSV\":\"NSE_EQ|INE918I01026\",\n",
    "    \"BAJFINANCE\":\"NSE_EQ|INE296A01032\",\n",
    "    \"M&MFIN\":\"NSE_EQ|INE774D01024\",\n",
    "    \"MUTHOOTFIN\":\"NSE_EQ|INE414G01012\",\n",
    "    \"POONAWALLA\":\"NSE_EQ|INE511C01022\",\n",
    "    \"JIOFIN\":\"NSE_EQ|INE758E01017\",\n",
    "    \"BAJAJHLDNG\":\"NSE_EQ|INE118A01012\",\n",
    "    \"CHOLAFIN\":\"NSE_EQ|INE121A01024\",\n",
    "    \"CHOLAHLDNG\":\"NSE_EQ|INE149A01033\",\n",
    "    \"SHRIRAMFIN\":\"NSE_EQ|INE721A01047\",\n",
    "    \"CRISIL\":\"NSE_EQ|INE007A01025\",\n",
    "    \"CARERATING\":\"NSE_EQ|INE752H01013\",\n",
    "    \"CDSL\":\"NSE_EQ|INE736A01011\",\n",
    "    \"KFINTECH\":\"NSE_EQ|INE138Y01010\",\n",
    "    \"BSE\":\"NSE_EQ|INE118H01025\",\n",
    "    \"CAMS\":\"NSE_EQ|INE596I01012\",\n",
    "    \"POLICYBZR\":\"NSE_EQ|INE417T01026\",\n",
    "    \"METROBRAND\":\"NSE_EQ|INE317I01021\",\n",
    "    \"TITAN\":\"NSE_EQ|INE280A01028\",\n",
    "    \"ARVIND\":\"NSE_EQ|INE034A01011\",\n",
    "    \"VIPIND\":\"NSE_EQ|INE054A01027\",\n",
    "    \"PAGEIND\":\"NSE_EQ|INE761H01022\",\n",
    "    \"KALYANKJIL\":\"NSE_EQ|INE303R01014\",\n",
    "    \"RAYMOND\":\"NSE_EQ|INE301A01014\",\n",
    "    \"TRENT\":\"NSE_EQ|INE849A01020\",\n",
    "    \"ABFRL\":\"NSE_EQ|INE647O01011\",\n",
    "    \"TRIDENT\":\"NSE_EQ|INE064C01022\",\n",
    "    \"BATAINDIA\":\"NSE_EQ|INE176A01028\",\n",
    "    \"BRITANNIA\":\"NSE_EQ|INE216A01030\",\n",
    "    \"DMART\":\"NSE_EQ|INE192R01011\",\n",
    "    \"TATACONSUM\":\"NSE_EQ|INE192A01025\",\n",
    "    \"JYOTHYLAB\":\"NSE_EQ|INE668F01031\",\n",
    "    \"EMAMILTD\":\"NSE_EQ|INE548C01032\",\n",
    "    \"GILLETTE\":\"NSE_EQ|INE322A01010\",\n",
    "    \"DABUR\":\"NSE_EQ|INE016A01026\",\n",
    "    \"GODREJCP\":\"NSE_EQ|INE102D01028\",\n",
    "    \"AWL\":\"NSE_EQ|INE699H01024\",\n",
    "    \"HINDUNILVR\":\"NSE_EQ|INE030A01027\",\n",
    "    \"NESTLEIND\":\"NSE_EQ|INE239A01024\",\n",
    "    \"JUBLFOOD\":\"NSE_EQ|INE797F01020\",\n",
    "    \"ITC\":\"NSE_EQ|INE154A01025\",\n",
    "    \"MARICO\":\"NSE_EQ|INE196A01026\",\n",
    "    \"VBL\":\"NSE_EQ|INE200M01039\",\n",
    "    \"RADICO\":\"NSE_EQ|INE944F01028\",\n",
    "    \"UNITDSPR\":\"NSE_EQ|INE854D01024\",\n",
    "    \"SULA\":\"NSE_EQ|INE142Q01026\",\n",
    "    \"UBL\":\"NSE_EQ|INE686F01025\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629d601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ZEEL...\n",
      "Fetching data for SUNTV...\n",
      "Fetching data for SUNTV...\n",
      "Fetching data for NYKAA...\n",
      "Fetching data for NYKAA...\n",
      "Fetching data for PAYTM...\n",
      "Fetching data for PAYTM...\n",
      "Fetching data for ETERNAL...\n",
      "Fetching data for ETERNAL...\n",
      "Fetching data for SWIGGY...\n",
      "Fetching data for SWIGGY...\n",
      "Fetching data for MANAPPURAM...\n",
      "Fetching data for MANAPPURAM...\n",
      "Fetching data for SUNDARAMFIN...\n",
      "Fetching data for SUNDARAMFIN...\n",
      "Fetching data for BAJAJFINSV...\n",
      "Fetching data for BAJAJFINSV...\n",
      "Fetching data for BAJFINANCE...\n",
      "Fetching data for BAJFINANCE...\n",
      "Fetching data for M&MFIN...\n",
      "Fetching data for M&MFIN...\n",
      "Fetching data for MUTHOOTFIN...\n",
      "Fetching data for MUTHOOTFIN...\n",
      "Fetching data for POONAWALLA...\n",
      "Fetching data for POONAWALLA...\n",
      "Fetching data for JIOFIN...\n",
      "Fetching data for JIOFIN...\n",
      "Fetching data for BAJAJHLDNG...\n",
      "Fetching data for BAJAJHLDNG...\n",
      "Fetching data for CHOLAFIN...\n",
      "Fetching data for CHOLAFIN...\n",
      "Fetching data for CHOLAHLDNG...\n",
      "Fetching data for CHOLAHLDNG...\n",
      "Fetching data for SHRIRAMFIN...\n",
      "Fetching data for SHRIRAMFIN...\n",
      "Fetching data for CRISIL...\n",
      "Fetching data for CRISIL...\n",
      "Fetching data for CARERATING...\n",
      "Fetching data for CARERATING...\n",
      "Fetching data for CDSL...\n",
      "Fetching data for CDSL...\n",
      "Fetching data for KFINTECH...\n",
      "Fetching data for KFINTECH...\n",
      "Fetching data for BSE...\n",
      "Fetching data for BSE...\n",
      "Fetching data for CAMS...\n",
      "Fetching data for CAMS...\n",
      "Fetching data for POLICYBZR...\n",
      "Fetching data for POLICYBZR...\n",
      "Fetching data for METROBRAND...\n",
      "Fetching data for METROBRAND...\n",
      "Fetching data for TITAN...\n",
      "Fetching data for TITAN...\n",
      "Fetching data for ARVIND...\n",
      "Fetching data for ARVIND...\n",
      "Fetching data for VIPIND...\n",
      "Fetching data for VIPIND...\n",
      "Fetching data for PAGEIND...\n",
      "Fetching data for PAGEIND...\n",
      "Fetching data for KALYANKJIL...\n",
      "Fetching data for KALYANKJIL...\n",
      "Fetching data for RAYMOND...\n",
      "Fetching data for RAYMOND...\n",
      "Fetching data for TRENT...\n",
      "Fetching data for TRENT...\n",
      "Fetching data for ABFRL...\n",
      "Fetching data for ABFRL...\n",
      "Fetching data for TRIDENT...\n",
      "Fetching data for TRIDENT...\n",
      "Fetching data for BATAINDIA...\n",
      "Fetching data for BATAINDIA...\n",
      "Fetching data for BRITANNIA...\n",
      "Fetching data for BRITANNIA...\n",
      "Fetching data for DMART...\n",
      "Fetching data for DMART...\n",
      "Fetching data for TATACONSUM...\n",
      "Fetching data for TATACONSUM...\n",
      "Fetching data for JYOTHYLAB...\n",
      "Fetching data for JYOTHYLAB...\n",
      "Fetching data for EMAMILTD...\n",
      "Fetching data for EMAMILTD...\n",
      "Fetching data for GILLETTE...\n",
      "Fetching data for GILLETTE...\n",
      "Fetching data for DABUR...\n",
      "Fetching data for DABUR...\n",
      "Fetching data for GODREJCP...\n",
      "Fetching data for GODREJCP...\n",
      "Fetching data for AWL...\n",
      "Fetching data for AWL...\n",
      "Fetching data for HINDUNILVR...\n",
      "Fetching data for HINDUNILVR...\n",
      "Fetching data for NESTLEIND...\n",
      "Fetching data for NESTLEIND...\n",
      "Fetching data for JUBLFOOD...\n",
      "Fetching data for JUBLFOOD...\n",
      "Fetching data for ITC...\n",
      "Fetching data for ITC...\n",
      "Fetching data for MARICO...\n",
      "Fetching data for MARICO...\n",
      "Fetching data for VBL...\n",
      "Fetching data for VBL...\n",
      "Fetching data for RADICO...\n",
      "Fetching data for RADICO...\n",
      "Fetching data for UNITDSPR...\n",
      "Fetching data for UNITDSPR...\n",
      "Fetching data for SULA...\n",
      "Fetching data for SULA...\n",
      "Fetching data for UBL...\n",
      "Fetching data for UBL...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABFRL</th>\n",
       "      <th>ARVIND</th>\n",
       "      <th>AWL</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BAJAJHLDNG</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BATAINDIA</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>BSE</th>\n",
       "      <th>CAMS</th>\n",
       "      <th>...</th>\n",
       "      <th>SWIGGY</th>\n",
       "      <th>TATACONSUM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>TRENT</th>\n",
       "      <th>TRIDENT</th>\n",
       "      <th>UBL</th>\n",
       "      <th>UNITDSPR</th>\n",
       "      <th>VBL</th>\n",
       "      <th>VIPIND</th>\n",
       "      <th>ZEEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, ABFRL), (Close, ARVIND), (Close, AWL), (Close, BAJAJFINSV), (Close, BAJAJHLDNG), (Close, BAJFINANCE), (Close, BATAINDIA), (Close, BRITANNIA), (Close, BSE), (Close, CAMS), (Close, CARERATING), (Close, CDSL), (Close, CHOLAFIN), (Close, CHOLAHLDNG), (Close, CRISIL), (Close, DABUR), (Close, DMART), (Close, EMAMILTD), (Close, ETERNAL), (Close, GILLETTE), (Close, GODREJCP), (Close, HINDUNILVR), (Close, ITC), (Close, JIOFIN), (Close, JUBLFOOD), (Close, JYOTHYLAB), (Close, KALYANKJIL), (Close, KFINTECH), (Close, M&MFIN), (Close, MANAPPURAM), (Close, MARICO), (Close, METROBRAND), (Close, MUTHOOTFIN), (Close, NESTLEIND), (Close, NYKAA), (Close, PAGEIND), (Close, PAYTM), (Close, POLICYBZR), (Close, POONAWALLA), (Close, RADICO), (Close, RAYMOND), (Close, SHRIRAMFIN), (Close, SULA), (Close, SUNDARAMFIN), (Close, SUNTV), (Close, SWIGGY), (Close, TATACONSUM), (Close, TITAN), (Close, TRENT), (Close, TRIDENT), (Close, UBL), (Close, UNITDSPR), (Close, VBL), (Close, VIPIND), (Close, ZEEL), (High, ABFRL), (High, ARVIND), (High, AWL), (High, BAJAJFINSV), (High, BAJAJHLDNG), (High, BAJFINANCE), (High, BATAINDIA), (High, BRITANNIA), (High, BSE), (High, CAMS), (High, CARERATING), (High, CDSL), (High, CHOLAFIN), (High, CHOLAHLDNG), (High, CRISIL), (High, DABUR), (High, DMART), (High, EMAMILTD), (High, ETERNAL), (High, GILLETTE), (High, GODREJCP), (High, HINDUNILVR), (High, ITC), (High, JIOFIN), (High, JUBLFOOD), (High, JYOTHYLAB), (High, KALYANKJIL), (High, KFINTECH), (High, M&MFIN), (High, MANAPPURAM), (High, MARICO), (High, METROBRAND), (High, MUTHOOTFIN), (High, NESTLEIND), (High, NYKAA), (High, PAGEIND), (High, PAYTM), (High, POLICYBZR), (High, POONAWALLA), (High, RADICO), (High, RAYMOND), (High, SHRIRAMFIN), (High, SULA), (High, SUNDARAMFIN), (High, SUNTV), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABFRL</th>\n",
       "      <th>ARVIND</th>\n",
       "      <th>AWL</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BAJAJHLDNG</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BATAINDIA</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>BSE</th>\n",
       "      <th>CAMS</th>\n",
       "      <th>...</th>\n",
       "      <th>SWIGGY</th>\n",
       "      <th>TATACONSUM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>TRENT</th>\n",
       "      <th>TRIDENT</th>\n",
       "      <th>UBL</th>\n",
       "      <th>UNITDSPR</th>\n",
       "      <th>VBL</th>\n",
       "      <th>VIPIND</th>\n",
       "      <th>ZEEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>83.64</td>\n",
       "      <td>323.05</td>\n",
       "      <td>272.45</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>12576.0</td>\n",
       "      <td>1061.90</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>2456.4</td>\n",
       "      <td>3938.1</td>\n",
       "      <td>...</td>\n",
       "      <td>923577.0</td>\n",
       "      <td>76662.0</td>\n",
       "      <td>100457.0</td>\n",
       "      <td>76935.0</td>\n",
       "      <td>768329.0</td>\n",
       "      <td>292301.0</td>\n",
       "      <td>131117.0</td>\n",
       "      <td>5645646.0</td>\n",
       "      <td>43849.0</td>\n",
       "      <td>2084771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>83.66</td>\n",
       "      <td>322.60</td>\n",
       "      <td>273.05</td>\n",
       "      <td>2124.2</td>\n",
       "      <td>12497.0</td>\n",
       "      <td>1057.50</td>\n",
       "      <td>1082.3</td>\n",
       "      <td>5828.5</td>\n",
       "      <td>2464.6</td>\n",
       "      <td>3945.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1554058.0</td>\n",
       "      <td>23899.0</td>\n",
       "      <td>91827.0</td>\n",
       "      <td>23252.0</td>\n",
       "      <td>395585.0</td>\n",
       "      <td>178763.0</td>\n",
       "      <td>40780.0</td>\n",
       "      <td>2004955.0</td>\n",
       "      <td>37679.0</td>\n",
       "      <td>1142317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>83.37</td>\n",
       "      <td>321.70</td>\n",
       "      <td>273.60</td>\n",
       "      <td>2110.9</td>\n",
       "      <td>12432.0</td>\n",
       "      <td>1048.30</td>\n",
       "      <td>1079.2</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>2456.9</td>\n",
       "      <td>3941.6</td>\n",
       "      <td>...</td>\n",
       "      <td>353223.0</td>\n",
       "      <td>50795.0</td>\n",
       "      <td>70970.0</td>\n",
       "      <td>30724.0</td>\n",
       "      <td>223747.0</td>\n",
       "      <td>52169.0</td>\n",
       "      <td>82353.0</td>\n",
       "      <td>860194.0</td>\n",
       "      <td>56732.0</td>\n",
       "      <td>842808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>83.20</td>\n",
       "      <td>321.95</td>\n",
       "      <td>274.90</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>12378.0</td>\n",
       "      <td>1048.25</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>5816.0</td>\n",
       "      <td>2450.4</td>\n",
       "      <td>3953.9</td>\n",
       "      <td>...</td>\n",
       "      <td>392627.0</td>\n",
       "      <td>65648.0</td>\n",
       "      <td>28147.0</td>\n",
       "      <td>39294.0</td>\n",
       "      <td>152238.0</td>\n",
       "      <td>19619.0</td>\n",
       "      <td>255071.0</td>\n",
       "      <td>1438338.0</td>\n",
       "      <td>17905.0</td>\n",
       "      <td>1645284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>83.06</td>\n",
       "      <td>321.30</td>\n",
       "      <td>273.45</td>\n",
       "      <td>2106.3</td>\n",
       "      <td>12399.0</td>\n",
       "      <td>1047.25</td>\n",
       "      <td>1074.8</td>\n",
       "      <td>5824.0</td>\n",
       "      <td>2446.3</td>\n",
       "      <td>3953.2</td>\n",
       "      <td>...</td>\n",
       "      <td>159507.0</td>\n",
       "      <td>115665.0</td>\n",
       "      <td>41869.0</td>\n",
       "      <td>39856.0</td>\n",
       "      <td>144349.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>136039.0</td>\n",
       "      <td>2849397.0</td>\n",
       "      <td>14814.0</td>\n",
       "      <td>1252387.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                      Close                                                                                       ...     Volume                                                              \\\n",
       "Ticker                     ABFRL  ARVIND     AWL BAJAJFINSV BAJAJHLDNG BAJFINANCE BATAINDIA BRITANNIA     BSE    CAMS  ...     SWIGGY TATACONSUM     TITAN    TRENT   TRIDENT       UBL  UNITDSPR   \n",
       "Datetime                                                                                                               ...                                                                          \n",
       "2025-10-30 09:15:00+05:30  83.64  323.05  272.45     2129.0    12576.0    1061.90    1078.0    5805.0  2456.4  3938.1  ...   923577.0    76662.0  100457.0  76935.0  768329.0  292301.0  131117.0   \n",
       "2025-10-30 10:15:00+05:30  83.66  322.60  273.05     2124.2    12497.0    1057.50    1082.3    5828.5  2464.6  3945.5  ...  1554058.0    23899.0   91827.0  23252.0  395585.0  178763.0   40780.0   \n",
       "2025-10-30 11:15:00+05:30  83.37  321.70  273.60     2110.9    12432.0    1048.30    1079.2    5811.0  2456.9  3941.6  ...   353223.0    50795.0   70970.0  30724.0  223747.0   52169.0   82353.0   \n",
       "2025-10-30 12:15:00+05:30  83.20  321.95  274.90     2111.0    12378.0    1048.25    1080.0    5816.0  2450.4  3953.9  ...   392627.0    65648.0   28147.0  39294.0  152238.0   19619.0  255071.0   \n",
       "2025-10-30 13:15:00+05:30  83.06  321.30  273.45     2106.3    12399.0    1047.25    1074.8    5824.0  2446.3  3953.2  ...   159507.0   115665.0   41869.0  39856.0  144349.0   34136.0  136039.0   \n",
       "\n",
       "Field                                                     \n",
       "Ticker                           VBL   VIPIND       ZEEL  \n",
       "Datetime                                                  \n",
       "2025-10-30 09:15:00+05:30  5645646.0  43849.0  2084771.0  \n",
       "2025-10-30 10:15:00+05:30  2004955.0  37679.0  1142317.0  \n",
       "2025-10-30 11:15:00+05:30   860194.0  56732.0   842808.0  \n",
       "2025-10-30 12:15:00+05:30  1438338.0  17905.0  1645284.0  \n",
       "2025-10-30 13:15:00+05:30  2849397.0  14814.0  1252387.0  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intrday data for instrument key 6\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS6 = instrumentkey6\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS6.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "    \n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "    \n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None, index5=None, index6=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index6 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index6\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f478c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 275)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>ABFRL</th>\n",
       "      <th>ARVIND</th>\n",
       "      <th>AWL</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BAJAJHLDNG</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BATAINDIA</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>BSE</th>\n",
       "      <th>CAMS</th>\n",
       "      <th>...</th>\n",
       "      <th>SWIGGY</th>\n",
       "      <th>TATACONSUM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>TRENT</th>\n",
       "      <th>TRIDENT</th>\n",
       "      <th>UBL</th>\n",
       "      <th>UNITDSPR</th>\n",
       "      <th>VBL</th>\n",
       "      <th>VIPIND</th>\n",
       "      <th>ZEEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>83.92</td>\n",
       "      <td>327.00</td>\n",
       "      <td>275.50</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>12625.0</td>\n",
       "      <td>1062.00</td>\n",
       "      <td>1075.6</td>\n",
       "      <td>5851.5</td>\n",
       "      <td>2443.0</td>\n",
       "      <td>3855.6</td>\n",
       "      <td>...</td>\n",
       "      <td>949026.0</td>\n",
       "      <td>120437.0</td>\n",
       "      <td>149470.0</td>\n",
       "      <td>59329.0</td>\n",
       "      <td>593755.0</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>146314.0</td>\n",
       "      <td>5567729.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>954477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>84.13</td>\n",
       "      <td>327.70</td>\n",
       "      <td>275.60</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>12615.0</td>\n",
       "      <td>1063.80</td>\n",
       "      <td>1075.1</td>\n",
       "      <td>5850.0</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>3856.9</td>\n",
       "      <td>...</td>\n",
       "      <td>407900.0</td>\n",
       "      <td>52986.0</td>\n",
       "      <td>58865.0</td>\n",
       "      <td>34526.0</td>\n",
       "      <td>773634.0</td>\n",
       "      <td>12388.0</td>\n",
       "      <td>158460.0</td>\n",
       "      <td>1885943.0</td>\n",
       "      <td>14561.0</td>\n",
       "      <td>1003430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>83.64</td>\n",
       "      <td>323.05</td>\n",
       "      <td>272.45</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>12576.0</td>\n",
       "      <td>1061.90</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>2456.4</td>\n",
       "      <td>3938.1</td>\n",
       "      <td>...</td>\n",
       "      <td>923577.0</td>\n",
       "      <td>76662.0</td>\n",
       "      <td>100457.0</td>\n",
       "      <td>76935.0</td>\n",
       "      <td>768329.0</td>\n",
       "      <td>292301.0</td>\n",
       "      <td>131117.0</td>\n",
       "      <td>5645646.0</td>\n",
       "      <td>43849.0</td>\n",
       "      <td>2084771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>83.66</td>\n",
       "      <td>322.60</td>\n",
       "      <td>273.05</td>\n",
       "      <td>2124.2</td>\n",
       "      <td>12497.0</td>\n",
       "      <td>1057.50</td>\n",
       "      <td>1082.3</td>\n",
       "      <td>5828.5</td>\n",
       "      <td>2464.6</td>\n",
       "      <td>3945.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1554058.0</td>\n",
       "      <td>23899.0</td>\n",
       "      <td>91827.0</td>\n",
       "      <td>23252.0</td>\n",
       "      <td>395585.0</td>\n",
       "      <td>178763.0</td>\n",
       "      <td>40780.0</td>\n",
       "      <td>2004955.0</td>\n",
       "      <td>37679.0</td>\n",
       "      <td>1142317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>83.37</td>\n",
       "      <td>321.70</td>\n",
       "      <td>273.60</td>\n",
       "      <td>2110.9</td>\n",
       "      <td>12432.0</td>\n",
       "      <td>1048.30</td>\n",
       "      <td>1079.2</td>\n",
       "      <td>5811.0</td>\n",
       "      <td>2456.9</td>\n",
       "      <td>3941.6</td>\n",
       "      <td>...</td>\n",
       "      <td>353223.0</td>\n",
       "      <td>50795.0</td>\n",
       "      <td>70970.0</td>\n",
       "      <td>30724.0</td>\n",
       "      <td>223747.0</td>\n",
       "      <td>52169.0</td>\n",
       "      <td>82353.0</td>\n",
       "      <td>860194.0</td>\n",
       "      <td>56732.0</td>\n",
       "      <td>842808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>83.20</td>\n",
       "      <td>321.95</td>\n",
       "      <td>274.90</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>12378.0</td>\n",
       "      <td>1048.25</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>5816.0</td>\n",
       "      <td>2450.4</td>\n",
       "      <td>3953.9</td>\n",
       "      <td>...</td>\n",
       "      <td>392627.0</td>\n",
       "      <td>65648.0</td>\n",
       "      <td>28147.0</td>\n",
       "      <td>39294.0</td>\n",
       "      <td>152238.0</td>\n",
       "      <td>19619.0</td>\n",
       "      <td>255071.0</td>\n",
       "      <td>1438338.0</td>\n",
       "      <td>17905.0</td>\n",
       "      <td>1645284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>83.06</td>\n",
       "      <td>321.30</td>\n",
       "      <td>273.45</td>\n",
       "      <td>2106.3</td>\n",
       "      <td>12399.0</td>\n",
       "      <td>1047.25</td>\n",
       "      <td>1074.8</td>\n",
       "      <td>5824.0</td>\n",
       "      <td>2446.3</td>\n",
       "      <td>3953.2</td>\n",
       "      <td>...</td>\n",
       "      <td>159507.0</td>\n",
       "      <td>115665.0</td>\n",
       "      <td>41869.0</td>\n",
       "      <td>39856.0</td>\n",
       "      <td>144349.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>136039.0</td>\n",
       "      <td>2849397.0</td>\n",
       "      <td>14814.0</td>\n",
       "      <td>1252387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>83.06</td>\n",
       "      <td>321.15</td>\n",
       "      <td>276.00</td>\n",
       "      <td>2113.9</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>1051.60</td>\n",
       "      <td>1071.9</td>\n",
       "      <td>5861.0</td>\n",
       "      <td>2442.4</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>400122.0</td>\n",
       "      <td>385636.0</td>\n",
       "      <td>153487.0</td>\n",
       "      <td>84230.0</td>\n",
       "      <td>384614.0</td>\n",
       "      <td>37297.0</td>\n",
       "      <td>173532.0</td>\n",
       "      <td>2525582.0</td>\n",
       "      <td>40958.0</td>\n",
       "      <td>869527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>82.85</td>\n",
       "      <td>322.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>12457.0</td>\n",
       "      <td>1052.50</td>\n",
       "      <td>1072.9</td>\n",
       "      <td>5850.0</td>\n",
       "      <td>2444.0</td>\n",
       "      <td>3951.0</td>\n",
       "      <td>...</td>\n",
       "      <td>339381.0</td>\n",
       "      <td>181864.0</td>\n",
       "      <td>57292.0</td>\n",
       "      <td>52260.0</td>\n",
       "      <td>277207.0</td>\n",
       "      <td>135802.0</td>\n",
       "      <td>139912.0</td>\n",
       "      <td>701250.0</td>\n",
       "      <td>26655.0</td>\n",
       "      <td>899438.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                      Close                                                                                       ...     Volume                                                              \\\n",
       "Ticker                     ABFRL  ARVIND     AWL BAJAJFINSV BAJAJHLDNG BAJFINANCE BATAINDIA BRITANNIA     BSE    CAMS  ...     SWIGGY TATACONSUM     TITAN    TRENT   TRIDENT       UBL  UNITDSPR   \n",
       "Datetime                                                                                                               ...                                                                          \n",
       "2025-10-29 14:15:00+05:30  83.92  327.00  275.50     2133.0    12625.0    1062.00    1075.6    5851.5  2443.0  3855.6  ...   949026.0   120437.0  149470.0  59329.0  593755.0    6108.0  146314.0   \n",
       "2025-10-29 15:15:00+05:30  84.13  327.70  275.60     2140.0    12615.0    1063.80    1075.1    5850.0  2449.0  3856.9  ...   407900.0    52986.0   58865.0  34526.0  773634.0   12388.0  158460.0   \n",
       "2025-10-30 09:15:00+05:30  83.64  323.05  272.45     2129.0    12576.0    1061.90    1078.0    5805.0  2456.4  3938.1  ...   923577.0    76662.0  100457.0  76935.0  768329.0  292301.0  131117.0   \n",
       "2025-10-30 10:15:00+05:30  83.66  322.60  273.05     2124.2    12497.0    1057.50    1082.3    5828.5  2464.6  3945.5  ...  1554058.0    23899.0   91827.0  23252.0  395585.0  178763.0   40780.0   \n",
       "2025-10-30 11:15:00+05:30  83.37  321.70  273.60     2110.9    12432.0    1048.30    1079.2    5811.0  2456.9  3941.6  ...   353223.0    50795.0   70970.0  30724.0  223747.0   52169.0   82353.0   \n",
       "2025-10-30 12:15:00+05:30  83.20  321.95  274.90     2111.0    12378.0    1048.25    1080.0    5816.0  2450.4  3953.9  ...   392627.0    65648.0   28147.0  39294.0  152238.0   19619.0  255071.0   \n",
       "2025-10-30 13:15:00+05:30  83.06  321.30  273.45     2106.3    12399.0    1047.25    1074.8    5824.0  2446.3  3953.2  ...   159507.0   115665.0   41869.0  39856.0  144349.0   34136.0  136039.0   \n",
       "2025-10-30 14:15:00+05:30  83.06  321.15  276.00     2113.9    12438.0    1051.60    1071.9    5861.0  2442.4  3960.0  ...   400122.0   385636.0  153487.0  84230.0  384614.0   37297.0  173532.0   \n",
       "2025-10-30 15:15:00+05:30  82.85  322.00  275.00     2118.0    12457.0    1052.50    1072.9    5850.0  2444.0  3951.0  ...   339381.0   181864.0   57292.0  52260.0  277207.0  135802.0  139912.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                           VBL    VIPIND       ZEEL  \n",
       "Datetime                                                   \n",
       "2025-10-29 14:15:00+05:30  5567729.0  112000.0   954477.0  \n",
       "2025-10-29 15:15:00+05:30  1885943.0   14561.0  1003430.0  \n",
       "2025-10-30 09:15:00+05:30  5645646.0   43849.0  2084771.0  \n",
       "2025-10-30 10:15:00+05:30  2004955.0   37679.0  1142317.0  \n",
       "2025-10-30 11:15:00+05:30   860194.0   56732.0   842808.0  \n",
       "2025-10-30 12:15:00+05:30  1438338.0   17905.0  1645284.0  \n",
       "2025-10-30 13:15:00+05:30  2849397.0   14814.0  1252387.0  \n",
       "2025-10-30 14:15:00+05:30  2525582.0   40958.0   869527.0  \n",
       "2025-10-30 15:15:00+05:30   701250.0   26655.0   899438.0  \n",
       "\n",
       "[9 rows x 275 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine historical and intrday data  for ik6\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik6.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index6  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df6 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df6 = combined_df6[~combined_df6.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df6.shape)\n",
    "print(combined_df6.index.names)\n",
    "print(combined_df6.columns.names)\n",
    "display(combined_df6.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b8184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FVG detection results saved to: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik6(30-10).pkl\n",
      "Master results updated at: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 6 (Retail Fin, etc.) (date: 2025-10-30):\n",
      "        Datetime      Ticker   Pattern    Gap               Range    Previous_FVGs\n",
      "2025-10-30 12:15       ABFRL 🔴 bearish   0.15       83.36 - 83.51 No previous FVGs\n",
      "2025-10-30 10:15       ABFRL 🔴 bearish   0.02       83.87 - 83.89 No previous FVGs\n",
      "2025-10-30 10:15      ARVIND 🔴 bearish   1.25     325.25 - 326.50 No previous FVGs\n",
      "2025-10-30 10:15         AWL 🔴 bearish   1.95     273.10 - 275.05 No previous FVGs\n",
      "2025-10-30 15:15  BAJAJFINSV 🟢 bullish   1.80   2112.00 - 2113.80 No previous FVGs\n",
      "2025-10-30 12:15  BAJAJFINSV 🔴 bearish   4.80   2114.80 - 2119.60 No previous FVGs\n",
      "2025-10-30 10:15  BAJAJFINSV 🔴 bearish   0.10   2131.90 - 2132.00 No previous FVGs\n",
      "2025-10-30 10:15  BAJAJHLDNG 🔴 bearish  23.00 12570.00 - 12593.00 No previous FVGs\n",
      "2025-10-30 15:15  BAJFINANCE 🟢 bullish   2.05   1049.35 - 1051.40 No previous FVGs\n",
      "2025-10-30 12:15  BAJFINANCE 🔴 bearish   1.00   1054.00 - 1055.00 No previous FVGs\n",
      "2025-10-30 14:15   BATAINDIA 🔴 bearish   2.60   1074.80 - 1077.40 No previous FVGs\n",
      "2025-10-30 15:15   BRITANNIA 🟢 bullish  17.50   5832.50 - 5850.00 No previous FVGs\n",
      "2025-10-30 10:15   BRITANNIA 🔴 bearish   6.50   5833.50 - 5840.00 No previous FVGs\n",
      "2025-10-30 13:15         BSE 🔴 bearish   3.30   2451.00 - 2454.30 No previous FVGs\n",
      "2025-10-30 10:15        CAMS 🟢 bullish  57.00   3858.00 - 3915.00 No previous FVGs\n",
      "2025-10-30 12:15  CARERATING 🟢 bullish   4.50   1585.00 - 1589.50 No previous FVGs\n",
      "2025-10-30 10:15       DABUR 🔴 bearish   2.85     504.50 - 507.35 No previous FVGs\n",
      "2025-10-30 13:15       DMART 🔴 bearish  13.30   4176.20 - 4189.50 No previous FVGs\n",
      "2025-10-30 10:15       DMART 🔴 bearish  17.00   4209.00 - 4226.00 No previous FVGs\n",
      "2025-10-30 10:15     ETERNAL 🔴 bearish   2.05     327.95 - 330.00 No previous FVGs\n",
      "2025-10-30 13:15    GILLETTE 🔴 bearish  12.00   9145.00 - 9157.00 No previous FVGs\n",
      "2025-10-30 10:15    GILLETTE 🟢 bullish  21.00   9080.00 - 9101.00 No previous FVGs\n",
      "2025-10-30 10:15  HINDUNILVR 🔴 bearish   2.40   2484.30 - 2486.70 No previous FVGs\n",
      "2025-10-30 13:15      JIOFIN 🔴 bearish   0.15     310.45 - 310.60 No previous FVGs\n",
      "2025-10-30 12:15    JUBLFOOD 🟢 bullish   0.70     609.95 - 610.65 No previous FVGs\n",
      "2025-10-30 10:15    JUBLFOOD 🔴 bearish   2.10     609.95 - 612.05 No previous FVGs\n",
      "2025-10-30 10:15   JYOTHYLAB 🔴 bearish   0.20     320.35 - 320.55 No previous FVGs\n",
      "2025-10-30 13:15  KALYANKJIL 🔴 bearish   2.85     512.80 - 515.65 No previous FVGs\n",
      "2025-10-30 15:15    KFINTECH 🟢 bullish   0.80   1106.50 - 1107.30 No previous FVGs\n",
      "2025-10-30 10:15    KFINTECH 🔴 bearish  10.00   1117.10 - 1127.10 No previous FVGs\n",
      "2025-10-30 14:15  MANAPPURAM 🔴 bearish   0.10     274.90 - 275.00 No previous FVGs\n",
      "2025-10-30 12:15  MANAPPURAM 🔴 bearish   0.55     276.50 - 277.05 No previous FVGs\n",
      "2025-10-30 15:15      MARICO 🟢 bullish   0.30     721.05 - 721.35 No previous FVGs\n",
      "2025-10-30 15:15  METROBRAND 🟢 bullish   1.40   1130.80 - 1132.20 No previous FVGs\n",
      "2025-10-30 10:15       NYKAA 🔴 bearish   0.27     257.14 - 257.41 No previous FVGs\n",
      "2025-10-30 10:15     PAGEIND 🔴 bearish 345.00 40940.00 - 41285.00 No previous FVGs\n",
      "2025-10-30 13:15   POLICYBZR 🟢 bullish   1.60   1824.90 - 1826.50 No previous FVGs\n",
      "2025-10-30 12:15   POLICYBZR 🟢 bullish   4.40   1803.90 - 1808.30 No previous FVGs\n",
      "2025-10-30 10:15   POLICYBZR 🟢 bullish  41.40   1731.00 - 1772.40 No previous FVGs\n",
      "2025-10-30 09:15   POLICYBZR 🟢 bullish  33.30   1731.30 - 1764.60 No previous FVGs\n",
      "2025-10-30 10:15  POONAWALLA 🔴 bearish   0.50     485.50 - 486.00 No previous FVGs\n",
      "2025-10-30 10:15     RAYMOND 🔴 bearish   1.75     583.25 - 585.00 No previous FVGs\n",
      "2025-10-30 12:15  SHRIRAMFIN 🔴 bearish   0.20     741.15 - 741.35 No previous FVGs\n",
      "2025-10-30 10:15        SULA 🟢 bullish   2.50     247.80 - 250.30 No previous FVGs\n",
      "2025-10-30 10:15 SUNDARAMFIN 🔴 bearish   7.50   4628.70 - 4636.20 No previous FVGs\n",
      "2025-10-30 10:15       SUNTV 🔴 bearish   1.25     569.40 - 570.65 No previous FVGs\n",
      "2025-10-30 12:15      SWIGGY 🟢 bullish   0.30     416.70 - 417.00 No previous FVGs\n",
      "2025-10-30 10:15      SWIGGY 🔴 bearish   1.55     416.70 - 418.25 No previous FVGs\n",
      "2025-10-30 15:15  TATACONSUM 🟢 bullish   2.10   1171.50 - 1173.60 No previous FVGs\n",
      "2025-10-30 10:15  TATACONSUM 🔴 bearish   0.80   1174.30 - 1175.10 No previous FVGs\n",
      "2025-10-30 10:15       TRENT 🔴 bearish  21.40   4753.60 - 4775.00 No previous FVGs\n",
      "2025-10-30 10:15         UBL 🔴 bearish  30.50   1807.70 - 1838.20 No previous FVGs\n",
      "2025-10-30 09:15         UBL 🔴 bearish  18.20   1819.80 - 1838.00 No previous FVGs\n",
      "2025-10-30 13:15    UNITDSPR 🟢 bullish   3.50   1381.90 - 1385.40 No previous FVGs\n",
      "2025-10-30 10:15    UNITDSPR 🔴 bearish   0.20   1384.00 - 1384.20 No previous FVGs\n",
      "2025-10-30 13:15         VBL 🔴 bearish   0.60     484.40 - 485.00 No previous FVGs\n",
      "2025-10-30 12:15         VBL 🔴 bearish   0.50     485.50 - 486.00 No previous FVGs\n",
      "2025-10-30 10:15         VBL 🔴 bearish   3.15     490.75 - 493.90 No previous FVGs\n",
      "2025-10-30 11:15      VIPIND 🔴 bearish   2.55     412.00 - 414.55 No previous FVGs\n",
      "2025-10-30 10:15      VIPIND 🔴 bearish   1.30     415.70 - 417.00 No previous FVGs\n",
      "2025-10-30 10:15        ZEEL 🔴 bearish   0.86     102.80 - 103.66 No previous FVGs\n",
      "        Datetime      Ticker   Pattern    Gap               Range    Previous_FVGs\n",
      "2025-10-30 12:15       ABFRL 🔴 bearish   0.15       83.36 - 83.51 No previous FVGs\n",
      "2025-10-30 10:15       ABFRL 🔴 bearish   0.02       83.87 - 83.89 No previous FVGs\n",
      "2025-10-30 10:15      ARVIND 🔴 bearish   1.25     325.25 - 326.50 No previous FVGs\n",
      "2025-10-30 10:15         AWL 🔴 bearish   1.95     273.10 - 275.05 No previous FVGs\n",
      "2025-10-30 15:15  BAJAJFINSV 🟢 bullish   1.80   2112.00 - 2113.80 No previous FVGs\n",
      "2025-10-30 12:15  BAJAJFINSV 🔴 bearish   4.80   2114.80 - 2119.60 No previous FVGs\n",
      "2025-10-30 10:15  BAJAJFINSV 🔴 bearish   0.10   2131.90 - 2132.00 No previous FVGs\n",
      "2025-10-30 10:15  BAJAJHLDNG 🔴 bearish  23.00 12570.00 - 12593.00 No previous FVGs\n",
      "2025-10-30 15:15  BAJFINANCE 🟢 bullish   2.05   1049.35 - 1051.40 No previous FVGs\n",
      "2025-10-30 12:15  BAJFINANCE 🔴 bearish   1.00   1054.00 - 1055.00 No previous FVGs\n",
      "2025-10-30 14:15   BATAINDIA 🔴 bearish   2.60   1074.80 - 1077.40 No previous FVGs\n",
      "2025-10-30 15:15   BRITANNIA 🟢 bullish  17.50   5832.50 - 5850.00 No previous FVGs\n",
      "2025-10-30 10:15   BRITANNIA 🔴 bearish   6.50   5833.50 - 5840.00 No previous FVGs\n",
      "2025-10-30 13:15         BSE 🔴 bearish   3.30   2451.00 - 2454.30 No previous FVGs\n",
      "2025-10-30 10:15        CAMS 🟢 bullish  57.00   3858.00 - 3915.00 No previous FVGs\n",
      "2025-10-30 12:15  CARERATING 🟢 bullish   4.50   1585.00 - 1589.50 No previous FVGs\n",
      "2025-10-30 10:15       DABUR 🔴 bearish   2.85     504.50 - 507.35 No previous FVGs\n",
      "2025-10-30 13:15       DMART 🔴 bearish  13.30   4176.20 - 4189.50 No previous FVGs\n",
      "2025-10-30 10:15       DMART 🔴 bearish  17.00   4209.00 - 4226.00 No previous FVGs\n",
      "2025-10-30 10:15     ETERNAL 🔴 bearish   2.05     327.95 - 330.00 No previous FVGs\n",
      "2025-10-30 13:15    GILLETTE 🔴 bearish  12.00   9145.00 - 9157.00 No previous FVGs\n",
      "2025-10-30 10:15    GILLETTE 🟢 bullish  21.00   9080.00 - 9101.00 No previous FVGs\n",
      "2025-10-30 10:15  HINDUNILVR 🔴 bearish   2.40   2484.30 - 2486.70 No previous FVGs\n",
      "2025-10-30 13:15      JIOFIN 🔴 bearish   0.15     310.45 - 310.60 No previous FVGs\n",
      "2025-10-30 12:15    JUBLFOOD 🟢 bullish   0.70     609.95 - 610.65 No previous FVGs\n",
      "2025-10-30 10:15    JUBLFOOD 🔴 bearish   2.10     609.95 - 612.05 No previous FVGs\n",
      "2025-10-30 10:15   JYOTHYLAB 🔴 bearish   0.20     320.35 - 320.55 No previous FVGs\n",
      "2025-10-30 13:15  KALYANKJIL 🔴 bearish   2.85     512.80 - 515.65 No previous FVGs\n",
      "2025-10-30 15:15    KFINTECH 🟢 bullish   0.80   1106.50 - 1107.30 No previous FVGs\n",
      "2025-10-30 10:15    KFINTECH 🔴 bearish  10.00   1117.10 - 1127.10 No previous FVGs\n",
      "2025-10-30 14:15  MANAPPURAM 🔴 bearish   0.10     274.90 - 275.00 No previous FVGs\n",
      "2025-10-30 12:15  MANAPPURAM 🔴 bearish   0.55     276.50 - 277.05 No previous FVGs\n",
      "2025-10-30 15:15      MARICO 🟢 bullish   0.30     721.05 - 721.35 No previous FVGs\n",
      "2025-10-30 15:15  METROBRAND 🟢 bullish   1.40   1130.80 - 1132.20 No previous FVGs\n",
      "2025-10-30 10:15       NYKAA 🔴 bearish   0.27     257.14 - 257.41 No previous FVGs\n",
      "2025-10-30 10:15     PAGEIND 🔴 bearish 345.00 40940.00 - 41285.00 No previous FVGs\n",
      "2025-10-30 13:15   POLICYBZR 🟢 bullish   1.60   1824.90 - 1826.50 No previous FVGs\n",
      "2025-10-30 12:15   POLICYBZR 🟢 bullish   4.40   1803.90 - 1808.30 No previous FVGs\n",
      "2025-10-30 10:15   POLICYBZR 🟢 bullish  41.40   1731.00 - 1772.40 No previous FVGs\n",
      "2025-10-30 09:15   POLICYBZR 🟢 bullish  33.30   1731.30 - 1764.60 No previous FVGs\n",
      "2025-10-30 10:15  POONAWALLA 🔴 bearish   0.50     485.50 - 486.00 No previous FVGs\n",
      "2025-10-30 10:15     RAYMOND 🔴 bearish   1.75     583.25 - 585.00 No previous FVGs\n",
      "2025-10-30 12:15  SHRIRAMFIN 🔴 bearish   0.20     741.15 - 741.35 No previous FVGs\n",
      "2025-10-30 10:15        SULA 🟢 bullish   2.50     247.80 - 250.30 No previous FVGs\n",
      "2025-10-30 10:15 SUNDARAMFIN 🔴 bearish   7.50   4628.70 - 4636.20 No previous FVGs\n",
      "2025-10-30 10:15       SUNTV 🔴 bearish   1.25     569.40 - 570.65 No previous FVGs\n",
      "2025-10-30 12:15      SWIGGY 🟢 bullish   0.30     416.70 - 417.00 No previous FVGs\n",
      "2025-10-30 10:15      SWIGGY 🔴 bearish   1.55     416.70 - 418.25 No previous FVGs\n",
      "2025-10-30 15:15  TATACONSUM 🟢 bullish   2.10   1171.50 - 1173.60 No previous FVGs\n",
      "2025-10-30 10:15  TATACONSUM 🔴 bearish   0.80   1174.30 - 1175.10 No previous FVGs\n",
      "2025-10-30 10:15       TRENT 🔴 bearish  21.40   4753.60 - 4775.00 No previous FVGs\n",
      "2025-10-30 10:15         UBL 🔴 bearish  30.50   1807.70 - 1838.20 No previous FVGs\n",
      "2025-10-30 09:15         UBL 🔴 bearish  18.20   1819.80 - 1838.00 No previous FVGs\n",
      "2025-10-30 13:15    UNITDSPR 🟢 bullish   3.50   1381.90 - 1385.40 No previous FVGs\n",
      "2025-10-30 10:15    UNITDSPR 🔴 bearish   0.20   1384.00 - 1384.20 No previous FVGs\n",
      "2025-10-30 13:15         VBL 🔴 bearish   0.60     484.40 - 485.00 No previous FVGs\n",
      "2025-10-30 12:15         VBL 🔴 bearish   0.50     485.50 - 486.00 No previous FVGs\n",
      "2025-10-30 10:15         VBL 🔴 bearish   3.15     490.75 - 493.90 No previous FVGs\n",
      "2025-10-30 11:15      VIPIND 🔴 bearish   2.55     412.00 - 414.55 No previous FVGs\n",
      "2025-10-30 10:15      VIPIND 🔴 bearish   1.30     415.70 - 417.00 No previous FVGs\n",
      "2025-10-30 10:15        ZEEL 🔴 bearish   0.86     102.80 - 103.66 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 61\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 6  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey6:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS6\n",
    "combined_df = combined_df6\n",
    "key_name = \"Instrument Key 6 (Retail Fin, etc.)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "\n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik6(31-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "\n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik6(24-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "    # Save combined/master data (overwrites master file — change path if you want daily snapshots)\n",
    "    master_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\")\n",
    "    if master_path.exists():\n",
    "        try:\n",
    "            prev_master = pd.read_pickle(master_path)\n",
    "            # concat and dedupe on Datetime + Ticker (use Datetime_dt when available)\n",
    "            prev_master['Datetime_dt'] = pd.to_datetime(prev_master['Datetime'])\n",
    "            combined_master = pd.concat([prev_master, df_display], ignore_index=True)\n",
    "            combined_master = combined_master.drop_duplicates(subset=['Ticker', 'Datetime_dt'])\n",
    "            combined_master = combined_master.sort_values(['Datetime_dt', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "            combined_master.to_pickle(master_path)\n",
    "        except Exception:\n",
    "            # fallback: overwrite if previous master can't be read\n",
    "            df_display.to_pickle(master_path)\n",
    "    else:\n",
    "        df_display.to_pickle(master_path)\n",
    "\n",
    "    print(f\"Master results updated at: {master_path}\")\n",
    "\n",
    "    # Prepare a friendly display including last-3 info\n",
    "    def format_row_with_prev(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "\n",
    "    # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "427fd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey7 = {\n",
    "    \"INFY\": \"NSE_EQ|INE009A01021\",\n",
    "    \"RELIANCE\": \"NSE_EQ|INE002A01018\", \n",
    "    \"PNBHOUSING\": \"NSE_EQ|INE572E01012\",\n",
    "    \"COFORGE\": \"NSE_EQ|INE591G01025\",\n",
    "    \"ITCHOTELS\":\"NSE_EQ|INE379A01028\",\n",
    "    \"CHALET\":\"NSE_EQ|INE427F01016\",\n",
    "    \"GMRAIRPORT\":\"NSE_EQ|INE776C01039\",\n",
    "    \"EIHOTEL\":\"NSE_EQ|INE230A01023\",\n",
    "    \"INDHOTEL\":\"NSE_EQ|INE053A01029\",\n",
    "    \"LEMONTREE\":\"NSE_EQ|INE970X01018\",\n",
    "    \"INDIGO\":\"NSE_EQ|INE646L01027\",\n",
    "    \"IRCTC\":\"NSE_EQ|INE335Y01020\",\n",
    "    \"KIMS\":\"NSE_EQ|INE967H01025\",\n",
    "    \"NH\":\"NSE_EQ|INE410P01011\",\n",
    "    \"MAXHEALTH\":\"NSE_EQ|INE027H01010\",\n",
    "    \"FORTIS\":\"NSE_EQ|INE061F01013\",\n",
    "    \"APOLLOHOSP\":\"NSE_EQ|INE437A01024\",\n",
    "    \"LALPATHLAB\":\"NSE_EQ|INE600L01024\",\n",
    "    \"ASTERDM\":\"NSE_EQ|INE914M01019\",\n",
    "    \"HOMEFIRST\":\"NSE_EQ|INE481N01025\",\n",
    "    \"HUDCO\":\"NSE_EQ|INE031A01017\",\n",
    "    \"LICHSGFIN\":\"NSE_EQ|INE115A01026\",\n",
    "    \"BAJAJHFL\":\"NSE_EQ|INE377Y01014\",\n",
    "    \"CANFINHOME\":\"NSE_EQ|INE377Y01014\",\n",
    "    \"AAVAS\":\"NSE_EQ|INE216P01012\",\n",
    "    \"APTUS\":\"NSE_EQ|INE852O01025\",\n",
    "    \"SBILIFE\":\"NSE_EQ|INE123W01016\",\n",
    "    \"GODIGIT\":\"NSE_EQ|INE03JT01014\",\n",
    "    \"HDFCLIFE\":\"NSE_EQ|INE795G01014\",\n",
    "    \"ICICIPRULI\":\"NSE_EQ|INE726G01019\",\n",
    "    \"LICI\":\"NSE_EQ|INE0J1Y01017\",\n",
    "    \"ICICIGI\":\"NSE_EQ|INE765G01017\",\n",
    "    \"PERSISTENT\":\"NSE_EQ|INE262H01021\",\n",
    "    \"BSOFT\":\"NSE_EQ|INE836A01035\",\n",
    "    \"MPHASIS\":\"NSE_EQ|INE356A01018\",\n",
    "    \"ZENSARTECH\":\"NSE_EQ|INE520A01027\",\n",
    "    \"TANLA\":\"NSE_EQ|INE483C01032\",\n",
    "    \"OFSS\":\"NSE_EQ|INE881D01027\",\n",
    "    \"NAUKRI\":\"NSE_EQ|INE663F01032\",\n",
    "    \"ECLERX\":\"NSE_EQ|INE738I01010\",\n",
    "    \"SONATSOFTW\":\"NSE_EQ|INE269A01021\",\n",
    "    \"LTTS\":\"NSE_EQ|INE010V01017\",\n",
    "    \"FSL\":\"NSE_EQ|INE684F01012\",\n",
    "    \"AFFLE\":\"NSE_EQ|INE00WC01027\",\n",
    "    \"REDINGTON\":\"NSE_EQ|INE891D01026\",\n",
    "    \"TATAELXSI\":\"NSE_EQ|INE670A01012\",\n",
    "    \"CYIENTDLM\":\"NSE_EQ|INE055S01018\",\n",
    "    \"KPITECH\":\"NSE_EQ|INE04I401011\",\n",
    "    \"TATATECH\":\"NSE_EQ|INE142M01025\",\n",
    "    \"TECHM\":\"NSE_EQ|INE669C01036\",\n",
    "    \"HCLTECH\":\"NSE_EQ|INE860A01027\",\n",
    "    \"LTIM\":\"NSE_EQ|INE214T01019\",\n",
    "    \"TCS\":\"NSE_EQ|INE467B01029\",\n",
    "    \"WIPRO\":\"NSE_EQ|INE075A01022\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0aedf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INFY...\n",
      "Fetching data for RELIANCE...\n",
      "Fetching data for RELIANCE...\n",
      "Fetching data for PNBHOUSING...\n",
      "Fetching data for PNBHOUSING...\n",
      "Fetching data for COFORGE...\n",
      "Fetching data for COFORGE...\n",
      "Fetching data for ITCHOTELS...\n",
      "Fetching data for ITCHOTELS...\n",
      "Fetching data for CHALET...\n",
      "Fetching data for CHALET...\n",
      "Fetching data for GMRAIRPORT...\n",
      "Fetching data for GMRAIRPORT...\n",
      "Fetching data for EIHOTEL...\n",
      "Fetching data for EIHOTEL...\n",
      "Fetching data for INDHOTEL...\n",
      "Fetching data for INDHOTEL...\n",
      "Fetching data for LEMONTREE...\n",
      "Fetching data for LEMONTREE...\n",
      "Fetching data for INDIGO...\n",
      "Fetching data for INDIGO...\n",
      "Fetching data for IRCTC...\n",
      "Fetching data for IRCTC...\n",
      "Fetching data for KIMS...\n",
      "Fetching data for KIMS...\n",
      "Fetching data for NH...\n",
      "Fetching data for NH...\n",
      "Fetching data for MAXHEALTH...\n",
      "Fetching data for MAXHEALTH...\n",
      "Fetching data for FORTIS...\n",
      "Fetching data for FORTIS...\n",
      "Fetching data for APOLLOHOSP...\n",
      "Fetching data for APOLLOHOSP...\n",
      "Fetching data for LALPATHLAB...\n",
      "Fetching data for LALPATHLAB...\n",
      "Fetching data for ASTERDM...\n",
      "Fetching data for ASTERDM...\n",
      "Fetching data for HOMEFIRST...\n",
      "Fetching data for HOMEFIRST...\n",
      "Fetching data for HUDCO...\n",
      "Fetching data for HUDCO...\n",
      "Fetching data for LICHSGFIN...\n",
      "Fetching data for LICHSGFIN...\n",
      "Fetching data for BAJAJHFL...\n",
      "Fetching data for BAJAJHFL...\n",
      "Fetching data for CANFINHOME...\n",
      "Fetching data for CANFINHOME...\n",
      "Fetching data for AAVAS...\n",
      "Fetching data for AAVAS...\n",
      "Fetching data for APTUS...\n",
      "Fetching data for APTUS...\n",
      "Fetching data for SBILIFE...\n",
      "Fetching data for SBILIFE...\n",
      "Fetching data for GODIGIT...\n",
      "Fetching data for GODIGIT...\n",
      "Fetching data for HDFCLIFE...\n",
      "Fetching data for HDFCLIFE...\n",
      "Fetching data for ICICIPRULI...\n",
      "Fetching data for ICICIPRULI...\n",
      "Fetching data for LICI...\n",
      "Fetching data for LICI...\n",
      "Fetching data for ICICIGI...\n",
      "Fetching data for ICICIGI...\n",
      "Fetching data for PERSISTENT...\n",
      "Fetching data for PERSISTENT...\n",
      "Fetching data for BSOFT...\n",
      "Fetching data for BSOFT...\n",
      "Fetching data for MPHASIS...\n",
      "Fetching data for MPHASIS...\n",
      "Fetching data for ZENSARTECH...\n",
      "Fetching data for ZENSARTECH...\n",
      "Fetching data for TANLA...\n",
      "Fetching data for TANLA...\n",
      "Fetching data for OFSS...\n",
      "Fetching data for OFSS...\n",
      "Fetching data for NAUKRI...\n",
      "Fetching data for NAUKRI...\n",
      "Fetching data for ECLERX...\n",
      "Fetching data for ECLERX...\n",
      "Fetching data for SONATSOFTW...\n",
      "Fetching data for SONATSOFTW...\n",
      "Fetching data for LTTS...\n",
      "Fetching data for LTTS...\n",
      "Fetching data for FSL...\n",
      "Fetching data for FSL...\n",
      "Fetching data for AFFLE...\n",
      "Fetching data for AFFLE...\n",
      "Fetching data for REDINGTON...\n",
      "Fetching data for REDINGTON...\n",
      "Fetching data for TATAELXSI...\n",
      "Fetching data for TATAELXSI...\n",
      "Fetching data for CYIENTDLM...\n",
      "Fetching data for CYIENTDLM...\n",
      "Fetching data for KPITECH...\n",
      "Fetching data for KPITECH...\n",
      "Fetching data for TATATECH...\n",
      "Fetching data for TATATECH...\n",
      "Fetching data for TECHM...\n",
      "Fetching data for TECHM...\n",
      "Fetching data for HCLTECH...\n",
      "Fetching data for HCLTECH...\n",
      "Fetching data for LTIM...\n",
      "Fetching data for LTIM...\n",
      "Fetching data for TCS...\n",
      "Fetching data for TCS...\n",
      "Fetching data for WIPRO...\n",
      "Fetching data for WIPRO...\n",
      "MultiIndex DataFrame created successfully\n",
      "MultiIndex DataFrame created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAVAS</th>\n",
       "      <th>AFFLE</th>\n",
       "      <th>APOLLOHOSP</th>\n",
       "      <th>APTUS</th>\n",
       "      <th>ASTERDM</th>\n",
       "      <th>BAJAJHFL</th>\n",
       "      <th>BSOFT</th>\n",
       "      <th>CANFINHOME</th>\n",
       "      <th>CHALET</th>\n",
       "      <th>COFORGE</th>\n",
       "      <th>...</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBILIFE</th>\n",
       "      <th>SONATSOFTW</th>\n",
       "      <th>TANLA</th>\n",
       "      <th>TATAELXSI</th>\n",
       "      <th>TATATECH</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>ZENSARTECH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Close, AAVAS), (Close, AFFLE), (Close, APOLLOHOSP), (Close, APTUS), (Close, ASTERDM), (Close, BAJAJHFL), (Close, BSOFT), (Close, CANFINHOME), (Close, CHALET), (Close, COFORGE), (Close, CYIENTDLM), (Close, ECLERX), (Close, EIHOTEL), (Close, FORTIS), (Close, FSL), (Close, GMRAIRPORT), (Close, GODIGIT), (Close, HCLTECH), (Close, HDFCLIFE), (Close, HOMEFIRST), (Close, HUDCO), (Close, ICICIGI), (Close, ICICIPRULI), (Close, INDHOTEL), (Close, INDIGO), (Close, INFY), (Close, IRCTC), (Close, ITCHOTELS), (Close, KIMS), (Close, KPITECH), (Close, LALPATHLAB), (Close, LEMONTREE), (Close, LICHSGFIN), (Close, LICI), (Close, LTIM), (Close, LTTS), (Close, MAXHEALTH), (Close, MPHASIS), (Close, NAUKRI), (Close, NH), (Close, OFSS), (Close, PERSISTENT), (Close, PNBHOUSING), (Close, REDINGTON), (Close, RELIANCE), (Close, SBILIFE), (Close, SONATSOFTW), (Close, TANLA), (Close, TATAELXSI), (Close, TATATECH), (Close, TCS), (Close, TECHM), (Close, WIPRO), (Close, ZENSARTECH), (High, AAVAS), (High, AFFLE), (High, APOLLOHOSP), (High, APTUS), (High, ASTERDM), (High, BAJAJHFL), (High, BSOFT), (High, CANFINHOME), (High, CHALET), (High, COFORGE), (High, CYIENTDLM), (High, ECLERX), (High, EIHOTEL), (High, FORTIS), (High, FSL), (High, GMRAIRPORT), (High, GODIGIT), (High, HCLTECH), (High, HDFCLIFE), (High, HOMEFIRST), (High, HUDCO), (High, ICICIGI), (High, ICICIPRULI), (High, INDHOTEL), (High, INDIGO), (High, INFY), (High, IRCTC), (High, ITCHOTELS), (High, KIMS), (High, KPITECH), (High, LALPATHLAB), (High, LEMONTREE), (High, LICHSGFIN), (High, LICI), (High, LTIM), (High, LTTS), (High, MAXHEALTH), (High, MPHASIS), (High, NAUKRI), (High, NH), (High, OFSS), (High, PERSISTENT), (High, PNBHOUSING), (High, REDINGTON), (High, RELIANCE), (High, SBILIFE), ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 270 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAVAS</th>\n",
       "      <th>AFFLE</th>\n",
       "      <th>APOLLOHOSP</th>\n",
       "      <th>APTUS</th>\n",
       "      <th>ASTERDM</th>\n",
       "      <th>BAJAJHFL</th>\n",
       "      <th>BSOFT</th>\n",
       "      <th>CANFINHOME</th>\n",
       "      <th>CHALET</th>\n",
       "      <th>COFORGE</th>\n",
       "      <th>...</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBILIFE</th>\n",
       "      <th>SONATSOFTW</th>\n",
       "      <th>TANLA</th>\n",
       "      <th>TATAELXSI</th>\n",
       "      <th>TATATECH</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>ZENSARTECH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1910.9</td>\n",
       "      <td>7796.0</td>\n",
       "      <td>313.50</td>\n",
       "      <td>695.0</td>\n",
       "      <td>110.97</td>\n",
       "      <td>373.10</td>\n",
       "      <td>110.97</td>\n",
       "      <td>950.65</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1124793.0</td>\n",
       "      <td>175985.0</td>\n",
       "      <td>85156.0</td>\n",
       "      <td>122919.0</td>\n",
       "      <td>37109.0</td>\n",
       "      <td>212285.0</td>\n",
       "      <td>407071.0</td>\n",
       "      <td>189861.0</td>\n",
       "      <td>3177070.0</td>\n",
       "      <td>55594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>312.35</td>\n",
       "      <td>696.3</td>\n",
       "      <td>110.86</td>\n",
       "      <td>373.40</td>\n",
       "      <td>110.86</td>\n",
       "      <td>963.80</td>\n",
       "      <td>1804.8</td>\n",
       "      <td>...</td>\n",
       "      <td>955893.0</td>\n",
       "      <td>90274.0</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>24011.0</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>74319.0</td>\n",
       "      <td>190177.0</td>\n",
       "      <td>265743.0</td>\n",
       "      <td>459384.0</td>\n",
       "      <td>13274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>1666.2</td>\n",
       "      <td>1939.5</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>312.50</td>\n",
       "      <td>697.6</td>\n",
       "      <td>110.85</td>\n",
       "      <td>374.40</td>\n",
       "      <td>110.85</td>\n",
       "      <td>962.50</td>\n",
       "      <td>1794.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1759711.0</td>\n",
       "      <td>119338.0</td>\n",
       "      <td>10508.0</td>\n",
       "      <td>43226.0</td>\n",
       "      <td>10426.0</td>\n",
       "      <td>34025.0</td>\n",
       "      <td>690586.0</td>\n",
       "      <td>266306.0</td>\n",
       "      <td>1151224.0</td>\n",
       "      <td>8821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1934.1</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>311.75</td>\n",
       "      <td>696.9</td>\n",
       "      <td>110.63</td>\n",
       "      <td>373.75</td>\n",
       "      <td>110.63</td>\n",
       "      <td>962.00</td>\n",
       "      <td>1805.5</td>\n",
       "      <td>...</td>\n",
       "      <td>617377.0</td>\n",
       "      <td>108422.0</td>\n",
       "      <td>15317.0</td>\n",
       "      <td>15927.0</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>35193.0</td>\n",
       "      <td>150464.0</td>\n",
       "      <td>155540.0</td>\n",
       "      <td>454134.0</td>\n",
       "      <td>22231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>1932.3</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>312.60</td>\n",
       "      <td>696.2</td>\n",
       "      <td>110.55</td>\n",
       "      <td>373.55</td>\n",
       "      <td>110.55</td>\n",
       "      <td>963.10</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995380.0</td>\n",
       "      <td>79284.0</td>\n",
       "      <td>21174.0</td>\n",
       "      <td>18732.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>20323.0</td>\n",
       "      <td>153664.0</td>\n",
       "      <td>150020.0</td>\n",
       "      <td>509770.0</td>\n",
       "      <td>11797.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                 ...     Volume                                                               \\\n",
       "Ticker                      AAVAS   AFFLE APOLLOHOSP   APTUS ASTERDM BAJAJHFL   BSOFT CANFINHOME  CHALET COFORGE  ...   RELIANCE   SBILIFE SONATSOFTW     TANLA TATAELXSI  TATATECH       TCS   \n",
       "Datetime                                                                                                          ...                                                                           \n",
       "2025-10-30 09:15:00+05:30  1651.0  1910.9     7796.0  313.50   695.0   110.97  373.10     110.97  950.65  1803.0  ...  1124793.0  175985.0    85156.0  122919.0   37109.0  212285.0  407071.0   \n",
       "2025-10-30 10:15:00+05:30  1651.0  1933.0     7810.0  312.35   696.3   110.86  373.40     110.86  963.80  1804.8  ...   955893.0   90274.0    24928.0   24011.0   10999.0   74319.0  190177.0   \n",
       "2025-10-30 11:15:00+05:30  1666.2  1939.5     7810.0  312.50   697.6   110.85  374.40     110.85  962.50  1794.2  ...  1759711.0  119338.0    10508.0   43226.0   10426.0   34025.0  690586.0   \n",
       "2025-10-30 12:15:00+05:30  1651.0  1934.1     7812.0  311.75   696.9   110.63  373.75     110.63  962.00  1805.5  ...   617377.0  108422.0    15317.0   15927.0    6860.0   35193.0  150464.0   \n",
       "2025-10-30 13:15:00+05:30  1656.0  1932.3     7800.0  312.60   696.2   110.55  373.55     110.55  963.10  1805.0  ...   995380.0   79284.0    21174.0   18732.0    8963.0   20323.0  153664.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                        TECHM      WIPRO ZENSARTECH  \n",
       "Datetime                                                   \n",
       "2025-10-30 09:15:00+05:30  189861.0  3177070.0    55594.0  \n",
       "2025-10-30 10:15:00+05:30  265743.0   459384.0    13274.0  \n",
       "2025-10-30 11:15:00+05:30  266306.0  1151224.0     8821.0  \n",
       "2025-10-30 12:15:00+05:30  155540.0   454134.0    22231.0  \n",
       "2025-10-30 13:15:00+05:30  150020.0   509770.0    11797.0  \n",
       "\n",
       "[5 rows x 270 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intrday data for instrument key 7\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"  # 🔒 Replace with your actual token\n",
    "INSTRUMENT_KEYS7 = instrumentkey7\n",
    "UNIT = \"hours\"\n",
    "INTERVAL = \"1\"\n",
    "\n",
    "# ---------- FUNCTION ----------\n",
    "def fetch_intraday_candles(instrument_name, instrument_key):\n",
    "    url = f\"https://api.upstox.com/v3/historical-candle/intraday/{instrument_key}/{UNIT}/{INTERVAL}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ API Error for {instrument_name}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    candles = data.get(\"data\", {}).get(\"candles\", [])\n",
    "\n",
    "    if not candles:\n",
    "        print(f\"⚠️ No intraday data for {instrument_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Handle columns (ignore open_interest)\n",
    "    df = pd.DataFrame([c[:6] for c in candles], columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "    # Convert timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # Filter trading hours\n",
    "    df = df[(df[\"timestamp\"].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "            (df[\"timestamp\"].dt.time <= pd.to_datetime(\"15:15\").time())]\n",
    "\n",
    "    # Add ticker name\n",
    "    df[\"ticker\"] = instrument_name\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- FETCH FOR ALL TICKERS ----------\n",
    "all_dfs = []\n",
    "for name, key in INSTRUMENT_KEYS7.items():\n",
    "    print(f\"Fetching data for {name}...\")\n",
    "    df = fetch_intraday_candles(name, key)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "    sleep(0.5)  # slight delay to avoid rate limit\n",
    "\n",
    "# After fetching data for all tickers in all_dfs list:\n",
    "if all_dfs:\n",
    "    \n",
    "    \n",
    "    # First concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(all_dfs)\n",
    "    \n",
    "    # Create pivot table to get MultiIndex columns\n",
    "    pivoted_df = combined_df.pivot(\n",
    "        index='timestamp',\n",
    "        columns='ticker',\n",
    "        values=['open', 'high', 'low', 'close', 'volume']\n",
    "    )\n",
    "    \n",
    "    # Rename index and column levels\n",
    "    pivoted_df.index.name = 'Datetime'\n",
    "    pivoted_df.columns.names = ['Field', 'Ticker']\n",
    "    \n",
    "    # Uppercase field names to match yfinance style\n",
    "    pivoted_df.columns = pivoted_df.columns.set_levels(\n",
    "        ['Open', 'High', 'Low', 'Close', 'Volume'], level=0\n",
    "    )\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    pivoted_df = pivoted_df.sort_index(axis=1)\n",
    "    \n",
    "    # Store result back in df for further processing\n",
    "    df = pivoted_df\n",
    "    \n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    intraday = SimpleNamespace(index4=None, index5=None, index7=None)\n",
    "    \n",
    "    # after you build pivoted_df:\n",
    "    intraday.index7 = pivoted_df\n",
    "    \n",
    "    # later:\n",
    "    df = intraday.index7\n",
    "\n",
    "    print(\"MultiIndex DataFrame created successfully\")\n",
    "    # Show all rows between 9:15 and 15:15\n",
    "    display(df.loc['2025-10-10 09:15:00+05:30':'2025-10-10 15:15:00+05:30'])\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data fetched for any instruments\")\n",
    "    # Still create the container even if empty\n",
    "    from types import SimpleNamespace\n",
    "    intraday = SimpleNamespace(index1=None, index2=None, index3=None, index4=None, index7=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1e6b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 270)\n",
      "['Datetime']\n",
      "['Field', 'Ticker']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAVAS</th>\n",
       "      <th>AFFLE</th>\n",
       "      <th>APOLLOHOSP</th>\n",
       "      <th>APTUS</th>\n",
       "      <th>ASTERDM</th>\n",
       "      <th>BAJAJHFL</th>\n",
       "      <th>BSOFT</th>\n",
       "      <th>CANFINHOME</th>\n",
       "      <th>CHALET</th>\n",
       "      <th>COFORGE</th>\n",
       "      <th>...</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SBILIFE</th>\n",
       "      <th>SONATSOFTW</th>\n",
       "      <th>TANLA</th>\n",
       "      <th>TATAELXSI</th>\n",
       "      <th>TATATECH</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>ZENSARTECH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-29 14:15:00+05:30</th>\n",
       "      <td>1665.7</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>7854.5</td>\n",
       "      <td>317.30</td>\n",
       "      <td>699.95</td>\n",
       "      <td>110.62</td>\n",
       "      <td>375.20</td>\n",
       "      <td>110.62</td>\n",
       "      <td>951.20</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2137758.0</td>\n",
       "      <td>250589.0</td>\n",
       "      <td>46593.0</td>\n",
       "      <td>103402.0</td>\n",
       "      <td>10809.0</td>\n",
       "      <td>69505.0</td>\n",
       "      <td>612529.0</td>\n",
       "      <td>187857.0</td>\n",
       "      <td>1761042.0</td>\n",
       "      <td>43220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29 15:15:00+05:30</th>\n",
       "      <td>1665.5</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>7854.5</td>\n",
       "      <td>316.45</td>\n",
       "      <td>699.10</td>\n",
       "      <td>110.70</td>\n",
       "      <td>375.50</td>\n",
       "      <td>110.70</td>\n",
       "      <td>950.00</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>492604.0</td>\n",
       "      <td>165493.0</td>\n",
       "      <td>57136.0</td>\n",
       "      <td>32466.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>80363.0</td>\n",
       "      <td>222065.0</td>\n",
       "      <td>78731.0</td>\n",
       "      <td>952162.0</td>\n",
       "      <td>44243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 09:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1910.9</td>\n",
       "      <td>7796.0</td>\n",
       "      <td>313.50</td>\n",
       "      <td>695.00</td>\n",
       "      <td>110.97</td>\n",
       "      <td>373.10</td>\n",
       "      <td>110.97</td>\n",
       "      <td>950.65</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1124793.0</td>\n",
       "      <td>175985.0</td>\n",
       "      <td>85156.0</td>\n",
       "      <td>122919.0</td>\n",
       "      <td>37109.0</td>\n",
       "      <td>212285.0</td>\n",
       "      <td>407071.0</td>\n",
       "      <td>189861.0</td>\n",
       "      <td>3177070.0</td>\n",
       "      <td>55594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 10:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>312.35</td>\n",
       "      <td>696.30</td>\n",
       "      <td>110.86</td>\n",
       "      <td>373.40</td>\n",
       "      <td>110.86</td>\n",
       "      <td>963.80</td>\n",
       "      <td>1804.8</td>\n",
       "      <td>...</td>\n",
       "      <td>955893.0</td>\n",
       "      <td>90274.0</td>\n",
       "      <td>24928.0</td>\n",
       "      <td>24011.0</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>74319.0</td>\n",
       "      <td>190177.0</td>\n",
       "      <td>265743.0</td>\n",
       "      <td>459384.0</td>\n",
       "      <td>13274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 11:15:00+05:30</th>\n",
       "      <td>1666.2</td>\n",
       "      <td>1939.5</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>312.50</td>\n",
       "      <td>697.60</td>\n",
       "      <td>110.85</td>\n",
       "      <td>374.40</td>\n",
       "      <td>110.85</td>\n",
       "      <td>962.50</td>\n",
       "      <td>1794.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1759711.0</td>\n",
       "      <td>119338.0</td>\n",
       "      <td>10508.0</td>\n",
       "      <td>43226.0</td>\n",
       "      <td>10426.0</td>\n",
       "      <td>34025.0</td>\n",
       "      <td>690586.0</td>\n",
       "      <td>266306.0</td>\n",
       "      <td>1151224.0</td>\n",
       "      <td>8821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 12:15:00+05:30</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1934.1</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>311.75</td>\n",
       "      <td>696.90</td>\n",
       "      <td>110.63</td>\n",
       "      <td>373.75</td>\n",
       "      <td>110.63</td>\n",
       "      <td>962.00</td>\n",
       "      <td>1805.5</td>\n",
       "      <td>...</td>\n",
       "      <td>617377.0</td>\n",
       "      <td>108422.0</td>\n",
       "      <td>15317.0</td>\n",
       "      <td>15927.0</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>35193.0</td>\n",
       "      <td>150464.0</td>\n",
       "      <td>155540.0</td>\n",
       "      <td>454134.0</td>\n",
       "      <td>22231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 13:15:00+05:30</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>1932.3</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>312.60</td>\n",
       "      <td>696.20</td>\n",
       "      <td>110.55</td>\n",
       "      <td>373.55</td>\n",
       "      <td>110.55</td>\n",
       "      <td>963.10</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995380.0</td>\n",
       "      <td>79284.0</td>\n",
       "      <td>21174.0</td>\n",
       "      <td>18732.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>20323.0</td>\n",
       "      <td>153664.0</td>\n",
       "      <td>150020.0</td>\n",
       "      <td>509770.0</td>\n",
       "      <td>11797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 14:15:00+05:30</th>\n",
       "      <td>1673.2</td>\n",
       "      <td>1930.2</td>\n",
       "      <td>7794.0</td>\n",
       "      <td>312.35</td>\n",
       "      <td>697.40</td>\n",
       "      <td>110.79</td>\n",
       "      <td>376.25</td>\n",
       "      <td>110.79</td>\n",
       "      <td>965.20</td>\n",
       "      <td>1809.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3194165.0</td>\n",
       "      <td>164845.0</td>\n",
       "      <td>34834.0</td>\n",
       "      <td>64488.0</td>\n",
       "      <td>32536.0</td>\n",
       "      <td>77296.0</td>\n",
       "      <td>440388.0</td>\n",
       "      <td>551725.0</td>\n",
       "      <td>1542147.0</td>\n",
       "      <td>35423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30 15:15:00+05:30</th>\n",
       "      <td>1669.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>7798.5</td>\n",
       "      <td>312.60</td>\n",
       "      <td>698.00</td>\n",
       "      <td>110.70</td>\n",
       "      <td>375.50</td>\n",
       "      <td>110.70</td>\n",
       "      <td>966.20</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>...</td>\n",
       "      <td>669143.0</td>\n",
       "      <td>104586.0</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>35299.0</td>\n",
       "      <td>16481.0</td>\n",
       "      <td>50508.0</td>\n",
       "      <td>208264.0</td>\n",
       "      <td>218555.0</td>\n",
       "      <td>1048734.0</td>\n",
       "      <td>22741.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Field                       Close                                                                                 ...     Volume                                                               \\\n",
       "Ticker                      AAVAS   AFFLE APOLLOHOSP   APTUS ASTERDM BAJAJHFL   BSOFT CANFINHOME  CHALET COFORGE  ...   RELIANCE   SBILIFE SONATSOFTW     TANLA TATAELXSI  TATATECH       TCS   \n",
       "Datetime                                                                                                          ...                                                                           \n",
       "2025-10-29 14:15:00+05:30  1665.7  1898.3     7854.5  317.30  699.95   110.62  375.20     110.62  951.20  1794.0  ...  2137758.0  250589.0    46593.0  103402.0   10809.0   69505.0  612529.0   \n",
       "2025-10-29 15:15:00+05:30  1665.5  1912.0     7854.5  316.45  699.10   110.70  375.50     110.70  950.00  1805.0  ...   492604.0  165493.0    57136.0   32466.0    7886.0   80363.0  222065.0   \n",
       "2025-10-30 09:15:00+05:30  1651.0  1910.9     7796.0  313.50  695.00   110.97  373.10     110.97  950.65  1803.0  ...  1124793.0  175985.0    85156.0  122919.0   37109.0  212285.0  407071.0   \n",
       "2025-10-30 10:15:00+05:30  1651.0  1933.0     7810.0  312.35  696.30   110.86  373.40     110.86  963.80  1804.8  ...   955893.0   90274.0    24928.0   24011.0   10999.0   74319.0  190177.0   \n",
       "2025-10-30 11:15:00+05:30  1666.2  1939.5     7810.0  312.50  697.60   110.85  374.40     110.85  962.50  1794.2  ...  1759711.0  119338.0    10508.0   43226.0   10426.0   34025.0  690586.0   \n",
       "2025-10-30 12:15:00+05:30  1651.0  1934.1     7812.0  311.75  696.90   110.63  373.75     110.63  962.00  1805.5  ...   617377.0  108422.0    15317.0   15927.0    6860.0   35193.0  150464.0   \n",
       "2025-10-30 13:15:00+05:30  1656.0  1932.3     7800.0  312.60  696.20   110.55  373.55     110.55  963.10  1805.0  ...   995380.0   79284.0    21174.0   18732.0    8963.0   20323.0  153664.0   \n",
       "2025-10-30 14:15:00+05:30  1673.2  1930.2     7794.0  312.35  697.40   110.79  376.25     110.79  965.20  1809.5  ...  3194165.0  164845.0    34834.0   64488.0   32536.0   77296.0  440388.0   \n",
       "2025-10-30 15:15:00+05:30  1669.0  1935.0     7798.5  312.60  698.00   110.70  375.50     110.70  966.20  1808.0  ...   669143.0  104586.0    24347.0   35299.0   16481.0   50508.0  208264.0   \n",
       "\n",
       "Field                                                      \n",
       "Ticker                        TECHM      WIPRO ZENSARTECH  \n",
       "Datetime                                                   \n",
       "2025-10-29 14:15:00+05:30  187857.0  1761042.0    43220.0  \n",
       "2025-10-29 15:15:00+05:30   78731.0   952162.0    44243.0  \n",
       "2025-10-30 09:15:00+05:30  189861.0  3177070.0    55594.0  \n",
       "2025-10-30 10:15:00+05:30  265743.0   459384.0    13274.0  \n",
       "2025-10-30 11:15:00+05:30  266306.0  1151224.0     8821.0  \n",
       "2025-10-30 12:15:00+05:30  155540.0   454134.0    22231.0  \n",
       "2025-10-30 13:15:00+05:30  150020.0   509770.0    11797.0  \n",
       "2025-10-30 14:15:00+05:30  551725.0  1542147.0    35423.0  \n",
       "2025-10-30 15:15:00+05:30  218555.0  1048734.0    22741.0  \n",
       "\n",
       "[9 rows x 270 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine historical and intrday data for ik 7\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load historical\n",
    "hist_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\historical_ik7.pkl\")\n",
    "df_historical = pd.read_pickle(hist_path)\n",
    "\n",
    "# 2) Point this to your in-memory intraday DataFrame\n",
    "df_intraday = intraday.index7  # <-- replace with your variable (the MultiIndex DF you just built)\n",
    "\n",
    "# 3) Optional: align timezone of index (only if both are DatetimeIndex and differ)\n",
    "if isinstance(df_historical.index, pd.DatetimeIndex) and isinstance(df_intraday.index, pd.DatetimeIndex):\n",
    "    if df_historical.index.tz is not df_intraday.index.tz:\n",
    "        df_intraday = df_intraday.tz_convert(df_historical.index.tz) if df_intraday.index.tz else df_intraday.tz_localize(df_historical.index.tz)\n",
    "\n",
    "# 4) Validate MultiIndex columns\n",
    "if not isinstance(df_historical.columns, pd.MultiIndex) or not isinstance(df_intraday.columns, pd.MultiIndex):\n",
    "    raise TypeError(\"Both DataFrames must have MultiIndex columns like ['Field','Ticker'].\")\n",
    "\n",
    "# 5) Combine: union columns, intraday overrides on overlapping timestamps\n",
    "all_cols = df_historical.columns.union(df_intraday.columns)\n",
    "hist  = df_historical.reindex(columns=all_cols)\n",
    "intra = df_intraday.reindex(columns=all_cols)\n",
    "\n",
    "combined_df7 = pd.concat([hist, intra]).sort_index()\n",
    "combined_df7 = combined_df7[~combined_df7.index.duplicated(keep=\"last\")]\n",
    "\n",
    "# 6) Inspect and optionally save\n",
    "print(combined_df7.shape)\n",
    "print(combined_df7.index.names)\n",
    "print(combined_df7.columns.names)\n",
    "display(combined_df7.tail(10))\n",
    "\n",
    "# Optional: save\n",
    "# combined_df.to_pickle(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\combined_ik2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fd47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FVG detection results saved to: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik7(30-10).pkl\n",
      "Master results updated at: c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\n",
      "\n",
      "FVG Detection Results for Instrument Key 7 (IT, Insurance and Home Fin etc.) (date: 2025-10-30):\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 15:15      AAVAS 🟢 bullish 10.80 1658.20 - 1669.00 No previous FVGs\n",
      "2025-10-30 10:15      AAVAS 🔴 bearish 10.90 1653.60 - 1664.50 No previous FVGs\n",
      "2025-10-30 11:15      AFFLE 🟢 bullish  4.30 1923.90 - 1928.20 No previous FVGs\n",
      "2025-10-30 10:15 APOLLOHOSP 🔴 bearish 40.00 7814.00 - 7854.00 No previous FVGs\n",
      "2025-10-30 10:15      APTUS 🔴 bearish  2.50   313.50 - 316.00 No previous FVGs\n",
      "2025-10-30 10:15    ASTERDM 🔴 bearish  2.10   696.70 - 698.80 No previous FVGs\n",
      "2025-10-30 15:15      BSOFT 🟢 bullish  1.30   374.10 - 375.40 No previous FVGs\n",
      "2025-10-30 10:15      BSOFT 🔴 bearish  0.85   373.65 - 374.50 No previous FVGs\n",
      "2025-10-30 11:15     CHALET 🟢 bullish  6.00   955.00 - 961.00 No previous FVGs\n",
      "2025-10-30 11:15  CYIENTDLM 🟢 bullish  0.45   459.55 - 460.00 No previous FVGs\n",
      "2025-10-30 15:15     ECLERX 🟢 bullish 18.00 4670.00 - 4688.00 No previous FVGs\n",
      "2025-10-30 10:15     ECLERX 🟢 bullish  4.70 4649.70 - 4654.40 No previous FVGs\n",
      "2025-10-30 11:15    EIHOTEL 🟢 bullish  0.80   390.75 - 391.55 No previous FVGs\n",
      "2025-10-30 15:15        FSL 🟢 bullish  0.65   352.35 - 353.00 No previous FVGs\n",
      "2025-10-30 10:15        FSL 🟢 bullish  0.30   350.50 - 350.80 No previous FVGs\n",
      "2025-10-30 10:15 GMRAIRPORT 🟢 bullish  0.51     93.58 - 94.09 No previous FVGs\n",
      "2025-10-30 09:15 GMRAIRPORT 🟢 bullish  0.27     92.93 - 93.20 No previous FVGs\n",
      "2025-10-30 10:15    GODIGIT 🔴 bearish  0.85   362.40 - 363.25 No previous FVGs\n",
      "2025-10-30 10:15    HCLTECH 🔴 bearish  9.20 1546.80 - 1556.00 No previous FVGs\n",
      "2025-10-30 12:15   HDFCLIFE 🔴 bearish  0.90   747.20 - 748.10 No previous FVGs\n",
      "2025-10-30 10:15   HDFCLIFE 🔴 bearish  8.30   751.00 - 759.30 No previous FVGs\n",
      "2025-10-30 13:15  HOMEFIRST 🔴 bearish  1.10 1207.90 - 1209.00 No previous FVGs\n",
      "2025-10-30 15:15      HUDCO 🟢 bullish  0.81   238.10 - 238.91 No previous FVGs\n",
      "2025-10-30 12:15      HUDCO 🟢 bullish  0.30   235.40 - 235.70 No previous FVGs\n",
      "2025-10-30 10:15    ICICIGI 🔴 bearish 11.90 2015.20 - 2027.10 No previous FVGs\n",
      "2025-10-30 13:15     INDIGO 🔴 bearish 16.00 5739.00 - 5755.00 No previous FVGs\n",
      "2025-10-30 10:15     INDIGO 🔴 bearish 18.50 5786.50 - 5805.00 No previous FVGs\n",
      "2025-10-30 13:15       INFY 🔴 bearish  1.40 1494.80 - 1496.20 No previous FVGs\n",
      "2025-10-30 10:15       INFY 🔴 bearish  9.50 1500.10 - 1509.60 No previous FVGs\n",
      "2025-10-30 13:15  ITCHOTELS 🔴 bearish  0.44   218.96 - 219.40 No previous FVGs\n",
      "2025-10-30 10:15  ITCHOTELS 🟢 bullish  0.38   219.22 - 219.60 No previous FVGs\n",
      "2025-10-30 10:15       KIMS 🔴 bearish  0.15   731.70 - 731.85 No previous FVGs\n",
      "2025-10-30 10:15    KPITECH 🔴 bearish 20.10 1171.90 - 1192.00 No previous FVGs\n",
      "2025-10-30 12:15 LALPATHLAB 🔴 bearish  1.50 3087.40 - 3088.90 No previous FVGs\n",
      "2025-10-30 11:15  LEMONTREE 🟢 bullish  0.74   166.46 - 167.20 No previous FVGs\n",
      "2025-10-30 10:15  LICHSGFIN 🔴 bearish 15.35   576.90 - 592.25 No previous FVGs\n",
      "2025-10-30 10:15       LICI 🔴 bearish  4.70   902.10 - 906.80 No previous FVGs\n",
      "2025-10-30 15:15       LTIM 🟢 bullish 17.00 5677.00 - 5694.00 No previous FVGs\n",
      "2025-10-30 12:15       LTIM 🟢 bullish  4.00 5657.50 - 5661.50 No previous FVGs\n",
      "2025-10-30 10:15       LTIM 🔴 bearish  9.50 5657.50 - 5667.00 No previous FVGs\n",
      "2025-10-30 15:15       LTTS 🟢 bullish 11.50 4090.20 - 4101.70 No previous FVGs\n",
      "2025-10-30 10:15  MAXHEALTH 🔴 bearish  5.90 1182.40 - 1188.30 No previous FVGs\n",
      "2025-10-30 13:15    MPHASIS 🟢 bullish  1.90 2872.00 - 2873.90 No previous FVGs\n",
      "2025-10-30 10:15     NAUKRI 🔴 bearish  1.70 1382.90 - 1384.60 No previous FVGs\n",
      "2025-10-30 10:15       OFSS 🔴 bearish 35.50 8614.00 - 8649.50 No previous FVGs\n",
      "2025-10-30 15:15 PERSISTENT 🟢 bullish  2.00 5948.00 - 5950.00 No previous FVGs\n",
      "2025-10-30 10:15 PNBHOUSING 🔴 bearish  1.45   936.05 - 937.50 No previous FVGs\n",
      "2025-10-30 10:15  REDINGTON 🔴 bearish  1.15   261.35 - 262.50 No previous FVGs\n",
      "2025-10-30 14:15   RELIANCE 🔴 bearish  1.20 1491.50 - 1492.70 No previous FVGs\n",
      "2025-10-30 10:15   RELIANCE 🔴 bearish  4.80 1498.30 - 1503.10 No previous FVGs\n",
      "2025-10-30 15:15    SBILIFE 🟢 bullish  2.90 1964.40 - 1967.30 No previous FVGs\n",
      "2025-10-30 10:15    SBILIFE 🔴 bearish  1.20 1965.80 - 1967.00 No previous FVGs\n",
      "2025-10-30 10:15 SONATSOFTW 🔴 bearish  1.90   371.65 - 373.55 No previous FVGs\n",
      "2025-10-30 10:15      TANLA 🔴 bearish  1.65   615.50 - 617.15 No previous FVGs\n",
      "2025-10-30 15:15  TATAELXSI 🟢 bullish  4.50 5526.00 - 5530.50 No previous FVGs\n",
      "2025-10-30 11:15   TATATECH 🔴 bearish  0.05   700.00 - 700.05 No previous FVGs\n",
      "2025-10-30 10:15        TCS 🔴 bearish  7.70 3047.90 - 3055.60 No previous FVGs\n",
      "2025-10-30 10:15      TECHM 🔴 bearish  7.00 1443.80 - 1450.80 No previous FVGs\n",
      "2025-10-30 15:15      WIPRO 🟢 bullish  0.49   241.27 - 241.76 No previous FVGs\n",
      "2025-10-30 10:15      WIPRO 🔴 bearish  0.16   241.87 - 242.03 No previous FVGs\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 15:15      AAVAS 🟢 bullish 10.80 1658.20 - 1669.00 No previous FVGs\n",
      "2025-10-30 10:15      AAVAS 🔴 bearish 10.90 1653.60 - 1664.50 No previous FVGs\n",
      "2025-10-30 11:15      AFFLE 🟢 bullish  4.30 1923.90 - 1928.20 No previous FVGs\n",
      "2025-10-30 10:15 APOLLOHOSP 🔴 bearish 40.00 7814.00 - 7854.00 No previous FVGs\n",
      "2025-10-30 10:15      APTUS 🔴 bearish  2.50   313.50 - 316.00 No previous FVGs\n",
      "2025-10-30 10:15    ASTERDM 🔴 bearish  2.10   696.70 - 698.80 No previous FVGs\n",
      "2025-10-30 15:15      BSOFT 🟢 bullish  1.30   374.10 - 375.40 No previous FVGs\n",
      "2025-10-30 10:15      BSOFT 🔴 bearish  0.85   373.65 - 374.50 No previous FVGs\n",
      "2025-10-30 11:15     CHALET 🟢 bullish  6.00   955.00 - 961.00 No previous FVGs\n",
      "2025-10-30 11:15  CYIENTDLM 🟢 bullish  0.45   459.55 - 460.00 No previous FVGs\n",
      "2025-10-30 15:15     ECLERX 🟢 bullish 18.00 4670.00 - 4688.00 No previous FVGs\n",
      "2025-10-30 10:15     ECLERX 🟢 bullish  4.70 4649.70 - 4654.40 No previous FVGs\n",
      "2025-10-30 11:15    EIHOTEL 🟢 bullish  0.80   390.75 - 391.55 No previous FVGs\n",
      "2025-10-30 15:15        FSL 🟢 bullish  0.65   352.35 - 353.00 No previous FVGs\n",
      "2025-10-30 10:15        FSL 🟢 bullish  0.30   350.50 - 350.80 No previous FVGs\n",
      "2025-10-30 10:15 GMRAIRPORT 🟢 bullish  0.51     93.58 - 94.09 No previous FVGs\n",
      "2025-10-30 09:15 GMRAIRPORT 🟢 bullish  0.27     92.93 - 93.20 No previous FVGs\n",
      "2025-10-30 10:15    GODIGIT 🔴 bearish  0.85   362.40 - 363.25 No previous FVGs\n",
      "2025-10-30 10:15    HCLTECH 🔴 bearish  9.20 1546.80 - 1556.00 No previous FVGs\n",
      "2025-10-30 12:15   HDFCLIFE 🔴 bearish  0.90   747.20 - 748.10 No previous FVGs\n",
      "2025-10-30 10:15   HDFCLIFE 🔴 bearish  8.30   751.00 - 759.30 No previous FVGs\n",
      "2025-10-30 13:15  HOMEFIRST 🔴 bearish  1.10 1207.90 - 1209.00 No previous FVGs\n",
      "2025-10-30 15:15      HUDCO 🟢 bullish  0.81   238.10 - 238.91 No previous FVGs\n",
      "2025-10-30 12:15      HUDCO 🟢 bullish  0.30   235.40 - 235.70 No previous FVGs\n",
      "2025-10-30 10:15    ICICIGI 🔴 bearish 11.90 2015.20 - 2027.10 No previous FVGs\n",
      "2025-10-30 13:15     INDIGO 🔴 bearish 16.00 5739.00 - 5755.00 No previous FVGs\n",
      "2025-10-30 10:15     INDIGO 🔴 bearish 18.50 5786.50 - 5805.00 No previous FVGs\n",
      "2025-10-30 13:15       INFY 🔴 bearish  1.40 1494.80 - 1496.20 No previous FVGs\n",
      "2025-10-30 10:15       INFY 🔴 bearish  9.50 1500.10 - 1509.60 No previous FVGs\n",
      "2025-10-30 13:15  ITCHOTELS 🔴 bearish  0.44   218.96 - 219.40 No previous FVGs\n",
      "2025-10-30 10:15  ITCHOTELS 🟢 bullish  0.38   219.22 - 219.60 No previous FVGs\n",
      "2025-10-30 10:15       KIMS 🔴 bearish  0.15   731.70 - 731.85 No previous FVGs\n",
      "2025-10-30 10:15    KPITECH 🔴 bearish 20.10 1171.90 - 1192.00 No previous FVGs\n",
      "2025-10-30 12:15 LALPATHLAB 🔴 bearish  1.50 3087.40 - 3088.90 No previous FVGs\n",
      "2025-10-30 11:15  LEMONTREE 🟢 bullish  0.74   166.46 - 167.20 No previous FVGs\n",
      "2025-10-30 10:15  LICHSGFIN 🔴 bearish 15.35   576.90 - 592.25 No previous FVGs\n",
      "2025-10-30 10:15       LICI 🔴 bearish  4.70   902.10 - 906.80 No previous FVGs\n",
      "2025-10-30 15:15       LTIM 🟢 bullish 17.00 5677.00 - 5694.00 No previous FVGs\n",
      "2025-10-30 12:15       LTIM 🟢 bullish  4.00 5657.50 - 5661.50 No previous FVGs\n",
      "2025-10-30 10:15       LTIM 🔴 bearish  9.50 5657.50 - 5667.00 No previous FVGs\n",
      "2025-10-30 15:15       LTTS 🟢 bullish 11.50 4090.20 - 4101.70 No previous FVGs\n",
      "2025-10-30 10:15  MAXHEALTH 🔴 bearish  5.90 1182.40 - 1188.30 No previous FVGs\n",
      "2025-10-30 13:15    MPHASIS 🟢 bullish  1.90 2872.00 - 2873.90 No previous FVGs\n",
      "2025-10-30 10:15     NAUKRI 🔴 bearish  1.70 1382.90 - 1384.60 No previous FVGs\n",
      "2025-10-30 10:15       OFSS 🔴 bearish 35.50 8614.00 - 8649.50 No previous FVGs\n",
      "2025-10-30 15:15 PERSISTENT 🟢 bullish  2.00 5948.00 - 5950.00 No previous FVGs\n",
      "2025-10-30 10:15 PNBHOUSING 🔴 bearish  1.45   936.05 - 937.50 No previous FVGs\n",
      "2025-10-30 10:15  REDINGTON 🔴 bearish  1.15   261.35 - 262.50 No previous FVGs\n",
      "2025-10-30 14:15   RELIANCE 🔴 bearish  1.20 1491.50 - 1492.70 No previous FVGs\n",
      "2025-10-30 10:15   RELIANCE 🔴 bearish  4.80 1498.30 - 1503.10 No previous FVGs\n",
      "2025-10-30 15:15    SBILIFE 🟢 bullish  2.90 1964.40 - 1967.30 No previous FVGs\n",
      "2025-10-30 10:15    SBILIFE 🔴 bearish  1.20 1965.80 - 1967.00 No previous FVGs\n",
      "2025-10-30 10:15 SONATSOFTW 🔴 bearish  1.90   371.65 - 373.55 No previous FVGs\n",
      "2025-10-30 10:15      TANLA 🔴 bearish  1.65   615.50 - 617.15 No previous FVGs\n",
      "2025-10-30 15:15  TATAELXSI 🟢 bullish  4.50 5526.00 - 5530.50 No previous FVGs\n",
      "2025-10-30 11:15   TATATECH 🔴 bearish  0.05   700.00 - 700.05 No previous FVGs\n",
      "2025-10-30 10:15        TCS 🔴 bearish  7.70 3047.90 - 3055.60 No previous FVGs\n",
      "2025-10-30 10:15      TECHM 🔴 bearish  7.00 1443.80 - 1450.80 No previous FVGs\n",
      "2025-10-30 15:15      WIPRO 🟢 bullish  0.49   241.27 - 241.76 No previous FVGs\n",
      "2025-10-30 10:15      WIPRO 🔴 bearish  0.16   241.87 - 242.03 No previous FVGs\n",
      "\n",
      "Total FVGs detected today: 60\n"
     ]
    }
   ],
   "source": [
    "# ===== FVG detector for instrument key 7  =====\n",
    "# Just change these 3 variables for different instrument keys:\n",
    "\n",
    "# For instrumentkey2:\n",
    "INSTRUMENT_KEYS = INSTRUMENT_KEYS7\n",
    "combined_df = combined_df7\n",
    "key_name = \"Instrument Key 7 (IT, Insurance and Home Fin etc.)\"\n",
    "\n",
    "# Process FVG detection results for all instruments\n",
    "all_results = []\n",
    "\n",
    "# Process each ticker separately\n",
    "for ticker in INSTRUMENT_KEYS.keys():\n",
    "    try:\n",
    "        # Extract OHLC data for this ticker - without time filtering initially\n",
    "        ticker_df = pd.DataFrame({\n",
    "            'Open': combined_df[('Open', ticker)],\n",
    "            'High': combined_df[('High', ticker)],\n",
    "            'Low': combined_df[('Low', ticker)],\n",
    "            'Close': combined_df[('Close', ticker)]\n",
    "        }).sort_index()  # Ensure chronological order\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ticker_df) < 3:\n",
    "            print(f\"Skipping {ticker} - insufficient data points\")\n",
    "            continue\n",
    "            \n",
    "        # Run FVG detection\n",
    "        fvg_list = detect_fvg(ticker_df)\n",
    "        \n",
    "        # Create results DataFrame for this ticker\n",
    "        if fvg_list:\n",
    "            df_instrument = pd.DataFrame()\n",
    "            df_instrument['Ticker'] = [ticker] * len(ticker_df)\n",
    "            df_instrument['Datetime'] = ticker_df.index\n",
    "            df_instrument['FVG_type'] = [x[0] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_gap'] = [x[2] - x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_low'] = [x[1] if x is not None else None for x in fvg_list]\n",
    "            df_instrument['FVG_high'] = [x[2] if x is not None else None for x in fvg_list]\n",
    "            \n",
    "            # Only keep rows where FVG was detected\n",
    "            df_instrument = df_instrument[df_instrument['FVG_type'].notna()]\n",
    "            \n",
    "            if not df_instrument.empty:\n",
    "                all_results.append(df_instrument)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    # Combine all results\n",
    "    df_display = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Sort by datetime descending\n",
    "    df_display['Datetime'] = pd.to_datetime(df_display['Datetime'])\n",
    "    df_display = df_display.sort_values(['Datetime', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # Format datetime for better readability\n",
    "    df_display['Datetime'] = df_display['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Format FVG values\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "\n",
    "    # Save the raw data to pickle\n",
    "    output_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\FVG detection results\\fvg_detection_resultsik7(30-10).pkl\")\n",
    "    df_display.to_pickle(output_path)\n",
    "    print(f\"\\nFVG detection results saved to: {output_path}\")\n",
    "\n",
    "    # Check if file exists and load previous data\n",
    "    pkl_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik7(24-10).pkl\")\n",
    "    if pkl_path.exists():\n",
    "        previous_data = pd.read_pickle(pkl_path)\n",
    "        # Combine with new data\n",
    "        df_display = pd.concat([previous_data, df_display], ignore_index=True)\n",
    "        # Remove duplicates if any\n",
    "        df_display = df_display.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "\n",
    "    # --- Preserve a machine-readable datetime column for comparisons ---\n",
    "    # If 'Datetime' was formatted to string earlier, restore datetime for logic\n",
    "    df_display['Datetime_dt'] = pd.to_datetime(df_display['Datetime'])\n",
    "\n",
    "    # Ensure sorting (newest last makes \"previous\" selection simpler)\n",
    "    df_display = df_display.sort_values(['Ticker', 'Datetime_dt'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    # Function to compute last 3 previous FVGs and relation (above / below / inside / overlap)\n",
    "    def relation_to_prev(curr_low, curr_high, prev_low, prev_high):\n",
    "        if (curr_low >= prev_low) and (curr_high <= prev_high):\n",
    "            return \"inside\"\n",
    "        if curr_low > prev_high:\n",
    "            return \"above\"\n",
    "        if curr_high < prev_low:\n",
    "            return \"below\"\n",
    "        return \"overlap\"\n",
    "\n",
    "    def get_last_3_fvgs_info(row, df_all):\n",
    "        \"\"\"\n",
    "        Return up to 3 previous FVGs for the same ticker but only from earlier dates\n",
    "        (exclude FVGs from the current row's date).\n",
    "        \"\"\"\n",
    "        ticker = row['Ticker']\n",
    "        dt = row['Datetime_dt']\n",
    "        curr_low = row['FVG_low']\n",
    "        curr_high = row['FVG_high']\n",
    "        # Ensure Date_only column exists (should be created earlier, but be defensive)\n",
    "        if 'Date_only' not in df_all.columns:\n",
    "            df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "\n",
    "        curr_date = pd.to_datetime(dt).date()\n",
    "\n",
    "        # Only consider previous FVGs strictly before the current date\n",
    "        prev = (\n",
    "            df_all[\n",
    "                (df_all['Ticker'] == ticker) &\n",
    "                (df_all['Date_only'] < curr_date)\n",
    "            ]\n",
    "            .sort_values('Datetime_dt', ascending=False)\n",
    "            .head(3)\n",
    "        )\n",
    "\n",
    "        if prev.empty:\n",
    "            return \"No previous FVGs\"\n",
    "\n",
    "        infos = []\n",
    "        for _, p in prev.iterrows():\n",
    "            p_low = p['FVG_low']\n",
    "            p_high = p['FVG_high']\n",
    "            rel = relation_to_prev(curr_low, curr_high, p_low, p_high)\n",
    "            symbol = '🟢' if p['FVG_type'] == 'bullish' else '🔴'\n",
    "            infos.append(\n",
    "                f\"{p['Datetime_dt'].strftime('%Y-%m-%d %H:%M')}: {symbol} {p['FVG_type']}, {p_low:.2f}-{p_high:.2f} ({rel})\"\n",
    "            )\n",
    "        return \" | \".join(infos)\n",
    "\n",
    "\n",
    "    # Compute last-3 info for each detected FVG row\n",
    "    df_display['Last_3_FVGs'] = df_display.apply(lambda r: get_last_3_fvgs_info(r, df_display), axis=1)\n",
    "\n",
    "    # Format datetime for human display (keep the dt column for future logic)\n",
    "    df_display['Datetime'] = df_display['Datetime_dt'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Format FVG values for display\n",
    "    df_display['FVG_gap'] = df_display['FVG_gap'].round(2)\n",
    "    df_display['FVG_low'] = df_display['FVG_low'].round(2)\n",
    "    df_display['FVG_high'] = df_display['FVG_high'].round(2)\n",
    "    \n",
    "    # --- SHOW ONLY CURRENT DATE'S PRIMARY ROWS, but keep previous-FVGs from history ---\n",
    "    import pandas as _pd\n",
    "    today = _pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "\n",
    "    # --- Ensure we have a full copy named df_all (was missing -> NameError) ---\n",
    "    df_all = df_display.copy()\n",
    "\n",
    "    # Make Datetime_dt timezone-aware in Asia/Kolkata before extracting date\n",
    "    # If it's naive, assume UTC then convert; adjust if you prefer a different default.\n",
    "    if df_all['Datetime_dt'].dt.tz is None:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    else:\n",
    "        df_all['Datetime_dt'] = df_all['Datetime_dt'].dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "    # Now safe to get date part\n",
    "    df_all['Date_only'] = df_all['Datetime_dt'].dt.date\n",
    "    df_today = df_all[df_all['Date_only'] == today].copy()\n",
    "\n",
    "    # Save combined/master data (overwrites master file — change path if you want daily snapshots)\n",
    "    master_path = Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_master.pkl\")\n",
    "    if master_path.exists():\n",
    "        try:\n",
    "            prev_master = pd.read_pickle(master_path)\n",
    "            # concat and dedupe on Datetime + Ticker (use Datetime_dt when available)\n",
    "            prev_master['Datetime_dt'] = pd.to_datetime(prev_master['Datetime'])\n",
    "            combined_master = pd.concat([prev_master, df_display], ignore_index=True)\n",
    "            combined_master = combined_master.drop_duplicates(subset=['Ticker', 'Datetime_dt'])\n",
    "            combined_master = combined_master.sort_values(['Datetime_dt', 'Ticker'], ascending=[False, True]).reset_index(drop=True)\n",
    "            combined_master.to_pickle(master_path)\n",
    "        except Exception:\n",
    "            # fallback: overwrite if previous master can't be read\n",
    "            df_display.to_pickle(master_path)\n",
    "    else:\n",
    "        df_display.to_pickle(master_path)\n",
    "\n",
    "    print(f\"Master results updated at: {master_path}\")\n",
    "\n",
    "    # Prepare a friendly display including last-3 info\n",
    "    def format_row_with_prev(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'],\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs']\n",
    "        })\n",
    "\n",
    "    # Use only today's primary rows for the main table, but keep previous-FVGs text from history\n",
    "    if df_today.empty:\n",
    "        print(f\"\\nNo FVGs detected for {today.strftime('%Y-%m-%d')} in {key_name}\")\n",
    "    else:\n",
    "        formatted_df = df_today.apply(format_row_with_prev, axis=1)\n",
    "        formatted_df = formatted_df[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']]\n",
    "\n",
    "        # optional: widen display for long Previous_FVGs text\n",
    "        pd.set_option('display.max_colwidth', 300)\n",
    "        pd.set_option('display.width', 200)\n",
    "\n",
    "        print(f\"\\nFVG Detection Results for {key_name} (date: {today}):\")\n",
    "        print(formatted_df.to_string(index=False))\n",
    "        # align columns to the right for consistent presentation (including Previous_FVGs)\n",
    "        print(formatted_df.to_string(index=False, justify='right'))\n",
    "        print(f\"\\nTotal FVGs detected today: {len(formatted_df)}\")\n",
    "else:\n",
    "    print(f\"No FVGs detected in any instrument in {key_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4b036d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentkey8 = {\n",
    "   \"mphasis\":\"NSE_EQ|INE356A01018\",\n",
    "   \"KPITECH\": \"NSE_EQ|INE04I401011\",\n",
    "   \"UBL\":\"NSE_EQ|INE686F01025\",\n",
    "   \"PIIND\":\"NSE_EQ|INE603J01030\",\n",
    "   \"WELCORP\":\"NSE_EQ|INE191B01025\", \n",
    "   \"BHARTIHEXA\":\"NSE_EQ|INE343G01021\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06153b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 matches in IK3\n",
      "Found 1 matches in IK4\n",
      "Found 1 matches in IK5\n",
      "Found 2 matches in IK6\n",
      "Found 2 matches in IK7\n",
      "\n",
      "FVG Detection Results for Focus Stocks (date: 2025-10-30):\n",
      "====================================================================================================\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 13:15    MPHASIS 🟢 bullish  1.90 2872.00 - 2873.90 No previous data\n",
      "2025-10-30 12:15    WELCORP 🟢 bullish  8.05   912.00 - 920.05 No previous data\n",
      "2025-10-30 10:15 BHARTIHEXA 🔴 bearish  6.60 1865.40 - 1872.00 No previous data\n",
      "2025-10-30 10:15    KPITECH 🔴 bearish 20.10 1171.90 - 1192.00 No previous data\n",
      "2025-10-30 10:15      PIIND 🔴 bearish  7.50 3592.60 - 3600.10 No previous data\n",
      "2025-10-30 10:15        UBL 🔴 bearish 30.50 1807.70 - 1838.20 No previous data\n",
      "2025-10-30 09:15        UBL 🔴 bearish 18.20 1819.80 - 1838.00 No previous data\n",
      "\n",
      "Total FVGs detected today: 7\n",
      "Found 1 matches in IK5\n",
      "Found 2 matches in IK6\n",
      "Found 2 matches in IK7\n",
      "\n",
      "FVG Detection Results for Focus Stocks (date: 2025-10-30):\n",
      "====================================================================================================\n",
      "        Datetime     Ticker   Pattern   Gap             Range    Previous_FVGs\n",
      "2025-10-30 13:15    MPHASIS 🟢 bullish  1.90 2872.00 - 2873.90 No previous data\n",
      "2025-10-30 12:15    WELCORP 🟢 bullish  8.05   912.00 - 920.05 No previous data\n",
      "2025-10-30 10:15 BHARTIHEXA 🔴 bearish  6.60 1865.40 - 1872.00 No previous data\n",
      "2025-10-30 10:15    KPITECH 🔴 bearish 20.10 1171.90 - 1192.00 No previous data\n",
      "2025-10-30 10:15      PIIND 🔴 bearish  7.50 3592.60 - 3600.10 No previous data\n",
      "2025-10-30 10:15        UBL 🔴 bearish 30.50 1807.70 - 1838.20 No previous data\n",
      "2025-10-30 09:15        UBL 🔴 bearish 18.20 1819.80 - 1838.00 No previous data\n",
      "\n",
      "Total FVGs detected today: 7\n"
     ]
    }
   ],
   "source": [
    "def compile_focus_stocks_fvg_from_memory(focus_stocks):\n",
    "    \"\"\"\n",
    "    Compile FVG data for focus stocks from today's detection results saved in pickle files\n",
    "    \"\"\"\n",
    "    today = pd.Timestamp.now(tz='Asia/Kolkata').date()\n",
    "    \n",
    "    # Dictionary of result file paths for each instrument key \n",
    "    result_files = {\n",
    "        'IK2': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik2(30-10).pkl\"),\n",
    "        'IK3': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik3(30-10).pkl\"),\n",
    "        'IK4': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik4(30-10).pkl\"), \n",
    "        'IK5': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik5(30-10).pkl\"),\n",
    "        'IK6': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik6(30-10).pkl\"),\n",
    "        'IK7': Path(r\"c:\\Users\\Parth1\\.ipython\\Upstox\\fvg_detection_resultsik7(30-10).pkl\")\n",
    "    }\n",
    "\n",
    "    # Load and combine results for focus stocks\n",
    "    focus_results = []\n",
    "    \n",
    "    for ik_name, file_path in result_files.items():\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                df = pd.read_pickle(file_path)\n",
    "                # Filter for focus stocks (case-insensitive)\n",
    "                focus_stocks_upper = {k.upper(): k for k in focus_stocks.keys()}\n",
    "                matches = df[df['Ticker'].str.upper().isin(focus_stocks_upper.keys())].copy()\n",
    "                \n",
    "                if not matches.empty:\n",
    "                    focus_results.append(matches)\n",
    "                    print(f\"Found {len(matches)} matches in {ik_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {ik_name}: {str(e)}\")\n",
    "\n",
    "    if not focus_results:\n",
    "        print(\"No FVG data found for focus stocks\")\n",
    "        return None\n",
    "\n",
    "    # Combine all results\n",
    "    df_focus = pd.concat(focus_results, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_focus = df_focus.drop_duplicates(subset=['Datetime', 'Ticker'])\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df_focus['Datetime'] = pd.to_datetime(df_focus['Datetime'])\n",
    "    df_focus = df_focus.sort_values(['Datetime', 'Ticker'], ascending=[False, True])\n",
    "    \n",
    "    # Filter for today's data\n",
    "    df_focus['Date'] = df_focus['Datetime'].dt.date\n",
    "    today_focus = df_focus[df_focus['Date'] == today].copy()\n",
    "    \n",
    "    if today_focus.empty:\n",
    "        print(f\"\\nNo FVGs detected today for focus stocks\")\n",
    "        return df_focus\n",
    "        \n",
    "    # Format for display\n",
    "    def format_row(row):\n",
    "        symbol = '🟢' if row['FVG_type'] == 'bullish' else '🔴'\n",
    "        return pd.Series({\n",
    "            'Datetime': row['Datetime'].strftime('%Y-%m-%d %H:%M'),\n",
    "            'Ticker': row['Ticker'],\n",
    "            'Pattern': f\"{symbol} {row['FVG_type']}\",\n",
    "            'Gap': f\"{row['FVG_gap']:.2f}\",\n",
    "            'Range': f\"{row['FVG_low']:.2f} - {row['FVG_high']:.2f}\",\n",
    "            'Previous_FVGs': row['Last_3_FVGs'] if 'Last_3_FVGs' in row else 'No previous data'\n",
    "        })\n",
    "\n",
    "    # Display results\n",
    "    formatted = today_focus.apply(format_row, axis=1)\n",
    "    \n",
    "    print(f\"\\nFVG Detection Results for Focus Stocks (date: {today}):\")\n",
    "    print(\"=\" * 100)\n",
    "    pd.set_option('display.max_colwidth', 300)\n",
    "    pd.set_option('display.width', 200)\n",
    "    print(formatted[['Datetime', 'Ticker', 'Pattern', 'Gap', 'Range', 'Previous_FVGs']].to_string(index=False))\n",
    "    print(f\"\\nTotal FVGs detected today: {len(formatted)}\")\n",
    "    \n",
    "    return df_focus\n",
    "\n",
    "# Run the compilation\n",
    "focus_stocks_data = compile_focus_stocks_fvg_from_memory(instrumentkey8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
